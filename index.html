<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.1">
<title data-rh="true">Blog | Zeebe Chaos</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://zeebe-io.github.io/zeebe-chaos/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="Blog | Zeebe Chaos"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/zeebe-chaos/img/zeebe-logo.png"><link data-rh="true" rel="canonical" href="https://zeebe-io.github.io/zeebe-chaos/"><link data-rh="true" rel="alternate" href="https://zeebe-io.github.io/zeebe-chaos/" hreflang="en"><link data-rh="true" rel="alternate" href="https://zeebe-io.github.io/zeebe-chaos/" hreflang="x-default"><script data-rh="true">function insertBanner(){var n=document.createElement("div");n.id="__docusaurus-base-url-issue-banner-container";n.innerHTML='\n<div id="__docusaurus-base-url-issue-banner" style="border: thick solid red; background-color: rgb(255, 230, 179); margin: 20px; padding: 20px; font-size: 20px;">\n   <p style="font-weight: bold; font-size: 30px;">Your Docusaurus site did not load properly.</p>\n   <p>A very common reason is a wrong site <a href="https://docusaurus.io/docs/docusaurus.config.js/#baseUrl" style="font-weight: bold;">baseUrl configuration</a>.</p>\n   <p>Current configured baseUrl = <span style="font-weight: bold; color: red;">/zeebe-chaos/</span> </p>\n   <p>We suggest trying baseUrl = <span id="__docusaurus-base-url-issue-banner-suggestion-container" style="font-weight: bold; color: green;"></span></p>\n</div>\n',document.body.prepend(n);var e=document.getElementById("__docusaurus-base-url-issue-banner-suggestion-container"),s=window.location.pathname,o="/"===s.substr(-1)?s:s+"/";e.innerHTML=o}document.addEventListener("DOMContentLoaded",(function(){void 0===window.docusaurus&&insertBanner()}))</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"Blog","@id":"https://zeebe-io.github.io/zeebe-chaos/","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/","headline":"Blog","description":"Blog","blogPost":[{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling","url":"https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling","headline":"Operate load handling","name":"Operate load handling","description":"Happy to announce that we are broadening the scope of our Chaos days, to look holistically at the whole Camunda Platform, starting today.","datePublished":"2024-08-16T00:00:00.000Z","author":{"@type":"Person","name":"Christopher Kujawa","description":"Chaos Engineer @ Zeebe","url":"https://github.com/zelldon","image":"https://github.com/zelldon.png"},"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting","url":"https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting","headline":"Using flow control to handle bottleneck on exporting","name":"Using flow control to handle bottleneck on exporting","description":"Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).","datePublished":"2024-07-25T00:00:00.000Z","author":{"@type":"Person","name":"Rodrigo Lopes","description":"Associate Software Engineer @ Zeebe","url":"https://github.com/rodrigo-lourenco-lopes","image":"https://github.com/rodrigo-lourenco-lopes.png"},"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops","url":"https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops","headline":"Using flow control to handle uncontrolled process loops","name":"Using flow control to handle uncontrolled process loops","description":"Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).","datePublished":"2024-07-25T00:00:00.000Z","author":{"@type":"Person","name":"Rodrigo Lopes","description":"Associate Software Engineer @ Zeebe","url":"https://github.com/rodrigo-lourenco-lopes","image":"https://github.com/rodrigo-lourenco-lopes.png"},"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency","url":"https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency","headline":"Reducing the job activation delay","name":"Reducing the job activation delay","description":"With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:","datePublished":"2024-01-19T00:00:00.000Z","author":{"@type":"Person","name":"Nicolas Pepin-Perreault","description":"Senior Software Engineer @ Zeebe","url":"https://github.com/npepinpe","image":"https://github.com/npepinpe.png"},"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance","url":"https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance","headline":"Broker Scaling and Performance","name":"Broker Scaling and Performance","description":"With Zeebe now supporting the addition and removal of brokers to a running cluster, we wanted to test three things:","datePublished":"2023-12-20T00:00:00.000Z","author":[{"@type":"Person","name":"Lena Schönburg","description":"Senior Software Engineer @ Zeebe","url":"https://github.com/lenaschoenburg","image":"https://github.com/lenaschoenburg.png"},{"@type":"Person","name":"Deepthi Akkoorath","description":"Senior Software Engineer @ Zeebe","url":"https://github.com/deepthidevaki","image":"https://github.com/deepthidevaki.png"}],"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss","url":"https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss","headline":"Dynamic Scaling with Dataloss","name":"Dynamic Scaling with Dataloss","description":"We continue our previous experiments with dynamically scaling by now also testing whether","datePublished":"2023-12-19T00:00:00.000Z","author":{"@type":"Person","name":"Lena Schönburg","description":"Senior Software Engineer @ Zeebe","url":"https://github.com/lenaschoenburg","image":"https://github.com/lenaschoenburg.png"},"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers","url":"https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers","headline":"Dynamically scaling brokers","name":"Dynamically scaling brokers","description":"We experimented with the first version of dynamic scaling in Zeebe, adding or removing brokers for a running cluster.","datePublished":"2023-12-18T00:00:00.000Z","author":{"@type":"Person","name":"Lena Schönburg","description":"Senior Software Engineer @ Zeebe","url":"https://github.com/lenaschoenburg","image":"https://github.com/lenaschoenburg.png"},"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency","url":"https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency","headline":"Job push resiliency","name":"Job push resiliency","description":"In today's chaos day we experimented with job push resiliency.","datePublished":"2023-12-06T00:00:00.000Z","author":[{"@type":"Person","name":"Christopher Kujawa","description":"Chaos Engineer @ Zeebe","url":"https://github.com/zelldon","image":"https://github.com/zelldon.png"},{"@type":"Person","name":"Nicolas Pepin-Perreault","description":"Senior Software Engineer @ Zeebe","url":"https://github.com/npepinpe","image":"https://github.com/npepinpe.png"}],"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading","url":"https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading","headline":"Job push overloading","name":"Job push overloading","description":"In today's chaos day we (Nicolas and I) want to verify how job push behaves and in general, the Zeebe system when we have slow workers.","datePublished":"2023-11-30T00:00:00.000Z","author":{"@type":"Person","name":"Christopher Kujawa","description":"Chaos Engineer @ Zeebe","url":"https://github.com/zelldon","image":"https://github.com/zelldon.png"},"keywords":[]},{"@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing","url":"https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing","headline":"Hot backups impact on processing","name":"Hot backups impact on processing","description":"Today, we want to experiment with hot backups in SaaS and a larger runtime state in Zeebe and how it impacts the ongoing processing in Zeebe (or not?). This is part of the investigation of a recently created bug issue we wanted to verify/reproduce #14696.","datePublished":"2023-11-07T00:00:00.000Z","author":{"@type":"Person","name":"Christopher Kujawa","description":"Chaos Engineer @ Zeebe","url":"https://github.com/zelldon","image":"https://github.com/zelldon.png"},"keywords":[]}]}</script><link rel="alternate" type="application/rss+xml" href="/zeebe-chaos/rss.xml" title="Zeebe Chaos RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zeebe-chaos/atom.xml" title="Zeebe Chaos Atom Feed"><link rel="stylesheet" href="/zeebe-chaos/assets/css/styles.4af10516.css">
<script src="/zeebe-chaos/assets/js/runtime~main.9a184470.js" defer="defer"></script>
<script src="/zeebe-chaos/assets/js/main.396bf1f2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zeebe-chaos/"><div class="navbar__logo"><img src="/zeebe-chaos/img/zeebe-logo.png" alt="Zeebe" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/zeebe-chaos/img/zeebe-logo.png" alt="Zeebe" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Zeebe Chaos</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zeebe-chaos/">Chaos Summaries</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/zeebe-io/zeebe-chaos" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/08/16/Operate-load-handling">Operate load handling</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting">Using flow control to handle bottleneck on exporting</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops">Using flow control to handle uncontrolled process loops</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/01/19/Job-Activation-Latency">Reducing the job activation delay</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2023</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/20/Broker-scaling-performance">Broker Scaling and Performance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss">Dynamic Scaling with Dataloss</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers">Dynamically scaling brokers</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/06/Job-Push-resiliency">Job push resiliency</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/11/30/Job-push-overloading">Job push overloading</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing">Hot backups impact on processing</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance">Using Large Multi-Instance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle">Continuing SST Partitioning toggle</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/05/15/SST-Partitioning-toggle">SST Partitioning toggle</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/04/06/gateway-termination">Gateway Termination</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/02/23/Recursive-call-activity">Recursive call activity</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2022</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition">Message Correlation after Network Partition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/08/02/deployment-distribution">Bring Deployment distribution experiment back</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS">Standalone Gateway in CCSaaS</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/02/01/High-Snapshot-Frequency">High Snapshot Frequency</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/01/19/big-variables">Handling of Big Variables</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2021</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance">Worker count should not impact performance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys">Not produce duplicate Keys</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/10/29/Throughput-on-big-state">Throughput on big state</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/10/05/recovery-time">Recovery (Fail Over) time</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/09/23/Old-Clients">Old-Clients</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/07/06/Slow-Network">Slow Network</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/06/08/Full-Disk">Full Disk Recovery</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/05/25/Reset-Clock">Time travel Experiment</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/04/29/Corrupted-Snapshot">Corrupted Snapshot Experiment Investigation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/04/03/bpmn-meets-chaos-engineering">BPMN meets Chaos Engineering</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/03/30/set-file-immutable">Set file immutable</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/03/23/camunda-cloud-network-partition">Camunda Cloud network partition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/03/09/cont-workflow-instance">Fault-tolerant processing of process instances</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/02/23/automate-deployments-dist">Automating Deployment Distribution Chaos Experiment</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/01/26/deployments">Deployment Distribution</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/01/19/network-partition">Network partitions</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/01/07/disconnect-leader-and-follower">Disconnect Leader and one Follower</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2020</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/11/24/message-correlation-after-failover">Message Correlation after Failover</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/11/11/job-timeouts">Many Job Timeouts</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/11/03/investigate-failing-tests">Investigate failing Chaos Tests</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/20/non-graceful-shutdown">Non-graceful Shutdown Broker</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/27/standalone-gw-memory">Gateway memory consumption</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/13/multiple-leader-changes">Multiple Leader Changes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/06/toxi-proxy">Play around with ToxiProxy</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/08/20/experiment-with-camunda-cloud">Experiment with Camunda Cloud</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/08/06/low-load">Experiment with Low Load</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/30/experiment-without-exporters">Experiment without Exporters</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/16/big-multi-instance">Big Multi Instance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/09/timer-and-huge-variables">Experiment with Timers and Huge Variables</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/02/extract-k8-resources">Extract K8 resources from namespace</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/25/gateway-network-partition">Gateway Network Partition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/18/correlate-message-after-failover">Correlate Message after failover</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/11/high-cpu-gateway">High CPU load on Standalone Gateway</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/04/first-chaos-day">First Chaos Day!</a></li></ul></div></nav></aside><main class="col col--7"><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2024/08/16/Operate-load-handling">Operate load handling</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-08-16T00:00:00.000Z">August 16, 2024</time> · <!-- -->8 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/zelldon.png" alt="Christopher Kujawa"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Christopher Kujawa</span></a></div><small class="authorTitle_nd0D" title="Chaos Engineer @ Zeebe">Chaos Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>🎉<!-- --> Happy to announce that we are broadening the scope of our Chaos days, to look holistically at the whole Camunda Platform, starting today.
In the past Chaos days we often had a close look (or concentrated mostly) at Zeebe performance and stability.</p>
<p>Today, we will look at the Operate import performance and how Zeebe processing throughput might affect (or not?) the throughput and latency of the Operate import. Is it decoupled as we thought?</p>
<p>The import time is an important metric, representing the time until data from Zeebe processing is
visible to the User (excluding Elasticsearch&#x27;s indexing). It is measured from when the record is written to the log, by the Zeebe processor, until Operate reads/imports it from Elasticsearch and converts it into its data model. We got much feedback (and experienced this on our own) that
Operate is often lagging behind or is too slow, and of course we want to tackle and investigate this further.</p>
<p>The results from this Chaos day and related benchmarks should allow us to better understand how the current importing
of Operate performs, and what its affects. Likely it will be a series of posts to investigate this further. In general,
the data will give us some guidance and comparable numbers for the future to improve the importing time. See also related GitHub issue <a href="https://github.com/camunda/camunda/issues/16912" target="_blank" rel="noopener noreferrer">#16912</a> which targets to improve such.</p>
<p><strong>TL;DR;</strong> We were not able to show that Zeebe throughput doesn&#x27;t affect Operate importing time. We have seen that Operate can be positively affected by the throughput of Zeebe. Surprisingly, Operate was faster to
import if Zeebe produced more data (with a higher throughput). One explanation of this might be that Operate was then less idle.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/performance">performance</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Operate load handling" href="/zeebe-chaos/2024/08/16/Operate-load-handling"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting">Using flow control to handle bottleneck on exporting</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-07-25T00:00:00.000Z">July 25, 2024</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/rodrigo-lourenco-lopes" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/rodrigo-lourenco-lopes.png" alt="Rodrigo Lopes"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/rodrigo-lourenco-lopes" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Rodrigo Lopes</span></a></div><small class="authorTitle_nd0D" title="Associate Software Engineer @ Zeebe">Associate Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).
Limiting the write rate is a new feature that can be used to prevent building up an excessive exporting backlog.
There are two ways to limit the write rate, either by setting a static limit or by enabling throttling that dynamically adjust the write rate based on the exporting backlog and rate.
In these experiments, we will test both ways of limiting the write rate and observe the effects on processing and exporting.</p>
<p><strong>TL;DR;</strong>
Both setting a static write rate limit and enabling throttling of the write rate can be used to prevent building up an excessive exporting backlog.
For users, this will be seen as backpressure because processing speed is limited by the rate at which it can write processing results.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="static-write-limit">Static write limit<a href="#static-write-limit" class="hash-link" aria-label="Direct link to Static write limit" title="Direct link to Static write limit">​</a></h2>
<p>We will construct a cluster under normal utilization and then artificially degrade the exporting process.
After this we will apply flow control settings to statically rate limit all writes.
The limit will be set slightly lower than the observed exporting rate.</p>
<p>For this we will use the flow control endpoint to temporarily configure the write rate limit.</p>
<p>To fetch the current configuration we can port forward to one of the zeebe pods and use the command:</p>
<div class="language-Shell language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">GET /actuator/flowControl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="original-configuration" src="/zeebe-chaos/assets/images/original-configuration-568ece5f5f513848f06d772b821f7ba6.png" width="586" height="532" class="img_ev3q"></p>
<p>To configure the write rate limit we use the same endpoint, for example:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;write&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;enabled&quot;: true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;limit&quot;: 400</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>When we start to degrade the exporting rate, we expect to see the exporting backlog to increase steadily.</p>
<p>Once a static write rate limit below the degraded exporting rate is applied, we expect fewer rates and slower processing.
The exporting backlog should decrease again until we eventually reach zero backlog again.
Backpressure should increase because processing has slowed down and some requests will be rejected by the write rate limit.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>After we artificially degrade the exporter performance, we see a constant increase in records not exported since the processing is still happening at the same rate.</p>
<p><img decoding="async" loading="lazy" alt="exporting-per-partition" src="/zeebe-chaos/assets/images/exporting-per-partition-post-degraded-exporting-45c6750dac85bf4a0a2b949833b6dfd0.png" width="1999" height="379" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition" src="/zeebe-chaos/assets/images/processing-per-partition-post-degraded-exporting-0e056df5c7a61f47f01c6a3cee5a3c41.png" width="1999" height="378" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="exporter-backlog" src="/zeebe-chaos/assets/images/number-of-records-not-exported-post-degraded-exporting-6df4c3931c2367ce522bac8f9a3a7698.png" width="1362" height="534" class="img_ev3q"></p>
<p>After applying a static rate limit of 400 to be slightly lower than the observed 500-600 of the exporting rate, we see that the processing speed changes accordingly.</p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition-post-rate-limit" src="/zeebe-chaos/assets/images/processing-per-partition-post-rate-limit-3cf3e06b8171ca675e12333dce4385aa.png" width="1999" height="371" class="img_ev3q"></p>
<p>As expected we also see this reflected in backpressure that sees the user commands being rejected in a much higher portion.</p>
<p><img decoding="async" loading="lazy" alt="backpressure" src="/zeebe-chaos/assets/images/backpressure-post-rate-limit-90eba93cb2dd681bfa3d67074ff83713.png" width="1532" height="460" class="img_ev3q"></p>
<p>We also observe that the backlog of records not exported starts to decrease at the rate of the difference between exported and written records.</p>
<p><img decoding="async" loading="lazy" alt="exporter-backlog-post-rate-limit" src="/zeebe-chaos/assets/images/number-of-records-not-exported-post-rate-limit-0e96e608f6826f596b09a32806640ea3.png" width="1360" height="540" class="img_ev3q"></p>
<p>These observations match our expectations and show that a static write rate limit can be used to prevent building up an excessive exporting backlog.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dynamic-write-rate-throttling">Dynamic write rate throttling<a href="#dynamic-write-rate-throttling" class="hash-link" aria-label="Direct link to Dynamic write rate throttling" title="Direct link to Dynamic write rate throttling">​</a></h2>
<p>Choosing a static write rate limit is not a full solution because we can&#x27;t predict the actual exporting rates.
To address this, we can enable write rate throttling that will dynamically adjust the write rate based on the exporting backlog and rate.</p>
<p>To enable write rate throttling we can use the flow control endpoint again, for example:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;write&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;enabled&quot;: true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;limit&quot;: 2500,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;throttling&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;enabled&quot;: true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;acceptableBacklog&quot;: 100000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;minimumLimit&quot;: 100,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;resolution&quot;: &quot;15s&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>Similar to the first experiment, we expect to see the exporting backlog increase when we artificially degrade the exporting performance.
After enabling write rate throttling, we expect that the write rate is reduced significantly and eventually matches the exporting rate.
The reduced write rate should show up as backpressure.
Eventually, the exporting backlog settles at the configured acceptable backlog.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>Re-running the same setup, but using the throttling of writes with an acceptable backlog at 100,000  of not exported records, and a limit higher than our processing speed (so has to not impact the experience), we get the following results:</p>
<p><img decoding="async" loading="lazy" alt="number-of-records-not-exported-post-throttling" src="/zeebe-chaos/assets/images/number-of-records-not-exported-post-throttling-89e888362474746d19c4047766c42cd0.png" width="1098" height="454" class="img_ev3q"></p>
<p>The orange underline metric displays when the throttled write rate is applied.</p>
<p><img decoding="async" loading="lazy" alt="exporting-per-partition-post-throttling" src="/zeebe-chaos/assets/images/exporting-per-partition-post-throttling-725f5e30d24caaef42c564ce2a986dcd.png" width="1999" height="293" class="img_ev3q"></p>
<p>From the panels of the “Exporting per Partition” and “Number of records not exported”, we can observe that during the re-run of the experience our artificially degrading of the exporters only affected Exporters 2 and 3.
After we enable throttling, the backlog on these affected exporters starts to decrease as expected, later stabilizing on around 100,000 records.
This will drop back to 0 once we remove the artificial degrading of the exporters.</p>
<p><img decoding="async" loading="lazy" alt="backpressure-post-throttling" src="/zeebe-chaos/assets/images/backpressure-post-throttling-77bb875c059269233e3d7b30c81ca1b9.png" width="1984" height="460" class="img_ev3q"></p>
<p>In the backpressure, we observe that this increases mostly on the affected partitions 2 and 3, and once the number of records not exported reaches the acceptable level this lowers slightly and stabilizes.</p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition-post-throttling" src="/zeebe-chaos/assets/images/processing-per-partition-post-throttling-9aa68235837dd795cbb5a10bd875f3b5.png" width="1999" height="290" class="img_ev3q"></p>
<p>Finally, on the panel that shows the processing per partition, we also confirm the expectation that since one of the exporters was not affected by the artificial degrading of the exporter, some additional traffic gets re-routed to this partition, after the throttling gets applied.
On the affected partitions we see the processing decreasing slightly in line with the exporting on the same partitions.</p>
<p>Overall the observations match our expectations and show that write rate throttling succeeds and keeps exporting backlog limited.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li></ul></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops">Using flow control to handle uncontrolled process loops</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-07-25T00:00:00.000Z">July 25, 2024</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/rodrigo-lourenco-lopes" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/rodrigo-lourenco-lopes.png" alt="Rodrigo Lopes"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/rodrigo-lourenco-lopes" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Rodrigo Lopes</span></a></div><small class="authorTitle_nd0D" title="Associate Software Engineer @ Zeebe">Associate Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).</p>
<p>Limiting the write rate is a new feature that can be used to prevent building up an excessive exporting backlog.</p>
<p>In these experiments we will test what happens with the deployment of endless
loops that result in high processing load, and how we can use the new
flow control to keep the cluster stable.</p>
<p><strong>TL;DR;</strong></p>
<p>Enabling the write rate limiting can help mitigate the effects caused by
process instances that contain uncontrolled loops by preventing building up an
excessive exporting backlog.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mitigating-the-performance-impacts-of-deployed-loops">Mitigating the performance impacts of deployed loops:<a href="#mitigating-the-performance-impacts-of-deployed-loops" class="hash-link" aria-label="Direct link to Mitigating the performance impacts of deployed loops:" title="Direct link to Mitigating the performance impacts of deployed loops:">​</a></h2>
<p>When an uncontrolled loop is accidentally deployed this tends to use of
most of the
processing resources of the partitions where instances are running.</p>
<p>Such instances completely occupies its partition, starves other instances and results in slow response times.</p>
<p>Usually, these problems should be addressed before other issues arise, such as full disk due to a large backlog of not exported records (max exporting speed tends to be slower than max processing speed).</p>
<p>Using the write rate limiter, we can slow down the processing speed and
give us more time to address the issue, while at the same time enabling us to reduce or maintain the backlog size and reduce risks of side effects.</p>
<p>To reduce the rate write limit we will use the unified control endpoint and configure write limit to be significantly lower than the processing speed.</p>
<p>To fetch the current configuration we can port forward to one of the zeebe pods and use the command:</p>
<div class="language-Shell language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">GET /actuator/flowControl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="original-configuration" src="/zeebe-chaos/assets/images/original-configuration-568ece5f5f513848f06d772b821f7ba6.png" width="586" height="532" class="img_ev3q"></p>
<p>To configure the write rate limit we use the same endpoint:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   &quot;write&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;enabled&quot;: true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;limit&quot;: 3000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For this experiment we will test the impact of write rate limits both in
single loops and dual loops.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="single-loop-processing">Single loop processing:<a href="#single-loop-processing" class="hash-link" aria-label="Direct link to Single loop processing:" title="Direct link to Single loop processing:">​</a></h2>
<p><img decoding="async" loading="lazy" alt="single-loop" src="/zeebe-chaos/assets/images/single-loop-2c6d288753c26789a55ac011536dcf6a.png" width="1090" height="634" class="img_ev3q"></p>
<p>This single-loop process will hoard the processing resources and never complete but will append to the processing queue only the next step in the process.</p>
<p>This means that the number of records not processed will only grow if many other processes or requests are arriving at the same time, at a faster rate than the cluster can process.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-results">Expected results:<a href="#expected-results" class="hash-link" aria-label="Direct link to Expected results:" title="Direct link to Expected results:">​</a></h3>
<p>When deploying a process instance with a single loop we should see the
processing rate in the partition increases significantly.</p>
<p>This can lead to processing speed to surpass the exporting speed, which
results in increase in the backlog of exported records.</p>
<p>Using the rate write limits to restrict the processing speed enables us to
reduce the backlog size and give more time for the user to fix the
underlying issues with the cluster.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>By deploying a single loop model we can see that the processing and writing
increases in the same partition and stabilizes around 5 000, later at
around 17:55 we apply the write rate limit of 3 000, and the processing
gets limited accordingly.</p>
<p>This leads to some of the requests being
redirected to
the other partitions which cause the processing in these to increase.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-processing-per-partition" src="/zeebe-chaos/assets/images/single-loop-processing-per-partition-5a64caa8af538a2e888591a0d00f7ab1.png" width="1999" height="290" class="img_ev3q"></p>
<p>When observing the backpressure, we can draw the same conclusions as from
the processing per partition graph, after the model gets deployed, we see an
increase in the backpressure to around 7% in the partition where the loop
instance was deployed.</p>
<p>Once the limit gets set at around 17:55 the backpressure in this partition
increases even more, to around 22% with the backpressure in the other partitions also increasing significantly.</p>
<p>This follows the expected results since with the limiting processing, the after partition will reject even more commands, which get redirected to the remaining partitions which also cause their load to increase and therefore their backpressure as well.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-backpressure" src="/zeebe-chaos/assets/images/single-loop-backpressure-3a91001378b847e1184ccb2e1e36d13a.png" width="1972" height="456" class="img_ev3q"></p>
<p>Observing the exporting per partition panel we can see that the exporting also increases in the affected partition, and this gets reduced after the limit gets imposed.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-exporting-per-partition" src="/zeebe-chaos/assets/images/single-loop-exporting-per-partition-c72cfee7a14b98c2a7e45945c63f2e99.png" width="1999" height="293" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dual-loop-processing">Dual loop processing:<a href="#dual-loop-processing" class="hash-link" aria-label="Direct link to Dual loop processing:" title="Direct link to Dual loop processing:">​</a></h2>
<p><img decoding="async" loading="lazy" alt="double-loop" src="/zeebe-chaos/assets/images/dual-loop-629f9c9afa1f36b5bab529656d32cf42.png" width="976" height="612" class="img_ev3q"></p>
<p>On the other hand, this dual loop process during its run will always create more records than can be processed since it doubles in the last step.</p>
<p>This will create a steady increase in records not processed even if no other processes or requests are competing for processing time.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h2>
<p>When deploying a process instance with a dual loop we should expect to see
a rapid increase in the processing speed and also in the number of records
not processed.</p>
<p>In this case, restricting the processing speed should not decrease the
backlog of processed records since on each run of the loop more records are
created than
processed.</p>
<p>However, it should help us at least in reducing the pace of the increase in
the backlog and therefore give us more time to address the
underlying problem.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h2>
<p>After deploying the dual loop we can see that the processing quickly jumps to its peak, at around 18:11 we configure the write rate limit at 3000.</p>
<p>Unlike the previous experience here we can observe that the processing speed in the other partitions was already increasing before the configuration gets applied.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-processing-per-partition" src="/zeebe-chaos/assets/images/dual-loop-processing-per-partition-89041e42051a2123a5c442c197ad08fe.png" width="1999" height="288" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="dual-loop-exporting-per-partition" src="/zeebe-chaos/assets/images/dual-loop-exporting-per-partition-65937890949ec823d82338a744ad7ffe.png" width="1999" height="295" class="img_ev3q"></p>
<p>Observing the backpressure we get the answer as to why the processing in the other partitions was already increasing before the configuration gets applied.</p>
<p>The backpressure had already reached at 100% which means that the dual loop process by itself hoarded completely the processing resources of the partition.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-backpressure" src="/zeebe-chaos/assets/images/dual-loop-backpressure-824800471f8562faea35e72be8d9be05.png" width="1966" height="462" class="img_ev3q"></p>
<p>Observing the number of records not processed we conclude as expected that
limiting the write rate cannot stop the records backlog from continuing to increase, but we can see that the slope of the curve is smaller after configuring the limit.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-records-not-exported" src="/zeebe-chaos/assets/images/dual-loop-number-of-records-not-processed-7e4a14070299c6842e16c7496e6b99cd.png" width="1106" height="462" class="img_ev3q"></p>
<p>Overall the results match our expectations that the flow control configuration can be leveraged to give us more control of the cluster, which in the case of acting on deployed loop instances can give us more tools to address these issues.</p>
<p><em>Footnote:
(As of the latest release, it is no longer possible to deploy processes that
contain a straight-through processing loops such as the ones used in this
experience).</em></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li></ul></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2024/01/19/Job-Activation-Latency">Reducing the job activation delay</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-01-19T00:00:00.000Z">January 19, 2024</time> · <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/npepinpe.png" alt="Nicolas Pepin-Perreault"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Nicolas Pepin-Perreault</span></a></div><small class="authorTitle_nd0D" title="Senior Software Engineer @ Zeebe">Senior Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:</p>
<ul>
<li>How much is a single job activation latency reduced?</li>
<li>How much is the activation latency reduced between each task of the same process instance?</li>
<li>How much is the activation latency reduced on large clusters with a high broker and partition count?</li>
</ul>
<p>Additionally, we wanted to guarantee that every component involved in streaming, including clients, would remain resilient in the face of load surges.</p>
<p><strong>TL;DR;</strong> Job activation latency is greatly reduced, with task based workloads seeing up to 50% reduced overall execution latency. Completing a task now immediately triggers pushing out the next one, meaning the latency to activate the next task in a sequence is bounded by how much time it takes to process its completion in Zeebe. Activation latency is unaffected by how many partitions or brokers there in a cluster, as opposed to job polling, thus ensuring scalability of the system. Finally, reuse of gRPC&#x27;s flow control mechanism ensure clients cannot be overloaded even in the face of load surges, without impacting other workloads in the cluster.</p>
<p><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#job-streaming" target="_blank" rel="noopener noreferrer">Head over to the documentation to learn how to start using job push!</a></p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Reducing the job activation delay" href="/zeebe-chaos/2024/01/19/Job-Activation-Latency"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2023/12/20/Broker-scaling-performance">Broker Scaling and Performance</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-12-20T00:00:00.000Z">December 20, 2023</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/lenaschoenburg" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/lenaschoenburg.png" alt="Lena Schönburg"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/lenaschoenburg" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Lena Schönburg</span></a></div><small class="authorTitle_nd0D" title="Senior Software Engineer @ Zeebe">Senior Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/deepthidevaki" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/deepthidevaki.png" alt="Deepthi Akkoorath"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/deepthidevaki" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Deepthi Akkoorath</span></a></div><small class="authorTitle_nd0D" title="Senior Software Engineer @ Zeebe">Senior Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>With Zeebe now supporting the addition and removal of brokers to a running cluster, we wanted to test three things:</p>
<ol>
<li>Is there an impact on processing performance while scaling?</li>
<li>Is scaling resilient to high processing load?</li>
<li>Can scaling up improve processing performance?</li>
</ol>
<p><strong>TL;DR;</strong> Scaling up works even under high load and has low impact on processing performance. After scaling is complete, processing performance improves in both throughput and latency.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/performance">performance</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Broker Scaling and Performance" href="/zeebe-chaos/2023/12/20/Broker-scaling-performance"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss">Dynamic Scaling with Dataloss</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-12-19T00:00:00.000Z">December 19, 2023</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/lenaschoenburg" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/lenaschoenburg.png" alt="Lena Schönburg"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/lenaschoenburg" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Lena Schönburg</span></a></div><small class="authorTitle_nd0D" title="Senior Software Engineer @ Zeebe">Senior Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>We continue our <a href="/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers">previous experiments</a> with dynamically scaling by now also testing whether
the cluster survives dataloss during the process.</p>
<p>One goal is to verify that we haven&#x27;t accidentally introduced a single point of failure in the cluster.
Another is to ensure that data loss does not corrupt the cluster topology.</p>
<p><strong>TL;DR;</strong>
Even with dataloss, the scaling completes successfully and with the expected results.
We found that during scaling, a single broker of the previous cluster configuration can become a single point of failure by preventing a partition from electing a leader.
This is not exactly a bug, but something that we want to improve.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Dynamic Scaling with Dataloss" href="/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers">Dynamically scaling brokers</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-12-18T00:00:00.000Z">December 18, 2023</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/lenaschoenburg" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/lenaschoenburg.png" alt="Lena Schönburg"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/lenaschoenburg" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Lena Schönburg</span></a></div><small class="authorTitle_nd0D" title="Senior Software Engineer @ Zeebe">Senior Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>We experimented with the first version of <a href="https://docs.camunda.io/docs/next/self-managed/zeebe-deployment/operations/cluster-scaling/" target="_blank" rel="noopener noreferrer">dynamic scaling in Zeebe</a>, adding or removing brokers for a running cluster.</p>
<p>Scaling up and down is a high-level operation that consists of many steps that need to be carried co-operatively by all brokers in the cluster.
For example, adding new brokers first adds them to the replication group of the assigned partitions and then removes some of the older brokers from the replication group.
Additionally, <a href="https://docs.camunda.io/docs/next/self-managed/zeebe-deployment/configuration/priority-election/" target="_blank" rel="noopener noreferrer">priorities</a> need to be reconfigured to ensure that the cluster approaches balanced leadership eventually.</p>
<p>This orchestration over multiple steps ensures that all partitions are replicated by at least as many brokers as configured with the <code>replicationFactor</code>.
As always, when it comes to orchestrating distributed systems, there are many edge cases and failure modes to consider.</p>
<p>The goal of this experiment was to verify that the operation is resilient to broker restarts.
We can accept that operations take longer than usual to complete, but we need to make sure that the operation eventually succeeds with the expected cluster topology as result.</p>
<p><strong>TL;DR;</strong> Both scaling up and down is resilient to broker restarts, with the only effect that the operation takes longer than usual to complete.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/performance">performance</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Dynamically scaling brokers" href="/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2023/12/06/Job-Push-resiliency">Job push resiliency</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-12-06T00:00:00.000Z">December 6, 2023</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/zelldon.png" alt="Christopher Kujawa"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Christopher Kujawa</span></a></div><small class="authorTitle_nd0D" title="Chaos Engineer @ Zeebe">Chaos Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/npepinpe.png" alt="Nicolas Pepin-Perreault"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Nicolas Pepin-Perreault</span></a></div><small class="authorTitle_nd0D" title="Senior Software Engineer @ Zeebe">Senior Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>In today&#x27;s chaos day we experimented with job push resiliency.</p>
<p>The following experiments we have done today:</p>
<ol>
<li>Job streams should be resilient to gateway restarts/crash</li>
<li>Job streams should be resilient to leadership changes/leader restarts</li>
<li>Job streams should be resilient to cluster restarts</li>
</ol>
<p><strong>TL;DR;</strong> All experiments succeeded and showcased the resiliency even on component restarts. <!-- -->🚀</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/resiliency">resiliency</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Job push resiliency" href="/zeebe-chaos/2023/12/06/Job-Push-resiliency"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2023/11/30/Job-push-overloading">Job push overloading</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-11-30T00:00:00.000Z">November 30, 2023</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/zelldon.png" alt="Christopher Kujawa"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Christopher Kujawa</span></a></div><small class="authorTitle_nd0D" title="Chaos Engineer @ Zeebe">Chaos Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>In today&#x27;s chaos day we (Nicolas and I) want to verify how job push behaves and in general, the Zeebe system when we have slow workers.</p>
<p><strong>TL;DR;</strong> Right now it seems that even if we have a slow worker it doesn&#x27;t impact the general system, and only affects the corresponding process instance, not other instances. We found no unexpected issues, everything performed pretty well.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Job push overloading" href="/zeebe-chaos/2023/11/30/Job-push-overloading"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing">Hot backups impact on processing</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-11-07T00:00:00.000Z">November 7, 2023</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/zelldon.png" alt="Christopher Kujawa"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/zelldon" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Christopher Kujawa</span></a></div><small class="authorTitle_nd0D" title="Chaos Engineer @ Zeebe">Chaos Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>Today, we want to experiment with hot backups in SaaS and a larger runtime state in Zeebe and how it impacts the ongoing processing in Zeebe (or not?). This is part of the investigation of a recently created bug issue we wanted to verify/reproduce <a href="https://github.com/camunda/camunda/issues/14696" target="_blank" rel="noopener noreferrer">#14696</a>.</p>
<p><strong>TL;DR;</strong> We were able to prove that hot backups are indeed not impacting overall processing throughput in Zeebe. We found that having a full Elasticsearch disk might impact or even fail your backups, which is intransparent to the user.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Hot backups impact on processing" href="/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing"><b>Read More</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/zeebe-chaos/page/2"><div class="pagination-nav__label">Older Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/zeebe" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://forum.camunda.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/Camunda" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/zeebe-io/zeebe-chaos/" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Zeebe Chaos. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>