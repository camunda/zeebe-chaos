<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://camunda.github.io/zeebe-chaos/</id>
    <title>Zeebe Chaos Blog</title>
    <updated>2025-11-27T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://camunda.github.io/zeebe-chaos/"/>
    <subtitle>Zeebe Chaos Blog</subtitle>
    <icon>https://camunda.github.io/zeebe-chaos/img/zeebe-logo.png</icon>
    <entry>
        <title type="html"><![CDATA[Stress testing Camunda]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda"/>
        <updated>2025-11-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In today's chaos experiment, we focused on stress-testing the Camunda 8 platform under high-load conditions. We simulated a large number of concurrent process instances to evaluate the performance of processing and system reliability.]]></summary>
        <content type="html"><![CDATA[<p>In today's chaos experiment, we focused on stress-testing the Camunda 8 platform under high-load conditions. We simulated a large number of concurrent process instances to evaluate the performance of processing and system reliability.</p>
<p>Due to our recent work in supporting <a href="https://github.com/camunda/camunda/issues/38829" target="_blank" rel="noopener noreferrer">load tests for different versions</a>, we were able to compare how different Camunda versions handle stress.</p>
<p><strong>TL;DR;</strong> We found that Camunda 8.8.x with adjusted resources (related to architecture streamlining) performs best under high load, followed by 8.7.x, the main branch, and 8.6.x. Latency was lowest (best) by a factor of 2 in 8.8.x with increased resources compared to 8.7.x.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>[Update: 28.11.2025]</p><p>As noted, the architecture in 8.8.x has changed to a single Camunda application. Combining several components, like Zeebe Broker, Zeebe Gateway, Operate Webapp + Importer, Tasklist Webapp + Importer, and Identity. Thus, it should not be surprising that resource demands have changed.</p><p>We experimented further with 8.8.x by increasing the CPU resources to 3.5 cores and, for example, enabling client load balancing. Increasing our resources already allowed us to reach a throughput of ~250 PI/s, which is comparable to 8.7.x performance, while the latency remained a factor of 2 lower.
Client load balancing enabled us to utilize our resources more effectively.</p><p>For more details, see the section "Further Experiments" below.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>Weekly, we run <a href="https://github.com/camunda/camunda/blob/main/docs/testing/reliability-testing.md#variations" target="_blank" rel="noopener noreferrer">endurance tests</a> to validate the stability of our systems. This time, we decided to push the limits further by increasing the load significantly and observing how Camunda handles the stress.</p>
<p>Additionally, we wanted to see how far we can go and how this differs between versions. Therefore, we compared the performance of Camunda 8.8.x and 8.7.x under identical stress conditions.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#setup" class="hash-link" aria-label="Direct link to Setup" title="Direct link to Setup">â€‹</a></h3>
<p>Details on the setup can be read in our  <a href="https://github.com/camunda/camunda/blob/main/docs/testing/reliability-testing.md#setup" target="_blank" rel="noopener noreferrer">reliability testing</a> documentation.</p>
<p>Important to know is that the architecture has changed slightly over the versions. In 8.8.x, we have a single Camunda application deployed, whereas in earlier versions, we had a split architecture between broker and gateway. This change has implications for how the system handles load and scales.</p>
<p><img decoding="async" loading="lazy" alt="setup" src="https://camunda.github.io/zeebe-chaos/assets/images/setup-5eae3d5c5c46544bbf2c24214cb5634e.png" width="1132" height="553" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="load-generation">Load Generation<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#load-generation" class="hash-link" aria-label="Direct link to Load Generation" title="Direct link to Load Generation">â€‹</a></h3>
<p><img decoding="async" loading="lazy" alt="setup-load" src="https://camunda.github.io/zeebe-chaos/assets/images/setup-load-test-5deae0786b63e79bdb4c7ea0d364deb9.jpg" width="5338" height="2427" class="img_ev3q"></p>
<p>We have a custom <a href="https://github.com/camunda/camunda/tree/main/load-tests/load-tester" target="_blank" rel="noopener noreferrer">load generation application</a> (split into starter and worker applications), which we deploy separately from Camunda. The starter creates process instances at a configurable rate, while the worker completes the corresponding service tasks.</p>
<p><img decoding="async" loading="lazy" alt="one-task" src="https://camunda.github.io/zeebe-chaos/assets/images/one_task-aeef574e8d7b06603338f3bc9a58e1b2.png" width="996" height="270" class="img_ev3q"></p>
<p>We will start simple, with a process that has a single service task. This is not very realistic, but it gives us a good sense of maximum load, as this is one of the smallest processes (including a service task) we can model. Reducing the used feature set to a small amount allows easy comparison between tests, as fewer variations and outside factors can influence test results. Additionally, it is a model we use in <a href="https://github.com/camunda/camunda/blob/main/docs/testing/reliability-testing.md#normal-artificial-load" target="_blank" rel="noopener noreferrer">our endurance test</a> as well, allowing us to compare it and know where to start. Our endurance tests usually have a load of 150 process instances per second (PI/s). Where the <a href="https://github.com/camunda/camunda/blob/main/load-tests/load-tester/src/main/resources/bpmn/typical_payload.json" target="_blank" rel="noopener noreferrer">payload is rather small ~0.5 KB</a>. In our stress test, the starter application will create process instances at a rate of 300 per second, while we will have six worker applications deployed processing the service tasks.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="88x-results">8.8.x Results<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#88x-results" class="hash-link" aria-label="Direct link to 8.8.x Results" title="Direct link to 8.8.x Results">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="single-service-task">Single Service Task<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#single-service-task" class="hash-link" aria-label="Direct link to Single Service Task" title="Direct link to Single Service Task">â€‹</a></h4>
<p>After setting up the load test environment and starting the load generation, we monitored the system's performance metrics, including CPU usage, memory consumption, latency (gateway response time and process instance execution time), and throughput (how many process instances, tasks, and flow-node instances were completed per second).</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-results" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-3fe2b9ee8e9ca7539d2de4c6301812f4.png" width="2525" height="859" class="img_ev3q"></p>
<p>Looking at the dashboard, we can see that we have reached the limit of our cluster. We have high back pressure (and a cluster load of nearly 100%). Our system is heavily CPU-throttled (~100% CPU utilization). This means that the system is not able to keep up with the incoming load of 300 PI/s.</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/88-latency-8568698a13378a7060876e7022a20b4c.png" width="2532" height="188" class="img_ev3q"></p>
<p>Interesting (or important) to note is that our backpressure mechanism allows us to keep the latency always steady and low. But not that low as compared to other versions, we will see later.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="increasing-resources">Increasing resources<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#increasing-resources" class="hash-link" aria-label="Direct link to Increasing resources" title="Direct link to Increasing resources">â€‹</a></h5>
<p>Out of interest, I increased the resources of the cluster (increasing CPU to 3 cores; memory increase was not necessary as we were not reaching our limit).</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-3-cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-3-cpu-7528fa79e363d11cee5cfa36e099c464.png" width="2516" height="872" class="img_ev3q"></p>
<p>When increasing the CPU resources by adding one core, we were able to increase the throughput by ~37% (220/160=1.375). We are still not able to handle the full load of 300 PI/s.</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-3-cpu-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-latency-3-cpu-564870c775b156cc68eb3f659a3b4ac9.png" width="2527" height="196" class="img_ev3q"></p>
<p>The p50 latency has been decreased significantly, while the p99 is similar to before. In general, we are seeing only one pod being CPU throttled. Likely related to the fact that we do not properly distribute our load across the gateways, see issue <a href="https://github.com/camunda/camunda/issues/9870" target="_blank" rel="noopener noreferrer">9870</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="87x-results">8.7.x Results<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#87x-results" class="hash-link" aria-label="Direct link to 8.7.x Results" title="Direct link to 8.7.x Results">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="single-service-task-1">Single Service Task<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#single-service-task-1" class="hash-link" aria-label="Direct link to Single Service Task" title="Direct link to Single Service Task">â€‹</a></h4>
<p>The results for 8.7.x are quite different. Here we can see that we are able to handle much higher load ~ 246 PI/s. The backpressure is lower, and the CPU usage (and throttling) is not as high as in 8.8.x.</p>
<p>Surprisingly, the memory usage is higher in 8.7.x compared to 8.8.x. Short research showed that the broker got in 8.7 <a href="https://github.com/camunda/camunda/blob/stable/8.7/zeebe/benchmarks/camunda-platform-values.yaml#L163" target="_blank" rel="noopener noreferrer">4GB of memory assigned</a>, and <a href="https://github.com/camunda/camunda/blob/stable/8.7/zeebe/benchmarks/camunda-platform-values.yaml#L91" target="_blank" rel="noopener noreferrer">25% is used by the JVM</a>. While in 8.8 we have <a href="https://github.com/camunda/camunda/blob/main/load-tests/camunda-platform-values.yaml#L76" target="_blank" rel="noopener noreferrer">2GB assigned to the Camunda application</a>. Additionally, in 8.8 we reduced the RocksDB memory (as <a href="https://github.com/camunda/camunda/issues/31706#issuecomment-2944455152" target="_blank" rel="noopener noreferrer">experiment</a>) to <a href="https://github.com/camunda/camunda/blob/main/load-tests/camunda-platform-values.yaml#L149" target="_blank" rel="noopener noreferrer">64 MB per partition</a> (instead of previously 500MB). This should explain the difference.</p>
<p><img decoding="async" loading="lazy" alt="87-one-task-results" src="https://camunda.github.io/zeebe-chaos/assets/images/87-one-task-1048bcfd445cb6cca31da22824cc485b.png" width="2524" height="866" class="img_ev3q"></p>
<p>The latency is also lower in 8.7.x compared to 8.8.x. The p50 latency is approximately 170ms for gateway requests and 240ms for PI execution, while the p99 latency increases to 700ms under high load.
<img decoding="async" loading="lazy" alt="87-one-task-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/87-one-task-latency-8aca2a44fdf88d12a8168b274afee9a9.png" width="2524" height="192" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="86x-results">8.6.x Results<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#86x-results" class="hash-link" aria-label="Direct link to 8.6.x Results" title="Direct link to 8.6.x Results">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="single-service-task-2">Single Service Task<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#single-service-task-2" class="hash-link" aria-label="Direct link to Single Service Task" title="Direct link to Single Service Task">â€‹</a></h4>
<p>The results for 8.6.x are comparable to those of 8.8.x, with more resources, but still lower than those of 8.7.x. We can handle approximately 220 PI/s with similar backpressure and CPU throttling as in 8.8.x, using 3 CPU cores.</p>
<p><img decoding="async" loading="lazy" alt="86-one-task-results" src="https://camunda.github.io/zeebe-chaos/assets/images/86-one-task-d709ee6d7bc6e2201b54b85031f9c846.png" width="2519" height="848" class="img_ev3q"></p>
<p>Even the latency is comparable to the first 8.8.x test, while the p99 is much higher.</p>
<p><img decoding="async" loading="lazy" alt="86-one-task-results" src="https://camunda.github.io/zeebe-chaos/assets/images/86-one-task-latency-673ec085a62fbff4b1e490088e70460e.png" width="2526" height="194" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="main">Main<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#main" class="hash-link" aria-label="Direct link to Main" title="Direct link to Main">â€‹</a></h3>
<p>For comparison, I also ran the same test on the main branch (which will become 8.9.x). Here, the results are better than 8.8.x with 3 CPU cores. We are reaching ~230 PI/s with similar latency characteristics. Still, it is not as good as 8.7.x.</p>
<p><img decoding="async" loading="lazy" alt="main-one-task-results" src="https://camunda.github.io/zeebe-chaos/assets/images/main-one-task-137e8390aa5feaf71f30329c0390afa8.png" width="2512" height="851" class="img_ev3q"></p>
<p>Looking at the latency, we can see that it is comparable to 8.7.x test results.</p>
<p><img decoding="async" loading="lazy" alt="main-one-task-results-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/main-one-task-latency-be0150b21d60104f732d3db3886003a3.png" width="2524" height="189" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary-of-results">Summary of Results<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#summary-of-results" class="hash-link" aria-label="Direct link to Summary of Results" title="Direct link to Summary of Results">â€‹</a></h2>
<p>In terms of throughput, 8.7.x performs best, followed by main and 8.6.x. Increasing resources in 8.8.x helps, but it still cannot match the performance of 8.7.x. Just looking at 8.7 and 8.8, this means a decrease of ~35% in throughput (160 / 246 = 0.65).</p>
<p>The latency is lowest in 8.8.x with increased resources, followed by main and 8.7.x. 8.6.x has the highest latency among the tested versions.</p>
<table><thead><tr><th>Version</th><th>Throughput (PI/s)</th><th>p50 PI execution Latency (ms)</th><th>p99 PI execution Latency (ms)</th><th>CPU Throttling</th></tr></thead><tbody><tr><td>8.7.x</td><td>~<strong>246</strong></td><td>~200</td><td>~700</td><td>80% one pod</td></tr><tr><td>8.6.x</td><td>~220</td><td>~400</td><td>~960</td><td>80+% all pods</td></tr><tr><td>8.8.x</td><td>~160</td><td>~370</td><td>~700</td><td>90+% all pods</td></tr><tr><td>8.8.x (3 CPU)</td><td>~220</td><td>~<strong>90</strong></td><td>~<strong>490</strong></td><td>80% one pod</td></tr><tr><td>Main</td><td>~230</td><td>~180</td><td>~497</td><td>90+% two pods</td></tr></tbody></table>
<p>Likely reasons for the performance differences could be related to <a href="https://camunda.com/blog/2025/03/streamlined-deployment-with-camunda-8-8/" target="_blank" rel="noopener noreferrer">architectural changes</a>, like having identity part of the Camunda application, a new Camunda Exporter (doing all the work previously Importers have done), etc. Further investigation is needed to pinpoint the exact causes and potential optimizations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps">â€‹</a></h2>
<p>Based on the results above, we will continue our investigation into the performance differences between the versions. We will analyze the changes made in the architecture and codebase to identify potential bottlenecks or optimizations that could explain the observed performance variations. Likely, we will also need to examine the resource allocation and configuration settings to determine if any differences could impact performance.</p>
<p>Furthermore, we plan to explore the impact of different process designs and workloads on the system's performance.
An everyday use case for Camunda is the implementation of straight-through processes that utilize service tasks. Therefore, we designed a simple BPMN process that consists of a start event, ten service tasks, some intermediate timer catch events, and an end event. The service tasks are configured to be handled by the worker application. In one of our next experiments, we will run the same stress test with this process model to see how the system handles more complex workflows under high load.</p>
<p><img decoding="async" loading="lazy" alt="ten_tasks" src="https://camunda.github.io/zeebe-chaos/assets/images/ten_tasks-41be0d9a138341d665c9ed2999e64ad2.png" width="2244" height="1155" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="further-experiments">Further Experiments<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#further-experiments" class="hash-link" aria-label="Direct link to Further Experiments" title="Direct link to Further Experiments">â€‹</a></h2>
<blockquote>
<p>[Update: 28.11.2025]</p>
</blockquote>
<p>We conducted further experiments with 8.8 to understand, why the performance is lower compared to 8.7.x.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cpu-resources-increase">CPU Resources increase<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#cpu-resources-increase" class="hash-link" aria-label="Direct link to CPU Resources increase" title="Direct link to CPU Resources increase">â€‹</a></h3>
<p>In previous experiment we increased the CPU resources from 2 to 3 cores. To understand whether this has an impact on performance, we ran an experiment where we increased the CPU resources to 3.5 cores.</p>
<p>As noted the architecture has changed in 8.8.x to a single Camunda application. Combining several components together like Zeebe Broker, Zeebe Gateway, Operate Webapp + Importer, Tasklist Webapp + Importer, Identity. Thus it should not suprise that the resource demands have changed.</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-512mb-rocksdb" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-more-35-cpu-ee2663d0ab2792881adaf3f9acb09938.png" width="1883" height="872" class="img_ev3q"></p>
<p>With the increased CPU resources, we are able to reach the same number of processed PI/s as in 8.7.x (~248 PI/s).</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-512mb-rocksdb" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-more-35-cpu-latency-910f4be60921a2d3840ccd3c37123f30.png" width="1884" height="189" class="img_ev3q"></p>
<p>The latency of 8.8 is much better than in 8.7.x.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rocksdb-memory-settings">RocksDB memory settings<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#rocksdb-memory-settings" class="hash-link" aria-label="Direct link to RocksDB memory settings" title="Direct link to RocksDB memory settings">â€‹</a></h3>
<p>As we have mentioned above, we reduced the RocksDB memory settings in 8.8.x to 64 MB per partition (instead of previously 512MB). Therefore, we ran an experiment where we increased the RocksDB memory back to 512MB per partition. To understand whether this has an impact on performance.</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-512mb-rocksdb" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-more-rocksdb-87252625768fa418aa8b9d93b3239af9.png" width="1879" height="861" class="img_ev3q">
<img decoding="async" loading="lazy" alt="88-one-task-512mb-rocksdb" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-more-rocksdb-latency-b489746cd7fe3f0e8c893ea0fa8800c5.png" width="1883" height="189" class="img_ev3q"></p>
<p>We can see that the throughput stays, but the memory consumption is much higher (as expected).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="more-workers">More Workers<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#more-workers" class="hash-link" aria-label="Direct link to More Workers" title="Direct link to More Workers">â€‹</a></h3>
<p>I realized that in previous experiments, we only had three worker applications deployed to process the service tasks. As I used a wrong configuration. My suspicion was that this limited the performance, so I scaled them to six. I did this for 8.8.x and 8.7.x to have a fair comparison.</p>
<p><img decoding="async" loading="lazy" alt="87-workers" src="https://camunda.github.io/zeebe-chaos/assets/images/87-workers-e6f7ad341f8500876c4c1472355e7c89.png" width="1886" height="853" class="img_ev3q">
<img decoding="async" loading="lazy" alt="88-more-workers" src="https://camunda.github.io/zeebe-chaos/assets/images/87-workers-e6f7ad341f8500876c4c1472355e7c89.png" width="1886" height="853" class="img_ev3q"></p>
<p>We can see that the job activation rate has increased, but the overall throughput stays the same. Thus having more workers does not help in this scenario.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="client-load-balancing">Client Load Balancing<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#client-load-balancing" class="hash-link" aria-label="Direct link to Client Load Balancing" title="Direct link to Client Load Balancing">â€‹</a></h3>
<p>Out of curiosity, we wanted to validate the usage of <a href="https://github.com/camunda/camunda/pull/38916" target="_blank" rel="noopener noreferrer">client load balancing</a> and the impact on the system resources and performance (as this would cause better distribution of the load). This is currently a custom feature (not yet implemented e2e).</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-35-cpu-client-load-balance" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-more-35-cpu-client-load-balance-3438963ec137775589c18eb75eac5ceb.png" width="1874" height="836" class="img_ev3q"></p>
<p>This shows the best results so far. We are able to reach ~250 PI/s with low latency and great utilization of our resources. Limited CPU throttling on only one pod.</p>
<p><img decoding="async" loading="lazy" alt="88-one-task-35-cpu-client-load-balance" src="https://camunda.github.io/zeebe-chaos/assets/images/88-one-task-more-35-cpu-client-load-balance-latency-99d0e7d6d611ecad69064e8f4d200ff2.png" width="1880" height="207" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://camunda.github.io/zeebe-chaos/2025/11/27/Stress-testing-Camunda#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">â€‹</a></h3>
<p>Summarizing the further experiments, we can see that increasing the CPU resources to 3.5 cores and enabling client load balancing significantly improved the performance of 8.8.x, allowing it to reach throughput levels comparable to 8.7.x while maintaining low latency.</p>
<table><thead><tr><th>Version</th><th>Throughput (PI/s)</th><th>p50 PI execution Latency (ms)</th><th>p99 PI execution Latency (ms)</th><th>CPU Throttling</th></tr></thead><tbody><tr><td>8.7.x</td><td>~<strong>246</strong></td><td>~200</td><td>~700</td><td>80% one pod</td></tr><tr><td>8.6.x</td><td>~220</td><td>~400</td><td>~960</td><td>80+% all pods</td></tr><tr><td>8.8.x</td><td>~160</td><td>~370</td><td>~700</td><td>90+% all pods</td></tr><tr><td>8.8.x (3 CPU)</td><td>~220</td><td>~<strong>90</strong></td><td>~<strong>490</strong></td><td>80% one pod</td></tr><tr><td>Main</td><td>~230</td><td>~180</td><td>~497</td><td>90+% two pods</td></tr><tr><td>8.8.x (3.5 CPU)</td><td>~<strong>248</strong></td><td>~65</td><td>~429</td><td>~40% two pods</td></tr><tr><td>8.8.x (3.5 CPU + Client LB)</td><td>~<strong>248</strong></td><td>~64</td><td>~350</td><td>35% one pod</td></tr><tr><td>8.8.x (3.5 CPU + 512MB RocksDB)</td><td>~<strong>248</strong></td><td>~64</td><td>~418</td><td>35% two pod</td></tr></tbody></table>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="performance" term="performance"/>
        <category label="stress-testing" term="stress-testing"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Testing retention of historical PIs in Camunda 8.8]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention"/>
        <updated>2025-10-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Summary:]]></summary>
        <content type="html"><![CDATA[<p><strong>Summary:</strong></p>
<p>With Camunda 8.8, a new unified Camunda Exporter is introduced that
directly populates data records consumable by read APIs on the
secondary storage. This significantly reduces the time until eventually
consistent data becomes available on Get and Search APIs. It also removes unnecessary duplication across multiple indices due to the previous architecture.</p>
<p>This architectural change prompted us to re-run the retention tests to compare
PI retention in historical indexes under the same conditions as Camunda 8.7.</p>
<p>The historical data refers to exported data from configured exporters, such as records of completed process instances, tasks, and events that are no longer part of the active (runtime) state but are retained for analysis, auditing, or reporting.</p>
<p>The goal of this experiment is to compare the amount of
PIs that we can retain in historical data between Camunda 8.7 and 8.8 running with the same hardware.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos experiment<a href="https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos experiment" title="Direct link to Chaos experiment">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-outcomes">Expected Outcomes<a href="https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention#expected-outcomes" class="hash-link" aria-label="Direct link to Expected Outcomes" title="Direct link to Expected Outcomes">â€‹</a></h3>
<p>We expect significant retention improvements for the same hardware with the change to harmonized indexes, which reduce the duplication of similar
data.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup<a href="https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention#setup" class="hash-link" aria-label="Direct link to Setup" title="Direct link to Setup">â€‹</a></h3>
<p>The experiment consists of using a <a href="https://github.com/camunda/camunda/blob/main/load-tests/load-tester/src/main/resources/bpmn/realistic/bankCustomerComplaintDisputeHandling.bpmn" target="_blank" rel="noopener noreferrer">realistic benchmark</a> with our <a href="https://github.com/camunda/camunda-load-tests-helm" target="_blank" rel="noopener noreferrer">Camunda
load tests project</a> running on its own Kubernetes cluster. It uses a
realistic process containing a mix of BPMN symbols such as tasks, events,
and call activities, including subprocesses.</p>
<p><img decoding="async" loading="lazy" alt="realistic-process-model" src="https://camunda.github.io/zeebe-chaos/assets/images/realistic-process-model-dc97d1094284a531e649fe21335a42f0.png" width="1781" height="736" class="img_ev3q"></p>
<p>For this experiment, we used a <a href="https://docs.camunda.io/docs/components/best-practices/architecture/sizing-your-environment/#camunda-8-saas" target="_blank" rel="noopener noreferrer">base size 1x cluster</a>
consisting of the standard 3 brokers, 3 partitions, a replication factor of 3, and 3 ES pods, each with a disk size of 32GB, for a total of 96GB of storage in ES.</p>
<p>Our goal was to run the cluster at maximum sustained load until exporting slowed and backpressure appeared. We treated that point as the Elasticsearch "watermark" â€” the threshold where exporting becomes the bottleneck for the cluster. Once we reached this point, we note the disks usage, stopped creating new PIs and counted how many had been archived in the historical indices. That count represents the retention capacity for the given ES disks under maximum sustained load.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment">Experiment<a href="https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention#experiment" class="hash-link" aria-label="Direct link to Experiment" title="Direct link to Experiment">â€‹</a></h3>
<p>The experiment involved using the realistic benchmarks and maintaining a stable rate of 5 PI/s (previously determined in other experiments), waiting several hours until backpressure was observed.</p>
<p>After a few hours, backpressure began to build up, reaching single-digit percentage points. Grafana metrics confirmed that the backpressure resulted from a backlog of unexported records.</p>
<p>The experiment was conducted twice to ensure the results were consistent.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">â€‹</a></h3>
<p>The PI/s completion rate remained relatively stable, even as backpressure started to build. The rate stabilized between 4 and 5 PI/s.</p>
<p>Disk usage after backpressure began:</p>
<table><thead><tr><th></th><th>First run</th><th>Second run</th></tr></thead><tbody><tr><td>ES disk 1</td><td>74%</td><td>74%</td></tr><tr><td>ES disk 2</td><td>61%</td><td>72%</td></tr><tr><td>ES disk 3</td><td>55%</td><td>67%</td></tr><tr><td>Average</td><td>63.3%</td><td>71%</td></tr></tbody></table>
<p>Number of completed historical PI/s:</p>
<ul>
<li>First run: 223,000 PIs</li>
<li>Second run: 255,000 PIs</li>
</ul>
<p>As we approached 70% disk usage, we noticed some impact on performance resulting of backpressure from exporting.
In previous tests with version 8.7, we observed similar backpressure onset between 70% and 80% disk usage.</p>
<p>Given that backpressure can occur earlier than expected, we decided to lower the threshold for automatically increasing disk sizes in the ES PVCs in SaaS (this happens in increments of 16GB). <a href="https://github.com/camunda/camunda/issues/40168" target="_blank" rel="noopener noreferrer">This threshold was reduced from 80% to 70%</a>.</p>
<p>Moreover, when comparing these results to the <a href="https://docs.camunda.io/docs/8.7/components/best-practices/architecture/sizing-your-environment/#camunda-8-saas" target="_blank" rel="noopener noreferrer">retention with version 8.7</a>, we observed a significant improvement in retention. This enhancement is attributed to the harmonized indexes and the elimination of duplicate document storage. In version 8.7, for the base 1x cluster with identical disk sizes in ES, the retention was around 75,000 PIs in historical indices. In contrast, we achieved 223,000 and 255,000 in this experiment, representing a 218% increase or 3.18 times larger retention, based on the average of both numbers.</p>
<p>Comparing the retention numbers of both versions we get:</p>
<table><thead><tr><th>Cluster size</th><th>1x</th><th>2x</th><th>3x</th><th>4x</th></tr></thead><tbody><tr><td>Camunda 8.7</td><td>75k</td><td>150k</td><td>225k</td><td>300k</td></tr><tr><td>Camunda 8.8</td><td>239k</td><td>478k</td><td>717k</td><td>956k</td></tr></tbody></table>
<p>Following these results, we updated the retention values in version 8.8. This was done conservatively (we rounded down to 200k for the base configuration), considering the high variability of process models. The intention is to provide a general representation of an average process, establishing standard metrics for performance comparison across Camunda versions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="participants">Participants<a href="https://camunda.github.io/zeebe-chaos/2025/10/31/Improvents-in-retention#participants" class="hash-link" aria-label="Direct link to Participants" title="Direct link to Participants">â€‹</a></h2>
<ul>
<li>@rodrigo</li>
</ul>]]></content>
        <author>
            <name>Rodrigo Lopes</name>
            <uri>https://github.com/rodrigo-lourenco-lopes</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resilience of dynamic scaling]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience"/>
        <updated>2025-10-02T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[With version 8.8, we introduced the ability to add new partitions to an existing Camunda cluster. This experiment aimed to evaluate the resilience of the scaling process under disruptive conditions.]]></summary>
        <content type="html"><![CDATA[<p>With version 8.8, we introduced the ability to add new partitions to an existing Camunda cluster. This experiment aimed to evaluate the resilience of the scaling process under disruptive conditions.</p>
<p><strong>Summary:</strong></p>
<ul>
<li>Several bugs were identified during testing.</li>
<li>After addressing these issues, scaling succeeded even when multiple nodes were restarted during the operation.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos experiment<a href="https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos experiment" title="Direct link to Chaos experiment">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>The scaling operation should complete successfully, even if multiple nodes are restarted during the process.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup<a href="https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience#setup" class="hash-link" aria-label="Direct link to Setup" title="Direct link to Setup">â€‹</a></h3>
<p>We initialized a cluster with the following configuration:</p>
<ul>
<li><code>clusterSize = 3</code></li>
<li><code>partitionCount = 3</code></li>
<li><code>replicationFactor = 3</code></li>
</ul>
<p>The cluster is running with a steady throughput of completing 150 jobs/s.</p>
<p>The target configuration was:</p>
<ul>
<li><code>clusterSize = 6</code></li>
<li><code>partitionCount = 6</code></li>
<li><code>replicationFactor = 3</code></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment">Experiment<a href="https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience#experiment" class="hash-link" aria-label="Direct link to Experiment" title="Direct link to Experiment">â€‹</a></h3>
<p>We first started new brokers using:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl scale statefulset &lt;zeebe-statefulset&gt; --replicas=6</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Next, we triggered the scaling operation via Camunda's management API:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl -X 'PATCH' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    'http://localhost:9600/actuator/cluster' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -H 'accept: application/json' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -H 'Content-Type: application/json' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "brokers": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             "add": [3,4,5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "partitions": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             "count": 6,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             "replicationFactor": 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Once the API request succeeded and scaling began, we started restarting pods one at a time using <code>kubectl delete pod &lt;zeebe-n&gt;</code>, choosing pods in random order. Each pod was restarted multiple times throughout the experiment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">â€‹</a></h3>
<p>During the initial run, scaling stalled at a specific step. The cluster status showed that bootstrapping partition 6 was not progressing:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">  "pendingChange": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     "id": 2,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     "status": "IN_PROGRESS",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     "completed": [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     "pending": [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "operation": "PARTITION_BOOTSTRAP",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "brokerId": 5,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "partitionId": 6,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "priority": 3,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "brokers": []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Investigation uncovered a <a href="https://github.com/camunda/camunda/issues/37495" target="_blank" rel="noopener noreferrer">bug</a>. After fixing it, we repeated the experiment.</p>
<p>In the second attempt, we observed that after bootstrapping a new partition, <a href="https://github.com/camunda/camunda/issues/37892" target="_blank" rel="noopener noreferrer">adding a second replica to that partition became stuck</a>. This revealed an unhandled edge case in the Raft join protocol. Since manual pod restarts are non-deterministic, reproducing this issue was challenging. To address this, we incorporated the scenario into our <a href="https://camunda.com/blog/2022/12/bulletproofing-zeebe-concurrency-bugs/" target="_blank" rel="noopener noreferrer">randomized Raft test</a>, which exposed additional edge cases that could block the join operation. These were subsequently fixed. Thanks to the improved test coverage, we are now confident that these issues have been resolved.</p>
<p>After applying the fixes, we reran the experiment. <!-- -->ðŸŽ‰<!-- --> This time, scaling completed successfully, even with repeated node restarts.</p>
<p>The scaling began at 11:35, with node restarts occurring during the operation.</p>
<p><img decoding="async" loading="lazy" alt="Pod restarts during scaling" src="https://camunda.github.io/zeebe-chaos/assets/images/pod-restarts-871d06a82db7ab88852b744070313189.png" width="472" height="212" class="img_ev3q"></p>
<p>Throughput was severely impacted by the muliple restarts of the brokers at the same time.</p>
<p><img decoding="async" loading="lazy" alt="Throughput affected due to restarts" src="https://camunda.github.io/zeebe-chaos/assets/images/throughput-1af6b6c027ea9083cc48056239afb47f.png" width="805" height="205" class="img_ev3q"></p>
<p>But the scaling process still completed within 15 minutes.</p>
<p><img decoding="async" loading="lazy" alt="scaling" src="https://camunda.github.io/zeebe-chaos/assets/images/scaling-259748a3b525dec19b762c9e2c4a0cb3.png" width="805" height="278" class="img_ev3q"></p>
<p>The cluster status query shows the last completed scaling operation.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">"lastChange": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "id": 2,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "status": "COMPLETED",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "startedAt": "2025-10-02T11:35:59.852+0000",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "completedAt": "2025-10-02T11:49:32.796+0000"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>While the operation would have finished faster without node failures, the key takeaway is that it remained resilient in the face of disruptions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="participants">Participants<a href="https://camunda.github.io/zeebe-chaos/2025/10/02/Dynamic-Scaling-Resilience#participants" class="hash-link" aria-label="Direct link to Participants" title="Direct link to Participants">â€‹</a></h2>
<ul>
<li>@deepthi</li>
</ul>]]></content>
        <author>
            <name>Deepthi Akkoorath</name>
            <uri>https://github.com/deepthidevaki</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[REST API: From ForkJoin to a Dedicated Thread Pool]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool"/>
        <updated>2025-09-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[During the latest REST API Performance load tests,]]></summary>
        <content type="html"><![CDATA[<p>During the latest <a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance" target="_blank" rel="noopener noreferrer">REST API Performance load tests</a>,
we discovered that REST API requests suffered from significantly higher latency under CPU pressure, even when throughput numbers looked comparable.
While adding more CPU cores alleviated the issue, this wasnâ€™t a sustainable solution â€” it hinted at an inefficiency in how REST handled broker responses.
See related <a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#request-handling-execution-logic" target="_blank" rel="noopener noreferrer">section</a> from the previous blog post.</p>
<p>This blog post is about how we diagnosed the issue, what we found, and the fix we introduced in <a href="https://github.com/camunda/camunda/pull/36517" target="_blank" rel="noopener noreferrer">PR #36517</a>
to close the performance gap.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-problem">The Problem<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#the-problem" class="hash-link" aria-label="Direct link to The Problem" title="Direct link to The Problem">â€‹</a></h2>
<p>A difference we spotted early between <strong>REST API</strong> and <strong>gRPC</strong> request handling was the usage of the <code>BrokerClient</code>:</p>
<ul>
<li><strong>gRPC:</strong> <code>BrokerClient</code> calls are wrapped with retries and handled directly in the request thread.</li>
<li><strong>REST:</strong> requests are executed without retries, and responses are handled asynchronously using the common <code>ForkJoinPool</code>.</li>
</ul>
<p>On clusters with 2 CPUs, the JVM defaults to a single thread for the common <code>ForkJoinPool</code>.
Our expectation was that this could cause contention: one thread might not be fast enough to process responses in time, leading to delays in the Gateway â†” Broker request-response cycle.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-solution-journey">The Solution Journey<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#the-solution-journey" class="hash-link" aria-label="Direct link to The Solution Journey" title="Direct link to The Solution Journey">â€‹</a></h2>
<p>Solving this issue wasnâ€™t a straight line â€” we tried a few approaches before landing on the final design.
Each iteration gave us valuable insights about Javaâ€™s thread pool usage and its impact on REST API performance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-first-attempt-synchronousqueue">1. First Attempt: SynchronousQueue<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#1-first-attempt-synchronousqueue" class="hash-link" aria-label="Direct link to 1. First Attempt: SynchronousQueue" title="Direct link to 1. First Attempt: SynchronousQueue">â€‹</a></h3>
<p>We began with a custom <code>ThreadPoolExecutor</code> that used a <code>SynchronousQueue</code> for task handoff:</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">new ThreadPoolExecutor(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    corePoolSize,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    maxPoolSize,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    keepAliveSeconds,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    TimeUnit.SECONDS,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    new SynchronousQueue&lt;&gt;(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    threadFactory,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    new ThreadPoolExecutor.CallerRunsPolicy());</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>A <code>SynchronousQueue</code> has <strong>no capacity</strong> â€” each task submission must immediately find a free worker thread.
If no thread is available, the caller blocks until one frees up.</p>
<p>In practice, this meant concurrency was <strong>artificially limited</strong>: bursts of REST requests had to wait for a thread to become available, reducing parallelism.
The results were modest:</p>
<ul>
<li><strong>Request rate:</strong> unchanged</li>
<li><strong>Average latency:</strong> improved slightly (from ~120 ms â†’ ~100 ms)</li>
<li><strong>CPU throttling:</strong> dropped only marginally (100% â†’ 90%)</li>
</ul>
<p>Before any changes introduced, results looked like this:
<img decoding="async" loading="lazy" alt="syncqueue-req-before" src="https://camunda.github.io/zeebe-chaos/assets/images/syncqueue-req-before-8d25531fa8c311440fa9c8e80e78d1e5.png" width="1052" height="1210" class="img_ev3q">
<img decoding="async" loading="lazy" alt="syncqueue-cpu-before" src="https://camunda.github.io/zeebe-chaos/assets/images/syncqueue-cpu-before-221093fdaa3aa155857222a6feec4e88.png" width="2112" height="674" class="img_ev3q"></p>
<p>Then we started benchmarking after introducing executor with <code>SynchronousQueue</code>:
<img decoding="async" loading="lazy" alt="syncqueue-req-after" src="https://camunda.github.io/zeebe-chaos/assets/images/syncqueue-req-after-172469b801a0b97b731b4b27ba44eedf.png" width="1050" height="1218" class="img_ev3q">
<img decoding="async" loading="lazy" alt="syncqueue-cpu-after" src="https://camunda.github.io/zeebe-chaos/assets/images/syncqueue-cpu-after-b2902d1db04dba87750b03e9dae1673f.png" width="2098" height="684" class="img_ev3q"></p>
<p>This hinted we were on the right track â€” a dedicated executor helped â€” but the queue strategy was too restrictive.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-experiment-arrayblockingqueue--abortpolicy">2. Experiment: ArrayBlockingQueue + AbortPolicy<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#2-experiment-arrayblockingqueue--abortpolicy" class="hash-link" aria-label="Direct link to 2. Experiment: ArrayBlockingQueue + AbortPolicy" title="Direct link to 2. Experiment: ArrayBlockingQueue + AbortPolicy">â€‹</a></h3>
<p>Next, we switched to an <code>ArrayBlockingQueue</code> with a capacity of 64.
This allowed the pool to <strong>buffer short micro-bursts</strong> of requests instead of blocking immediately.
At the same time, we replaced <code>CallerRunsPolicy</code> with <code>AbortPolicy</code>:</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">new ThreadPoolExecutor.AbortPolicy();</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The idea was to <strong>fail fast</strong> on saturation: if the queue filled up and no thread was free, the executor would throw <code>RejectedExecutionException</code> immediately.
This boosted the measured request rate, but at a cost:</p>
<ul>
<li>Many requests were simply rejected outright.</li>
<li>Measuring true performance became tricky, since high throughput numbers hid the rejections.</li>
<li>Operationally, this wasnâ€™t acceptable â€” REST clients would constantly see errors under load.</li>
</ul>
<p>Because of this, we abandoned the fail-fast approach.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-final-decision-callerrunspolicy--higher-max-pool-size">3. Final Decision: CallerRunsPolicy + Higher Max Pool Size<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#3-final-decision-callerrunspolicy--higher-max-pool-size" class="hash-link" aria-label="Direct link to 3. Final Decision: CallerRunsPolicy + Higher Max Pool Size" title="Direct link to 3. Final Decision: CallerRunsPolicy + Higher Max Pool Size">â€‹</a></h3>
<p>Finally, we returned to <code>CallerRunsPolicy</code>.
Instead of rejecting tasks, this policy makes the caller thread execute the task itself when the pool is saturated.
This introduces <strong>natural backpressure</strong>: clients slow down automatically when the system is busy, without dropping requests.</p>
<p>To give the executor more headroom, we also increased the maximum pool size from <code>availableProcessors * 2</code> to <code>availableProcessors * 8</code>.</p>
<p>This combination made the breakthrough:</p>
<ul>
<li><strong>Request rate (REST):</strong> stabilized around 150 RPS with spikes up to 200 RPS</li>
<li><strong>Average latency:</strong> dropped dramatically (from ~120 ms â†’ ~25 ms)</li>
<li><strong>CPU throttling:</strong> reduced significantly (100% â†’ 30-40%)</li>
</ul>
<p>Here are the final results:
<img decoding="async" loading="lazy" alt="final-decision-result-rest" src="https://camunda.github.io/zeebe-chaos/assets/images/final-decision-result-rest-f324c1eef2158ab2f20dd5d688a4e89f.png" width="2338" height="1202" class="img_ev3q">
<img decoding="async" loading="lazy" alt="final-decision-result-cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/final-decision-result-cpu-c579720539ebcb00496de95c9120dc49.png" width="2332" height="672" class="img_ev3q"></p>
<p>This design struck the right balance: elastic concurrency, backpressure, and resource efficiency.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways">â€‹</a></h3>
<ol>
<li><strong>SynchronousQueue limits concurrency</strong> â€” good for handoff semantics, but too restrictive for REST workloads.</li>
<li><strong>Fail-fast rejection looks good in benchmarks but fails in production</strong> â€” clients canâ€™t handle widespread request errors.</li>
<li><strong>CallerRunsPolicy provides natural backpressure</strong> â€” throughput stabilizes without dropping requests, and latency improves.</li>
<li><strong>CPU-aware max pool sizing matters</strong> â€” scaling pool size relative to cores unlocks performance gains.</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="more-benchmarking">More Benchmarking<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#more-benchmarking" class="hash-link" aria-label="Direct link to More Benchmarking" title="Direct link to More Benchmarking">â€‹</a></h2>
<p>To validate that our executor change holds up across configurations, we ran extra tests on our benchmark cluster provisioned with 2 vCPUs per Camunda application.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-comparing-max-pool-size-4-8-16">1) Comparing Max Pool Size (Ã—4, Ã—8, Ã—16)<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#1-comparing-max-pool-size-4-8-16" class="hash-link" aria-label="Direct link to 1) Comparing Max Pool Size (Ã—4, Ã—8, Ã—16)" title="Direct link to 1) Comparing Max Pool Size (Ã—4, Ã—8, Ã—16)">â€‹</a></h3>
<p>We ran the same workload while varying <code>maxPoolSize = availableProcessors Ã— {4, 8, 16}</code>. Below are the observed tops from Grafana panels in the screenshots:</p>
<p><code>maxPoolSizeMultiplier=4</code>
<img decoding="async" loading="lazy" alt="max-pool-size-multiplier-4" src="https://camunda.github.io/zeebe-chaos/assets/images/max-pool-size-multiplier-4-61b29561f085e4079b30f5de0552bab5.png" width="2316" height="1212" class="img_ev3q"></p>
<p><code>maxPoolSizeMultiplier=8</code>
<img decoding="async" loading="lazy" alt="max-pool-size-multiplier-8" src="https://camunda.github.io/zeebe-chaos/assets/images/max-pool-size-multiplier-8-f324c1eef2158ab2f20dd5d688a4e89f.png" width="2338" height="1202" class="img_ev3q"></p>
<p><code>maxPoolSizeMultiplier=16</code>
<img decoding="async" loading="lazy" alt="max-pool-size-multiplier-16" src="https://camunda.github.io/zeebe-chaos/assets/images/max-pool-size-multiplier-16-e1011e424e35c3178f468ef5bcc4656a.png" width="2332" height="1204" class="img_ev3q"></p>
<table><thead><tr><th style="text-align:right">Multiplier</th><th style="text-align:right">Request Rate (proc-instances)</th><th style="text-align:right">Request Rate (completion)</th><th style="text-align:right">Avg Latency (proc-instances)</th><th style="text-align:right">Avg Latency (completion)</th></tr></thead><tbody><tr><td style="text-align:right">Ã—4</td><td style="text-align:right">~51.6 req/s</td><td style="text-align:right">~42.3 req/s</td><td style="text-align:right">~40.2 ms</td><td style="text-align:right">~57.4 ms</td></tr><tr><td style="text-align:right">Ã—8</td><td style="text-align:right">~144.4 req/s</td><td style="text-align:right">~144.7 req/s</td><td style="text-align:right">~21.4 ms</td><td style="text-align:right">~24.1 ms</td></tr><tr><td style="text-align:right">Ã—16</td><td style="text-align:right">~22.7 req/s</td><td style="text-align:right">~19.5 req/s</td><td style="text-align:right">~38.4 ms</td><td style="text-align:right">~55.4 ms</td></tr></tbody></table>
<p><strong>What this suggests (in our setup):</strong></p>
<ul>
<li><strong>Ã—8</strong> is the clear <strong>sweet spot</strong>: highest sustained throughput with the lowest average latencies.</li>
<li><strong>Ã—4</strong> under-provisions the pool (lower RPS, higher latency).</li>
<li><strong>Ã—16</strong> shows <strong>diminishing/negative returns</strong> (likely scheduler contention or oversubscription): much lower RPS and latencies drifting back up.</li>
</ul>
<p><strong>Takeaway:</strong> In our setup, Ã—8 balances elasticity and scheduling overhead, delivering the best throughputâ€“latency trade-off.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-comparing-queue-capacity-16-vs-64-vs-256">3) Comparing Queue Capacity (16 vs 64 vs 256)<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#3-comparing-queue-capacity-16-vs-64-vs-256" class="hash-link" aria-label="Direct link to 3) Comparing Queue Capacity (16 vs 64 vs 256)" title="Direct link to 3) Comparing Queue Capacity (16 vs 64 vs 256)">â€‹</a></h3>
<p>We varied the executor <strong>queue capacity</strong> and compared <strong>16</strong>, <strong>64</strong> (our current/default for this run), and <strong>256</strong> under the same workload.<br>
<!-- -->Below are the observed tops from the Grafana panels for the two hot endpoints:</p>
<ul>
<li>POST /v2/process-instances</li>
<li>POST /v2/jobs/{jobKey}/completion</li>
</ul>
<p><code>queueCapacity=16</code><br>
<img decoding="async" loading="lazy" alt="queue-capacity-16" src="https://camunda.github.io/zeebe-chaos/assets/images/queue-capacity-16-516379e4fce7362827be0d3ad957e7dc.png" width="2338" height="1208" class="img_ev3q"></p>
<p><code>queueCapacity=64</code><br>
<img decoding="async" loading="lazy" alt="queue-capacity-64" src="https://camunda.github.io/zeebe-chaos/assets/images/queue-capacity-64-f324c1eef2158ab2f20dd5d688a4e89f.png" width="2338" height="1202" class="img_ev3q"></p>
<p><code>queueCapacity=256</code><br>
<img decoding="async" loading="lazy" alt="queue-capacity-256" src="https://camunda.github.io/zeebe-chaos/assets/images/queue-capacity-256-19acdd7b6ca1df00ccaefb20fae5ce41.png" width="2338" height="1216" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="measured-summary">Measured summary<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#measured-summary" class="hash-link" aria-label="Direct link to Measured summary" title="Direct link to Measured summary">â€‹</a></h4>
<table><thead><tr><th style="text-align:right">Queue Capacity</th><th style="text-align:right">Request Rate (proc-instances)</th><th style="text-align:right">Request Rate (completion)</th><th style="text-align:right">Avg Latency (proc-instances)</th><th style="text-align:right">Avg Latency (completion)</th></tr></thead><tbody><tr><td style="text-align:right">16</td><td style="text-align:right">~78.2 req/s</td><td style="text-align:right">~56.0 req/s</td><td style="text-align:right">~28.2 ms</td><td style="text-align:right">~40.8 ms</td></tr><tr><td style="text-align:right">64</td><td style="text-align:right">~144.4 req/s</td><td style="text-align:right">~144.7 req/s</td><td style="text-align:right">~21.4 ms</td><td style="text-align:right">~24.1 ms</td></tr><tr><td style="text-align:right">256</td><td style="text-align:right">~80.2 req/s</td><td style="text-align:right">~61.2 req/s</td><td style="text-align:right">~29.3 ms</td><td style="text-align:right">~43.0 ms</td></tr></tbody></table>
<p><strong>What this suggests (in our setup):</strong></p>
<ul>
<li><strong>Queue = 64</strong> is the clear <strong>sweet spot</strong>: highest sustained throughput (~144 req/s on hot endpoints) with the lowest avg latencies (~21â€“24 ms). Likely large enough to absorb micro-bursts, but small enough to avoid long queue waits.</li>
<li><strong>Queue = 16</strong> under-buffers: lower RPS (~78 / ~56 req/s) and higher latency (~28â€“41 ms). With <code>CallerRunsPolicy</code>, the queue fills quickly and the caller runs tasks often â†’ frequent backpressure throttles producers.</li>
<li><strong>Queue = 256</strong> shows <strong>diminishing/negative returns</strong> relative to 64: lower RPS (~80 / ~61 req/s) and higher latency (~29â€“43 ms). The big buffer hides saturation, adding queueing delay before execution without delivering extra useful work at the same CPU budget.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://camunda.github.io/zeebe-chaos/2025/09/18/REST-API-From-ForkJoin-to-a-Dedicated-Thread-Pool#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>Moving off the common <code>ForkJoinPool</code> to a dedicated, CPU-aware executor with bounded queueing and <code>CallerRunsPolicy</code> backpressure turned an overload problem into graceful degradation: fewer 5xxs, steadier RPS, and far lower tail latency under the same CPU budget.</p>
<p><strong>Final takeaways</strong></p>
<ul>
<li><strong>Isolation beats sharing.</strong> A dedicated pool prevents noisy neighbors from the common <code>ForkJoinPool</code>.</li>
<li><strong>Backpressure beats drops.</strong> <code>CallerRunsPolicy</code> slows producers when saturated, stabilizing the system without mass rejections.</li>
<li><strong>Right-sized knobs matter.</strong> <code>maxPoolSize â‰ˆ cores Ã— 8</code> and <code>queueCapacity â‰ˆ 64</code> hit the best throughput/latency balance in our runs; smaller queues over-throttle, larger queues hide saturation and add wait time.</li>
<li><strong>Results are environment-specific.</strong> At higher core counts, the sweet spot may shiftâ€”re-benchmark when CPUs or workload mix change.</li>
</ul>
<p><strong>Note:</strong> Results are environment-specific; at higher core counts, the sweet spot may shiftâ€”re-benchmark when CPUs or workload mix change.
In this experiment, we focused on CPU-bound scenarios.</p>]]></content>
        <author>
            <name>Berkay Can</name>
            <uri>https://github.com/berkaycanbc</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resiliency against ELS unavailability]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability"/>
        <updated>2025-08-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Due to recent initiatives and architecture changes, we coupled us even more against the secondary storage (often Elasticsearch, but can also be OpenSearch or in the future RDBMS).]]></summary>
        <content type="html"><![CDATA[<p>Due to recent initiatives and architecture changes, we coupled us even more against the secondary storage (often Elasticsearch, but can also be OpenSearch or in the future RDBMS).</p>
<p>We now have one single application to run Webapps, Gateway, Broker, Exporters, etc., together. Including the new Camunda Exporter exporting all necessary data to the secondary storage. On bootstrap we need to create an expected schema, so our components work as expected, allowing Operate and Tasklist Web apps to consume the data and the exporter to export correctly. Furthermore, we have a new query API (REST API) allowing the search for available data in the secondary storage.</p>
<p>We have seen in previous experiments and load tests that unavailable ELS and not properly configured replicas can cause issues like the exporter not catching up or queries not succeeding. See related <a href="https://github.com/camunda/camunda/issues/35080" target="_blank" rel="noopener noreferrer">GitHub issue</a>.</p>
<p>In todays chaos day, we want to play around with the replicas setting of the indices, which can be set in the Camunda Exporter (which is in charge of writing the data to the secondary storage).</p>
<p><strong>TL;DR;</strong> Without the index replicas set, the Camunda Exporter is directly impacted by ELS node restarts. The query API seem to handle this transparently, but changing the resulting data. Having the replicas set will cause some performance impact, as the ELS node might run into CPU throttling (as they have much more to do). ELS slowing down has an impact on processing as well due to our write throttling mechanics. This means we need to be careful with this setting, while it gives us better availability (CamundaExporter can continue when ELS nodes restart), it might come with some cost.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>In the following, we want to experiment with the following:</p>
<ol>
<li>We restart the first Elasticsearch node and observe how the CamundaExporter performs.</li>
<li>We restart the Elasticsearch node that is primary for a certain index, and use the query API.</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>With the index replica set to more than zero in the Camunda Exporter, the Exporter and Query API should be able to work properly even if one ELS node goes down. In our base set up we expect it to fail.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We will set up a base load test, having the default configuration, and some increasing the replicas to compare with.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">â€‹</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="set-up">Set up<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#set-up" class="hash-link" aria-label="Direct link to Set up" title="Direct link to Set up">â€‹</a></h5>
<p>Creating the default load test by simply running our <a href="https://github.com/camunda/camunda/actions/workflows/zeebe-benchmark.yml" target="_blank" rel="noopener noreferrer">benchmark GitHub action</a>. By default, the load tests install Elasticsearch with three nodes.</p>
<p><img decoding="async" loading="lazy" alt="base-es" src="https://camunda.github.io/zeebe-chaos/assets/images/base-indices-fb488f288f5b3b11d2b92929a04216c2.png" width="1889" height="512" class="img_ev3q"></p>
<p>We can see that the indices have only one primary shard, but no replication.</p>
<p>The system is working as expected with the normal load.</p>
<p><img decoding="async" loading="lazy" alt="base" src="https://camunda.github.io/zeebe-chaos/assets/images/base-ed163f3cbe7cffc95bc08f46dc5b83d9.png" width="1898" height="759" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="restart-first-node">Restart first node<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#restart-first-node" class="hash-link" aria-label="Direct link to Restart first node" title="Direct link to Restart first node">â€‹</a></h5>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod elastic-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "elastic-0" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>As soon as the Elasticsearch pod was restarted, the cluster reacted with backpressure. The decrease of exporting was detected, causing to throttle the writing. We can see the cluster load metric, which spiked. Having a direct impact of the processing performance.</p>
<p><img decoding="async" loading="lazy" alt="base-restart" src="https://camunda.github.io/zeebe-chaos/assets/images/base-es-restart-ad2897e5b77f38f2307906ef0f72f28e.png" width="1865" height="925" class="img_ev3q"></p>
<p>As soon as the Elasticsearch pod recovers and comes back the cluster and processing can recover as well.</p>
<p><img decoding="async" loading="lazy" alt="base-recover" src="https://camunda.github.io/zeebe-chaos/assets/images/base-recover-54ceaa944fb473bb3856ba21aca7604b.png" width="1882" height="768" class="img_ev3q"></p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="restart-primary">Restart primary<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#restart-primary" class="hash-link" aria-label="Direct link to Restart primary" title="Direct link to Restart primary">â€‹</a></h6>
<p>Looking at the nodes and the index distributions, we can, for example, see that Node 1 is the primary of the flow node instance index.</p>
<p><img decoding="async" loading="lazy" alt="base-primary" src="https://camunda.github.io/zeebe-chaos/assets/images/base-primary-node-236505e9bb3fc5fbf7b322ef319ab880.png" width="1892" height="572" class="img_ev3q"></p>
<p><strong>Querying for flownode instances:</strong></p>
<p>First, we have to port-forward to our Camunda instance.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">k port-forward svc/camunda 8080</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Forwarding from 127.0.0.1:8080 -&gt; 8080</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Forwarding from [::1]:8080 -&gt; 8080</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Search flow node instances following the <a href="https://docs.camunda.io/docs/next/apis-tools/operate-api/specifications/search-4/" target="_blank" rel="noopener noreferrer">documentation </a>, we can copy the cURL command (removing the Authorization header as we don't need it with our current installation):</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> curl -L 'http://localhost:8080/v1/flownode-instances/search' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      -H 'Content-Type: application/json' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      -H 'Accept: application/json' \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "filter": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "key": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "processInstanceKey": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "processDefinitionKey": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "startDate": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "endDate": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "flowNodeId": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "flowNodeName": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "incidentKey": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "type": "UNSPECIFIED",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "state": "ACTIVE",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "incident": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tenantId": "string"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "searchAfter": [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "sort": [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "field": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "order": "ASC"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"status":400,"message":"Sort has invalid field(s): string","instance":"f5ddf702-7ad6-4a05-af9a-9112f2436706","type":"Data invalid"}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Seems to cause some issues with the sorting. Removing this and setting the size to 1 (as this was another failure returned), we run into:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "filter": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "key": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "processInstanceKey": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "processDefinitionKey": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "startDate": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "endDate": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "flowNodeId": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "flowNodeName": "string",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "incidentKey": 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "type": "UNSPECIFIED",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "state": "ACTIVE",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "incident": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tenantId": "string"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1 </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"status":500,"message":"Error in reading flownode instances","instance":"a50c501e-161c-42fb-bac1-dc71416580d7","type":"API application error"}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Not clear what the issue is. Removing the filters and just setting size, returns us something.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"items":[{"key":2251799817981066,"processInstanceKey":2251799817981049,"processDefinitionKey":2251799813685298,"startDate":"2025-08-26T12:13:23.156+0000","endDate":"2025-08-26T12:13:23.156+0000","flowNodeId":"start","flowNodeName":"start","type":"START_EVENT","state":"COMPLETED","incident":false,"tenantId":"&lt;default&gt;"}],"sortValues":[2251799817981066],"total":10000}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now going ahead and restarting Elasticsearch node 1.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod elastic-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "elastic-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"items":[{"key":2251799817981066,"processInstanceKey":2251799817981049,"processDefinitionKey":2251799813685298,"startDate":"2025-08-26T12:13:23.156+0000","endDate":"2025-08-26T12:13:23.156+0000","flowNodeId":"start","flowNodeName":"start","type":"START_EVENT","state":"COMPLETED","incident":false,"tenantId":"&lt;default&gt;"}],"sortValues":[2251799817981066],"total":10000}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The restart seem to be rather quick and had no real impact on the query API. Checking the primary distribution again, we realized that actually <code>elastic-2</code> is the primary of the historic indices.</p>
<p><img decoding="async" loading="lazy" alt="real-primary" src="https://camunda.github.io/zeebe-chaos/assets/images/base-real-primary-a8803e45780a06090f24bfb10bf0ae26.png" width="1861" height="447" class="img_ev3q"></p>
<p>Doing it again, we can also observe that the historic index is unassinged at this time.</p>
<p><img decoding="async" loading="lazy" alt="base-unassigned" src="https://camunda.github.io/zeebe-chaos/assets/images/base-unassigned-77da751ad273ae1199740eda922d5374.png" width="1365" height="527" class="img_ev3q"></p>
<p>Interestingly, is that we are not seeing any error from the query API. We still return some data.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"items":[{"key":2251799818189380,"processInstanceKey":2251799818189363,"processDefinitionKey":2251799813685298,"startDate":"2025-08-26T12:16:09.754+0000","endDate":"2025-08-26T12:16:09.754+0000","flowNodeId":"start","flowNodeName":"start","type":"START_EVENT","state":"COMPLETED","incident":false,"tenantId":"&lt;default&gt;"}],"sortValues":[2251799818189380],"total":10000}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To better understand this, we introduce some sorting based on the key.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1, "sort": [ { "field": "key" } ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"items":[{"key":2251799817981066,"processInstanceKey":2251799817981049,"processDefinitionKey":2251799813685298,"startDate":"2025-08-26T12:13:23.156+0000","endDate":"2025-08-26T12:13:23.156+0000","flowNodeId":"start","flowNodeName":"start","type":"START_EVENT","state":"COMPLETED","incident":false,"tenantId":"&lt;default&gt;"}],"sortValues":[2251799817981066,2251799817981066],"total":10000}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We can see the returned FNI has the key <code>2251799817981066</code>. If we now remove the primary of the historic indices (elastic-2).</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> k delete pod elastic-2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "elastic-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa (No connection:-) ~/(main)]$ curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1, "sort": [ { "field": "key" } ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"items":[{"key":2251799818301951,"processInstanceKey":2251799818301934,"processDefinitionKey":2251799813685298,"startDate":"2025-08-26T12:18:43.362+0000","endDate":"2025-08-26T12:18:43.362+0000","flowNodeId":"start","flowNodeName":"start","type":"START_EVENT","state":"COMPLETED","incident":false,"tenantId":"&lt;default&gt;"}],"sortValues":[2251799818301951,2251799818301951],"total":9916}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We retrieve <code>2251799818301951</code> which is likely in the runtime index, an instance that haven't been archived yet.</p>
<p>The Query API is handling the Elasticsearch availability transparently, by returning different results (likely this depends on the filter criteria). Something we (and users) should be aware.</p>
<p>Just for the sake of completeness, I tested with restarting <code>elastic-1</code> and <code>elastic-2</code> and run the same query.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod elastic-2 elastic-1 &amp;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[1] 201244</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "elastic-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "elastic-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1, "sort": [ { "field": "key" } ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"status":500,"message":"Error in reading flownode instances","instance":"1fa0c323-082f-4a9f-99d1-01208ecccbd5","type":"API application error"}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The error handling should be improved to better indicate the current issue.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="one-replica">One replica<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#one-replica" class="hash-link" aria-label="Direct link to One replica" title="Direct link to One replica">â€‹</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="set-up-1">Set up<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#set-up-1" class="hash-link" aria-label="Direct link to Set up" title="Direct link to Set up">â€‹</a></h5>
<p>Setting: <code>--set zeebe.config.zeebe.broker.exporters.CamundaExporter.args.index.numberOfReplicas=1</code> should allow us to configure the CamundaExporter to create indices with one replica (instead of zero as per default).</p>
<p>Deploying a configmap with:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">   zeebe:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      broker:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        exporters:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          CamundaExporter:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            args:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              index:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                numberOfReplicas: 1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This seems to have no affect.</p>
<p><img decoding="async" loading="lazy" alt="index-no-replica" src="https://camunda.github.io/zeebe-chaos/assets/images/index-no-replica-5873c8adb1df0ede02e6b3077177e75b.png" width="1615" height="373" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="index-template-no-replica" src="https://camunda.github.io/zeebe-chaos/assets/images/index-template-no-replica-c532ee73879d60f5d0606ad5a775eea4.png" width="716" height="503" class="img_ev3q"></p>
<p>The reason is that the config has been moved to: <code>camunda.database.index.numberOfReplicas</code> (in the current SNAPSHOT). After changing the configuration (and restarting the pods), the indices settings are updated.</p>
<p><img decoding="async" loading="lazy" alt="replicas" src="https://camunda.github.io/zeebe-chaos/assets/images/replicas-aa3d363cf1f342d90d903cc4191b3f1e.png" width="1750" height="738" class="img_ev3q"></p>
<p>Generally, the performance of the cluster seem to be highly affected.</p>
<p><img decoding="async" loading="lazy" alt="one-replica-general" src="https://camunda.github.io/zeebe-chaos/assets/images/one-replica-general-c770f4309d357321f892db752892f549.png" width="1865" height="775" class="img_ev3q"></p>
<p>Looking at the CPU usage, we can see the Elasticsearch CPU went from around 1 core to almost 2. The throttling is around 60%, which likely impacts the performance a lot.</p>
<p><img decoding="async" loading="lazy" alt="cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/one-replica-cpu-52f7a96748e7a13040ffa776ce93d1ae.png" width="1883" height="690" class="img_ev3q"></p>
<p>In comparison to the base.</p>
<p><img decoding="async" loading="lazy" alt="base-cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/base-cpu-e9471092c25276fa5f003225ca538ef8.png" width="1884" height="690" class="img_ev3q"></p>
<p>I think in general it is not suprising, as the ES nodes need to do more (replicating), but something we should be aware of when rolling it out.</p>
<p>This means enabling the replicas can highly impact the system performance, and likely need some resource adjustments (not only disk space).</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="restart-first-node-1">Restart first node<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#restart-first-node-1" class="hash-link" aria-label="Direct link to Restart first node" title="Direct link to Restart first node">â€‹</a></h5>
<p>Even though the performance is already impacted, we should see less impact when restarting the first node, so we will continue with the experimentation for now.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod elastic-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "elastic-0" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="one-replica-impact" src="https://camunda.github.io/zeebe-chaos/assets/images/one-replica-impact-c19aa064cc4536e3207e757643e8bac8.png" width="1874" height="764" class="img_ev3q"></p>
<p>When restarting the first node, we can see that "only" one partition seems to be affected. But due to the limit of resources on the nodes and already existing CPU throttling, this also impacts other nodes. Causing our cluster load going up, and backpressure in consequence.</p>
<p>Compared to the base, we still can see some difference, as it was before it impacted all partitions.</p>
<p><img decoding="async" loading="lazy" alt="base-impact" src="https://camunda.github.io/zeebe-chaos/assets/images/base-impact-8f8d5a3058d6f2f9ecf417c167f14627.png" width="1878" height="458" class="img_ev3q"></p>
<p>It might be interesting to do the experiment again, with increased resources.</p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="restart-primary-1">Restart primary<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#restart-primary-1" class="hash-link" aria-label="Direct link to Restart primary" title="Direct link to Restart primary">â€‹</a></h6>
<p>When we check the index-node distribution, we can see the replicas as well.</p>
<p><img decoding="async" loading="lazy" alt="one-replica-distribution" src="https://camunda.github.io/zeebe-chaos/assets/images/one-replica-distribution-f7ace01da14896d626e105bf0427e0a9.png" width="1905" height="524" class="img_ev3q"></p>
<p>We have already seen in our base that the query API still works when one of the historic or runtime indices is available.</p>
<p>Interesting would be now, if we still return the same result, even when we restart the primary of the historic index.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1, "sort": [ { "field": "key" } ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"items":[{"key":2251799813772120,"processInstanceKey":2251799813772101,"processDefinitionKey":2251799813685252,"startDate":"2025-08-26T11:22:09.083+0000","endDate":"2025-08-26T11:22:12.640+0000","flowNodeId":"task","flowNodeName":"task","type":"SERVICE_TASK","state":"COMPLETED","incident":false,"tenantId":"&lt;default&gt;"}],"sortValues":[2251799813772120,2251799813772120],"total":10000}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod elastic-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "elastic-0" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ curl -L 'http://localhost:8080/v1/flownode-instances/search' -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "size": 1, "sort": [ { "field": "key" } ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{"items":[{"key":2251799813772120,"processInstanceKey":2251799813772101,"processDefinitionKey":2251799813685252,"startDate":"2025-08-26T11:22:09.083+0000","endDate":"2025-08-26T11:22:12.640+0000","flowNodeId":"task","flowNodeName":"task","type":"SERVICE_TASK","state":"COMPLETED","incident":false,"tenantId":"&lt;default&gt;"}],"sortValues":[2251799813772120,2251799813772120],"total":10000}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>As expected, the results are the same (as we have a replica).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h2>
<p>When running the experiment against the base, we were not expecting that the Query API handles ES unavailability until a certain point. The error messaging needs to be improved here if there is actually a problem, like a wrong filter or no index available.</p>
<p>Enabling the replicas was harder than expected, as we are currently in the process of changing our configuration (unified configuration). After finding the right properties (thanks to Houssain), we were even able to update an existing installation.</p>
<p>The replicas setting has an unforeseen performance impact; we expected disk space increase in our past discussions, but not how it impacts the general performance. It should be considered when rolling it out by default.</p>
<p>Having this setting allows to better handle ELS unavailability, especially for the Query API. When enough resources, likely also for the Camunda Exporter, this should be re-tested.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="observations">Observations<a href="https://camunda.github.io/zeebe-chaos/2025/08/26/Resiliency-against-ELS-unavailability#observations" class="hash-link" aria-label="Direct link to Observations" title="Direct link to Observations">â€‹</a></h3>
<ul>
<li>Query API handles ELS unavailability transparently; we should clarify whether this is expected</li>
<li>Query API returns useless errors when the needed indices are not available or when the given filter doesn't work</li>
<li>The Query API documentation is not easy to start with - we should give a command that can be easily tried out</li>
<li>Replicas setting has an impact on cluster performance - as ELS can run in CPU throttling, causing slow in general processing (due to write throttling).</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Scaling: probing linear scalability]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling"/>
        <updated>2025-07-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Hypothesis]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hypothesis">Hypothesis<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#hypothesis" class="hash-link" aria-label="Direct link to Hypothesis" title="Direct link to Hypothesis">â€‹</a></h2>
<p>The objective of this chaos day is to estimate the scalability of Zeebe when brokers and partitions are
scaled together: we expect to be able to see the system scaling linearly with the number of brokers/partition
in terms of throughput and back pressure, while maintaining predictable latency.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="general-experiment-setup">General Experiment setup<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#general-experiment-setup" class="hash-link" aria-label="Direct link to General Experiment setup" title="Direct link to General Experiment setup">â€‹</a></h3>
<p>To test this, we ran a benchmark using the latest alpha version of Camunda 8.8.0-alpha6, with the old
<code>ElasticsearchExporter</code> disabled, and the new <code>CamundaExporter</code> enabled. We also made sure Raft
leadership was balanced before starting the test, meaning each broker is leader for exactly one partition,
and we turned on partition scaling by adding the following environment variable:</p>
<ul>
<li><code>ZEEBE_BROKER_EXPERIMENTAL_FEATURES_ENABLEPARTITIONSCALING=true</code></li>
</ul>
<p>Each broker also has a SSD-class volume with 32GB of disk space, limiting them to a few thousand IOPS.
The processing load was 150 processes per second, with a large payload of 32KiB each. Each process instance has
a single service task:</p>
<p><img decoding="async" loading="lazy" alt="one-task" src="https://camunda.github.io/zeebe-chaos/assets/images/one_task-f083f237e568d87cc17eef056cb45d73.png" width="999" height="276" class="img_ev3q"></p>
<p>The processing load is generated by our own <a href="https://github.com/camunda/camunda/tree/9e723b21b0e408fc2b97fd7d3f6b092af8e62dbe/benchmarks" target="_blank" rel="noopener noreferrer">benchmarking application</a>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="initial-cluster-configuration">Initial cluster configuration<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#initial-cluster-configuration" class="hash-link" aria-label="Direct link to Initial cluster configuration" title="Direct link to Initial cluster configuration">â€‹</a></h4>
<p>To test this hypothesis, we will start with a <em>standard</em> configuration of the <em>Camunda orchestration cluster</em>:</p>
<ul>
<li>3 nodes</li>
<li>3 partitions</li>
<li>CPU limit: 2</li>
<li>Memory limit: 2 GB</li>
</ul>
<p>We will increase the load through a load generator in fixed increments until we start to see the nodes showing constant non zero backpressure,
which is a sign that the system has hit its throughput limits.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="target-cluster-configuration">Target cluster configuration<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#target-cluster-configuration" class="hash-link" aria-label="Direct link to Target cluster configuration" title="Direct link to Target cluster configuration">â€‹</a></h4>
<p>Once that level of throughput is increased, we will scale broker &amp; partitions <strong>while the cluster is under load</strong> to the new target value:</p>
<ul>
<li>6 nodes</li>
<li>6 partitions</li>
<li>CPU limit: 2</li>
<li>Memory limit: 2 GB</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="experiment">Experiment<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#experiment" class="hash-link" aria-label="Direct link to Experiment" title="Direct link to Experiment">â€‹</a></h4>
<p>We expect that during the scaling operation the backpressure/latencies might worsen,
but only temporarily, as once the scaling operation has completed,
the additional load it generate is not present anymore.</p>
<p>Then, we will execute the same procedure as above,
until we hit 2x the critical throughput hit before.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="expectation">Expectation<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#expectation" class="hash-link" aria-label="Direct link to Expectation" title="Direct link to Expectation">â€‹</a></h4>
<p>If the system scales linearly, we expect to see similar level of performance metrics
for similar values of the ratios <code>PI (created/complete) per second / nr. of partition</code>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="steady-state">Steady state<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#steady-state" class="hash-link" aria-label="Direct link to Steady state" title="Direct link to Steady state">â€‹</a></h2>
<p>The system is started with a throughput of 150 Process instances created per second.
As this is a <strong>standard benchmark configuration</strong>, nothing unexpected happens:</p>
<ul>
<li>The same number of process instances are completed as the ones created</li>
<li>The expected number of jobs is completed per unit of time</li>
</ul>
<p>At this point, we have the following topology:</p>
<p><img decoding="async" loading="lazy" alt="initial-topology" src="https://camunda.github.io/zeebe-chaos/assets/images/initial-topology-37fddc92ed46f6b20ae0cfb7ff0cac27.png" width="1585" height="192" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="first-benchmark-3-broker-and-3-partitions">First benchmark: 3 broker and 3 partitions<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#first-benchmark-3-broker-and-3-partitions" class="hash-link" aria-label="Direct link to First benchmark: 3 broker and 3 partitions" title="Direct link to First benchmark: 3 broker and 3 partitions">â€‹</a></h3>
<p>Let's start increasing the load incrementally, by adding 30 Process instances/s for every step.</p>
<table><thead><tr><th>Time</th><th>Brokers</th><th>Partitions</th><th>Throughput</th><th>CPU Usage</th><th>Throttling (CPU)</th><th>Backpressure</th></tr></thead><tbody><tr><td>09:30</td><td>3</td><td>3</td><td>150 PI/s, 150 jobs/s</td><td>1.28 / 1.44 / 1.02</td><td>12% / 7% / 1%</td><td>0</td></tr><tr><td>09:49</td><td>3</td><td>3</td><td>180 PI/s, 180 jobs/s</td><td>1.34 / 1.54 / 1.12</td><td>20% / 17% / 2%</td><td>0</td></tr><tr><td>10:00</td><td>3</td><td>3</td><td>210 PI/s, 210 jobs/s</td><td>1.79 / 1.62 / 1.33</td><td>28% / 42% / 4%</td><td>0</td></tr><tr><td>10:12</td><td>3</td><td>3</td><td>240 PI/s, 240 jobs/s</td><td>1.77 / 1.95 / 1.62</td><td>45% / 90% / 26%</td><td>0/0.5%</td></tr></tbody></table>
<p>At 240 Process Instances spawned per second, the system starts to hit the limits:
<img decoding="async" loading="lazy" alt="CPU usage @ 240 PI/s" src="https://camunda.github.io/zeebe-chaos/assets/images/config_1_240_cpu-8520ff99e75fea10d3add1bf720b21ab.png" width="1702" height="1127" class="img_ev3q">
<img decoding="async" loading="lazy" alt="CPU throttling@ 240 PI/s" src="https://camunda.github.io/zeebe-chaos/assets/images/config_1_240_cpu_throttling-0f8daf817e83828dffb1f5468577e753.png" width="1702" height="1127" class="img_ev3q"></p>
<p>And the backpressure is not zero anymore:
<img decoding="async" loading="lazy" alt="Backpressure @ 240 PI/s" src="https://camunda.github.io/zeebe-chaos/assets/images/config_1_240_backpressure-dafc5cbae6bd06f5ed054fa4a1b87377.png" width="1702" height="1127" class="img_ev3q"></p>
<ul>
<li>The CPU throttling reaches almost 90% on one node (this is probably caused by only one node being selected as <strong>gateway</strong> as previously noted)</li>
<li>Backpressure is now constantly above zero, even if it's just 0.5%, it's a sign that we are reaching the throughput limits.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="second-part-of-the-benchmark-scaling-to-6-brokers-and-6-partitions">Second part of the benchmark: scaling to 6 brokers and 6 partitions<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#second-part-of-the-benchmark-scaling-to-6-brokers-and-6-partitions" class="hash-link" aria-label="Direct link to Second part of the benchmark: scaling to 6 brokers and 6 partitions" title="Direct link to Second part of the benchmark: scaling to 6 brokers and 6 partitions">â€‹</a></h3>
<p>With 240 process instances per second being spawned, we send the commands to scale the cluster.</p>
<p>We first scale the <code>zeebe</code> <em>statefulset</em> to 6 brokers. As soon as the new brokers are running, even before they are healthy,
we can send the command to include them in the cluster and to increase the number of partition to 6.</p>
<p>This can be done following the <a href="https://docs.camunda.io/docs/next/self-managed/components/orchestration-cluster/zeebe/operations/cluster-scaling/#2b-scaling-brokers-and-partitions" target="_blank" rel="noopener noreferrer">guide in the official docs</a>.</p>
<p>Once the scaling has been completed, as can be seen from the <strong>Cluster operation</strong> section in the dashboard, we see the newly created
partitions participate in the workload.</p>
<p>We now have the following topology:</p>
<p><img decoding="async" loading="lazy" alt="six-partitions-topology" src="https://camunda.github.io/zeebe-chaos/assets/images/six-partitions-topology-c06f2c4b77537e86ff32e533466494ed.png" width="1569" height="298" class="img_ev3q"></p>
<p>As we did before, let's start increasing the load incrementally as we did with the other cluster configuration.</p>
<table><thead><tr><th>Time</th><th>Brokers</th><th>Partitions</th><th>Throughput</th><th>CPU Usage</th><th>Throttling (CPU)</th><th>Backpressure</th><th>Notes</th></tr></thead><tbody><tr><td>10:27</td><td>6</td><td>6</td><td>240 PI/s</td><td>0.92/1.26/0.74/0.94/0.93/0.93</td><td>2.8/6.0/0.3/2.8/3.4/3.18</td><td>0</td><td>After scale up</td></tr><tr><td>11:05</td><td>6</td><td>6</td><td>300 PI/s</td><td>1.17/1.56/1.06/1.23/1.19/1.18</td><td>9%/29%/0.6%/9%/11%/10%</td><td>0</td><td>Stable</td></tr><tr><td>11:10</td><td>6</td><td>6</td><td>360 PI/s</td><td>1.39/1.76/1.26/1.43/1.37/1.42</td><td>19%/42%/2%/16%/21%/22%</td><td>0</td><td>Stable</td></tr><tr><td>11:10</td><td>6</td><td>6</td><td>420 PI/s</td><td>1.76/1.89/1.50/1.72/1.50/1.70</td><td>76%/84%/52%/71%/60%/65%</td><td>0 (spurts on 1 partition)</td><td>Pushing hard</td></tr></tbody></table>
<p>However, at 11:32 one of the workers restarted, causing a spike in the processing due to jobs being yielded back to the engine, less jobs to be activated,
and thus less to be completed. This caused a job backlog to build up in the engine. Once the worker restarted, the backlog was drained, leading to a spike in
job completion requests: around 820 req/s, as opposed to the expected 420 req/s.</p>
<p>Because of this extra load, the cluster started to consume even more CPU, resulting in heavy CPU throttling from the cloud provider.</p>
<p><img decoding="async" loading="lazy" alt="CPU usage @ 420 PI/s" src="https://camunda.github.io/zeebe-chaos/assets/images/config_2_420_cpu-7179ead09ae826515cfc6a8aeafec600.png" width="1649" height="1128" class="img_ev3q">
<img decoding="async" loading="lazy" alt="CPU throttling @ 420 PI/s" src="https://camunda.github.io/zeebe-chaos/assets/images/config_2_420_cpu_throttling-f4f8d922f4cdf6859965acb1c6a3b78f.png" width="1649" height="1128" class="img_ev3q"></p>
<p>On top of this, eventually a broker restarted (most likely as we run on spot VMs). In order to continue with our test, we scaled the load down to 60 PI/s
to give the cluster the time to heal.</p>
<p>Once the cluster was healthy again, we raised the throughput back to 480 PI/s to verify the scalability with twice as much throughput as the initial configuration.</p>
<p>The cluster was able to sustain 480 process instances per second with similar levels of backpressure of the initial configuration:</p>
<p><img decoding="async" loading="lazy" alt="Backpressure @ 480 PI/s" src="https://camunda.github.io/zeebe-chaos/assets/images/config_2_480_backpressure-50f97c503678bcf1a51c1c316029be52.png" width="1705" height="1135" class="img_ev3q"></p>
<p>We can see below that CPU usage is high, and there is still some throttling, indicating we might be able to do more with a little bit of vertical scaling, or by scaling out and reducing the number of partitions per broker:</p>
<p><img decoding="async" loading="lazy" alt="CPU usage @ 480 PI/s" src="https://camunda.github.io/zeebe-chaos/assets/images/config_2_480_cpu-33e89ad48a794be879a4977d4c5d1a5f.png" width="1702" height="1127" class="img_ev3q">
<img decoding="async" loading="lazy" alt="CPU throttling" src="https://camunda.github.io/zeebe-chaos/assets/images/config_2_480_cpu_throttling-dc7f857c52e898fb159f70761f142499.png" width="1702" height="1127" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://camunda.github.io/zeebe-chaos/2025/07/11/linear-dynamic-scaling#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>We were able to verify that the cluster can scale almost linearly with new brokers and partitions, so long as the other components, like the secondary storage, workers, connectors, etc., are able to sustain a similar.</p>
<p>In particular, making sure that the secondary storage is able to keep up with the throughput turned out to be crucial to keep the cluster stable in order to
avoid filling up the Zeebe disks, which would bring to a halt the cluster.</p>
<p>We encountered a similar issue when one worker restarts: initially it creates a backlog of unhandled jobs, which turns into a massive increase in requests per second when the worker comes back, as it starts activating jobs faster than the cluster can complete them.</p>
<p>Finally, with this specific test, it would be interesting to explore the limits of vertical scalability, as we often saw CPU throttling being a major blocker for processing. This would make for an interesting future experiment.</p>]]></content>
        <author>
            <name>Carlo Sana</name>
            <uri>https://github.com/entangled90</uri>
        </author>
        <category label="availability" term="availability"/>
        <category label="scalability" term="scalability"/>
        <category label="performance" term="performance"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Follow up REST API performance]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance"/>
        <updated>2025-07-02T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Investigating REST API performance]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="investigating-rest-api-performance">Investigating REST API performance<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#investigating-rest-api-performance" class="hash-link" aria-label="Direct link to Investigating REST API performance" title="Direct link to Investigating REST API performance">â€‹</a></h2>
<p>This post collates the experiments, findings, and lessons learned during the REST API performance investigation.</p>
<p>There wasn't one explicit root cause identified. As it is often the case with such performance issues, it is the combination of several things.</p>
<p><strong>Quint essence:</strong> REST API is more CPU intense/heavy than gRPC. You can read more about this in the <a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#conclusion">conclusion part</a>. We have discovered ~10 issues we have to follow up with, where at least 2-3 might have a significant impact in the performance. Details can be found in the <a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#discovered-issues">Discovered issues</a> section</p>
<p><em>Short summary of what we have done and validated</em></p>
<ul>
<li>Investigations<!-- -->
<ul>
<li>Investigated existing REST api metrics<!-- -->
<ul>
<li>Breakdown metrics to have a better overview of where time is spent (created a tmp dashboard)</li>
</ul>
</li>
<li>Investigated worker failing with OOM</li>
<li>Investigated deployments and anti-affinities</li>
<li>Investigated command distribution</li>
<li>Investigated JFR recordings and profiles<!-- -->
<ul>
<li>Take JFR recordings and profile the system</li>
<li>Make use of the async profiler</li>
</ul>
</li>
</ul>
</li>
<li>Experiments<!-- -->
<ul>
<li>Increase CPU resources to understand whether it is resource contention - it is.</li>
<li>Improve Spring request filtering and execution<!-- -->
<ul>
<li>Use virtual threads for Spring</li>
<li>Use PathPattern instead of legacy AntPathPattern</li>
<li>Use direct response handling instead of asynchronous</li>
<li>Combine some of them</li>
</ul>
</li>
<li>Experiment with different setups to better distribute the load</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-1-investigation-rest-api-performance">Day 1: Investigation REST API Performance<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#day-1-investigation-rest-api-performance" class="hash-link" aria-label="Direct link to Day 1: Investigation REST API Performance" title="Direct link to Day 1: Investigation REST API Performance">â€‹</a></h2>
<p>This blog post aims to summarize the investigation of the REST API performance and give some hints and suggestions on what to improve.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rest-api-metrics">REST API Metrics<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#rest-api-metrics" class="hash-link" aria-label="Direct link to REST API Metrics" title="Direct link to REST API Metrics">â€‹</a></h3>
<p>One remark from the last experiments was that we do not have good insights for the REST API. Actually, we have the necessary metrics already exposed, but not yet available in our Dashboard.</p>
<p>This is currently prepared with <a href="https://github.com/camunda/camunda/pull/33907" target="_blank" rel="noopener noreferrer">#33907</a>. Based on this, I was able to further investigate the REST API performance.</p>
<p><img decoding="async" loading="lazy" alt="rest-api" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-api-922105b50aa5f7c2c731f488a8999976.png" width="2539" height="607" class="img_ev3q"></p>
<p>What we can see is that our requests take on average more than 50ms to complete. This is causing our throughput to go down, we are not able to create 150 PI/s even.</p>
<p>Looking at a different Benchmark using gRPC, we can see that requests take 5-10ms to complete, and have a stable throughput</p>
<p><img decoding="async" loading="lazy" alt="grpc-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/grpc-latency-097288055f8e099cc22f7268d67b53a9.png" width="2526" height="333" class="img_ev3q">
<img decoding="async" loading="lazy" alt="grpc" src="https://camunda.github.io/zeebe-chaos/assets/images/grpc-93fbafebfd4eebb459d95c8c713b67d7.png" width="1273" height="486" class="img_ev3q"></p>
<p>Due to the slower workers (on completion), we can see error reports of the workers not being able to accept further job pushes. This has been mentioned in the previous blog post as well.  This, in consequence, means the worker sends FAIL commands for such jobs, to give them back. It has a cascading effect, as jobs are sent back and forth, impacting the general process instance execution latency (which grows up to 60s compared to 0.2s).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="investigating-worker-errors">Investigating Worker Errors<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#investigating-worker-errors" class="hash-link" aria-label="Direct link to Investigating Worker Errors" title="Direct link to Investigating Worker Errors">â€‹</a></h3>
<p>In our previous experiments, we have seen the following exceptions</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">13:25:14.684 [pool-4-thread-3] WARN  io.camunda.client.job.worker - Worker benchmark failed to handle job with key 4503599628992806 of type benchmark-task, sending fail command to broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">java.lang.IllegalStateException: Queue full</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ArrayBlockingQueue.add(ArrayBlockingQueue.java:329) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.Worker.lambda$handleJob$1(Worker.java:122) ~[classes/:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.JobRunnableFactoryImpl.executeJob(JobRunnableFactoryImpl.java:45) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.JobRunnableFactoryImpl.lambda$create$0(JobRunnableFactoryImpl.java:40) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.BlockingExecutor.lambda$execute$0(BlockingExecutor.java:50) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This is actually coming from the Worker (benchmark) application, as it is collecting all <a href="https://github.com/camunda/camunda/blob/main/zeebe/benchmarks/project/src/main/java/io/camunda/zeebe/Worker.java#L54" target="_blank" rel="noopener noreferrer">the request futures in a blocking queue</a>.</p>
<p>As the performance is lower of handling requests, we collect more futures in the worker, causing to fill the queue. This in the end causes also to fail more jobs - causing even more work.</p>
<p>This allows explains why our workers have a higher memory consumption - we had to increase the worker memory to have a stable worker.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="profiling-the-system">Profiling the System<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#profiling-the-system" class="hash-link" aria-label="Direct link to Profiling the System" title="Direct link to Profiling the System">â€‹</a></h3>
<p>With the previous results, we were encouraged to do some profiling. For the start we used <a href="https://docs.oracle.com/javacomponents/jmc-5-4/jfr-runtime-guide/about.htm#JFRUH170" target="_blank" rel="noopener noreferrer">JFR</a> for some basic profiling.</p>
<p>You can do this by:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">  kubectl exec -it "$1" -- jcmd 1 JFR.start duration=100s filename=/usr/local/camunda/data/flight-$(date +%d%m%y-%H%M).jfr</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>If the flight recording is done, you can copy the recording (via <code>kubectl cp</code>) and open it with Intellij (JMC didn't work for me)</p>
<p><img decoding="async" loading="lazy" alt="first-profile" src="https://camunda.github.io/zeebe-chaos/assets/images/first-profile-6385c51bbf0d219a4a48da47d2505805.png" width="2012" height="626" class="img_ev3q"></p>
<p>We see that the Spring filter chaining is dominating the profile, which is not unexpected as every request has gone through this chain. As this is a CPU based sampling profile, it is likely to be part of the profile. Still, it was something interesting to note and investigate.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="path-pattern-matching">Path pattern matching<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#path-pattern-matching" class="hash-link" aria-label="Direct link to Path pattern matching" title="Direct link to Path pattern matching">â€‹</a></h4>
<p>Some research showed that it might be interesting to look into other path pattern matchers, as we use the (legacy) <a href="https://github.com/camunda/camunda/blob/main/dist/src/main/resources/application.properties#L17" target="_blank" rel="noopener noreferrer">ant path matcher</a> with <a href="https://github.com/camunda/camunda/blob/main/authentication/src/main/java/io/camunda/authentication/config/WebSecurityConfig.java#L86" target="_blank" rel="noopener noreferrer">regex</a>.</p>
<p><strong>Resources:</strong></p>
<ul>
<li>PathPattern - <a href="https://spring.io/blog/2020/06/30/url-matching-with-pathpattern-in-spring-mvc#pathpattern" target="_blank" rel="noopener noreferrer">https://spring.io/blog/2020/06/30/url-matching-with-pathpattern-in-spring-mvc#pathpattern</a></li>
<li><a href="https://github.com/spring-projects/spring-framework/issues/31098#issuecomment-1891737375" target="_blank" rel="noopener noreferrer">Results of using PathPattern and related discussion on GH</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="gateway---broker-request-latency">Gateway - Broker request latency<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#gateway---broker-request-latency" class="hash-link" aria-label="Direct link to Gateway - Broker request latency" title="Direct link to Gateway - Broker request latency">â€‹</a></h4>
<p>As we have such a high request-response latency, we have to find out where the time is spent. Ideally, we would have some sort of tracing (which we didn't have yet), or we would look at metrics that cover sub-parts of the system and the request-response cycle.</p>
<p>The REST API request-response latency metric, we can take it as the complete round trip, accepting the request on the gateway edge, converting it to a Broker request, sending it to the Broker, the Broker processes, sends the response back, etc.</p>
<p>Luckily, we have a metric that is covering the part of sending the Broker request (from the other side of the Gateway) to the Broker and wait for the response. See related <a href="https://github.com/camunda/camunda/blob/main/zeebe/broker-client/src/main/java/io/camunda/zeebe/broker/client/impl/BrokerRequestManager.java#L153" target="_blank" rel="noopener noreferrer">code here</a>.</p>
<p>The difference shows us that there is not a small overhead, meaning that actually the Gateway to Broker request-response is slower with REST as well, which is unexpected.</p>
<p>This can either be because different data is sent, or a different API is used, or some other execution mechanics, etc.</p>
<p>Using the same cluster and enabling the REST API later, we can see the immediate effect on performance.</p>
<p><img decoding="async" loading="lazy" alt="rest-enabled" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-enabled-845502a54c3df66f99d1e87d99480221.png" width="2512" height="652" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="request-handling-execution-logic">Request handling execution logic<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#request-handling-execution-logic" class="hash-link" aria-label="Direct link to Request handling execution logic" title="Direct link to Request handling execution logic">â€‹</a></h5>
<p>A difference we have spotted with REST API and gRPC is the usage of the BrokerClient.</p>
<p>While we use on the gRPC side the <a href="https://github.com/camunda/camunda/blob/main/zeebe/gateway-grpc/src/main/java/io/camunda/zeebe/gateway/EndpointManager.java#L457" target="_blank" rel="noopener noreferrer">BrokerClient with retries</a> and direct response handling, on the REST API we use no retries and <a href="https://github.com/camunda/camunda/blob/main/service/src/main/java/io/camunda/service/ApiServices.java#L55" target="_blank" rel="noopener noreferrer">handle the response async with the ForkJoinPool</a>.</p>
<p>As our benchmark clusters have two CPUs, <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener noreferrer">meaning 1 Thread for the common ForkJoin thread pool</a> we expected some contention on the thread.</p>
<p>For testing purposes, we increased the thread count by: <code>-Djava.util.concurrent.ForkJoinPool.common.parallelism=8</code></p>
<p>In a profile we can see that more threads are used, but it doesn't change anything in the performance.</p>
<p><img decoding="async" loading="lazy" alt="profile-inc-fork-join" src="https://camunda.github.io/zeebe-chaos/assets/images/profile-inc-fork-join-f567119ebd3858f2f5414425b7212228.png" width="2537" height="630" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="rest-gw-metrics-after-increaese-thread-pool" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-gw-metrics-after-increaese-thread-pool-f43f9d58ea3cc7f791d9e8a6aa85e32f.png" width="1907" height="761" class="img_ev3q"></p>
<p>The assumption was that we might not be able to handle the response in time with one thread, and this causes some contention also on the Gateway-Broker request-response cycle, but this is not the case.</p>
<p>We seem to spend time somewhere else or have a general resource contention issue. What we can see is that we have to work with more CPU throttling, then without REST API usage.</p>
<p><img decoding="async" loading="lazy" alt="rest-api-cpu-throttling.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-api-cpu-throttling-f4210b87ca53b8fcab9741cf12e76a60.png" width="2541" height="950" class="img_ev3q"></p>
<p>Increasing the CPU resolves the general performance problem, hinting even more that we might have some issues with threads competing with resources, etc.</p>
<p>In the following screenshot, you see the test with 6 CPUs per Camunda application.</p>
<p><img decoding="async" loading="lazy" alt="six-cpus" src="https://camunda.github.io/zeebe-chaos/assets/images/six-cpus-fcbf79199e8adfeb2dd3f073ae0020fe.png" width="1896" height="933" class="img_ev3q"></p>
<p>Compared to the previous run with 2 CPUs per Camunda application, where it had to fight with a lot of CPU throttling. The request-response latency was five times higher on average.</p>
<p><img decoding="async" loading="lazy" alt="two-cpus" src="https://camunda.github.io/zeebe-chaos/assets/images/two-cpus-a003a95c94a18bd11326736ffd163332.png" width="1901" height="925" class="img_ev3q"></p>
<p>We have to further investigate this based on this knowledge.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-2-profiling-and-experimenting">Day 2: Profiling and Experimenting<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#day-2-profiling-and-experimenting" class="hash-link" aria-label="Direct link to Day 2: Profiling and Experimenting" title="Direct link to Day 2: Profiling and Experimenting">â€‹</a></h2>
<p>Yesterday I was taking profiles with 100s, to reduce the noise. Still, we can see that the filter chain is taking ~40% of the complete profile.</p>
<p><img decoding="async" loading="lazy" alt="jfr-10-minutes-filter-chain.png" src="https://camunda.github.io/zeebe-chaos/assets/images/jfr-10-minutes-filter-chain-c3a4c75586a6c3ce023bad52889c5590.png" width="2540" height="665" class="img_ev3q"></p>
<p>When opening the JFR recording with JMC, we get some hints, related to context switches, CPU throttling (which we already know) and the inverted parallelism of GC (also mentioning high IO).</p>
<p><img decoding="async" loading="lazy" alt="locks-and-contention-context-switch.png" src="https://camunda.github.io/zeebe-chaos/assets/images/locks-and-contention-context-switch-b3ebe8dc71f088fc16b4bf39f5defd2e.png" width="640" height="107" class="img_ev3q">
<img decoding="async" loading="lazy" alt="jfr-cpu-throttling-detection.png" src="https://camunda.github.io/zeebe-chaos/assets/images/jfr-cpu-throttling-detection-5cfaa70f6b7e3b06c6ac745b8d317413.png" width="658" height="193" class="img_ev3q">
<img decoding="async" loading="lazy" alt="gc-ineffeciency-high-io.png" src="https://camunda.github.io/zeebe-chaos/assets/images/gc-ineffeciency-high-io-8e03650f088004e21e0e549bf8cf985c.png" width="636" height="240" class="img_ev3q"></p>
<p>We have already seen in our metrics, for example, that we fight with high CPU throttling</p>
<p><img decoding="async" loading="lazy" alt="rest-base-cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-cpu-c50ce9a1e9a0bb6715386fe81d11e5d8.png" width="2540" height="308" class="img_ev3q"></p>
<p>To better analyze (and circumvent that we have no tracing), I added some more metrics to understand where time is spent. Furthermore, I created a temporary dashboard to break down where time is spent.</p>
<p>When we look at the base with gRPC (taking our weekly benchmarks), we can see all latencies are low, and mostly under 5 ms.</p>
<p><img decoding="async" loading="lazy" alt="grpc-break-down.png" src="https://camunda.github.io/zeebe-chaos/assets/images/grpc-break-down-5f9058a44a49e0fd5f38f87489eda3e7.png" width="2526" height="644" class="img_ev3q"></p>
<p>As soon as we enable the REST API, we can see the latencies go up. The most significant increase we see is in the job activations.</p>
<p><img decoding="async" loading="lazy" alt="rest-break-down" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-break-down-b8b23cb51fdc0b22bda557fd5f3d7836.png" width="2533" height="796" class="img_ev3q"></p>
<p>Fascinating is that the write to process latency, the time from acceptance by the CommandAPI until the processor processes this command, also increases.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="virtual-threads">Virtual threads<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#virtual-threads" class="hash-link" aria-label="Direct link to Virtual threads" title="Direct link to Virtual threads">â€‹</a></h3>
<p>To remove some thoughts about potential IO and CPU contention, I experimented with virtual threads, which we can <a href="https://www.baeldung.com/spring-6-virtual-threads" target="_blank" rel="noopener noreferrer">easily enable for Spring</a>.</p>
<p>I set the following system property on the statefulset.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-Dspring.threads.virtual.enabled=true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Taking a new profile, we can see that all the http threads are gone, but still the filtering is prominent.</p>
<p><img decoding="async" loading="lazy" alt="jfr-virtual-threads.png" src="https://camunda.github.io/zeebe-chaos/assets/images/jfr-virtual-threads-c97b70375d089d057d3edecdd0ad2ad5.png" width="2522" height="714" class="img_ev3q"></p>
<p>Checking our metrics break-down again we see there is no benefit here.</p>
<p><img decoding="async" loading="lazy" alt="virtual-threads-break-down.png" src="https://camunda.github.io/zeebe-chaos/assets/images/virtual-threads-break-down-2d3df2e117f534eeb119f4614c377e90.png" width="2532" height="849" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="direct-handling">Direct handling<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#direct-handling" class="hash-link" aria-label="Direct link to Direct handling" title="Direct link to Direct handling">â€‹</a></h3>
<p>Investigating the code basis, we saw several times <code>#handleAsync</code> without using an extra executor, causing to use of the ForkJoinPool (as mentioned the other day). One idea was to <a href="https://github.com/camunda/camunda/commit/265d7164f5384be8c443c30b20e432582df09c24" target="_blank" rel="noopener noreferrer">directly handle the future completions</a>, meaning the response handling, etc.</p>
<p>We didn't observe any benefits with this.</p>
<p><img decoding="async" loading="lazy" alt="direct-handling-breakdown.png" src="https://camunda.github.io/zeebe-chaos/assets/images/direct-handling-breakdown-f5af66c79a5d1064e3d1e603651d8797.png" width="2530" height="808" class="img_ev3q"></p>
<p>In the JFR recording, we can see that less Threads are used, but the Spring filter chain is also super prominent.
<img decoding="async" loading="lazy" alt="direct-handling-v2-profile-too-much-filtering.png" src="https://camunda.github.io/zeebe-chaos/assets/images/direct-handling-v2-profile-too-much-filtering-d3a5da919b5220949e925bbb9042dbb4.png" width="2529" height="692" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="spring-pathpattern-parser-for-mvc">Spring PathPattern parser for MVC<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#spring-pathpattern-parser-for-mvc" class="hash-link" aria-label="Direct link to Spring PathPattern parser for MVC" title="Direct link to Spring PathPattern parser for MVC">â€‹</a></h3>
<p>At the end of the day I finally came to try the <code>PathPattern</code> parser. As mentioned the other day, it is recommended to use it over the legacy <code>AntPathMatcher</code>.</p>
<p>The migration was <a href="https://github.com/camunda/camunda/commit/357522d8355a624a1c07e1fb889561254b0305ba" target="_blank" rel="noopener noreferrer">rather simple</a>, we can replace the <code>spring.mvc.pathmatch.matching-strategy=ant_path_matcher</code> with
<code>spring.mvc.pathmatch.matching-strategy=path_pattern_parser</code>, we only had to fix some occurrences of regex combinations with <code>**</code>, as it is only allowed to have <code>**</code> at the end (no regex after).</p>
<p>See related branch <a href="https://github.com/camunda/camunda/commits/ck-pattern-path-parse/" target="_blank" rel="noopener noreferrer">ck-pattern-path-parse</a>.</p>
<p><img decoding="async" loading="lazy" alt="path-pattern-breakdown" src="https://camunda.github.io/zeebe-chaos/assets/images/path-pattern-breakdown-9d9c15dc4c5d21d70472756d370ca533.png" width="2512" height="817" class="img_ev3q"></p>
<p>We were able to reduce the latencies by half, which also allowed us to bring back our throughput.</p>
<p><img decoding="async" loading="lazy" alt="path-pattern-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/path-pattern-general-a9e20dc4a52c74b0488488aa78fa6e62.png" width="2528" height="667" class="img_ev3q"></p>
<p>I did a cross-check with the current SNAPSHOT, and weirdly the SNAPSHOT now behaved the same. I will run this for a while to see the results, as it might fail after a certain period of time. As this might also be related to where the pods are scheduled (noisy neighbours etc.)</p>
<p><img decoding="async" loading="lazy" alt="rest-base-v2-breakdown.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-v2-breakdown-fe4ebdd50122d4c32e30517e8e66c2ce.png" width="2543" height="796" class="img_ev3q">
<img decoding="async" loading="lazy" alt="rest-base-v2-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-v2-general-b19aece8c6549aa08c4caef4ba45bf02.png" width="2527" height="679" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="combination-of-direct-handle-and-pathpattern">Combination of direct handle and PathPattern<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#combination-of-direct-handle-and-pathpattern" class="hash-link" aria-label="Direct link to Combination of direct handle and PathPattern" title="Direct link to Combination of direct handle and PathPattern">â€‹</a></h3>
<p>On top of the above, I <a href="https://github.com/camunda/camunda/commits/ck-direct-handle/" target="_blank" rel="noopener noreferrer">combined the direct handling and PathPattern usage</a>, and this gave us the best results.</p>
<p>The latencies are only two times higher than gRPC vs before 5 times (and more).</p>
<p><img decoding="async" loading="lazy" alt="combination-of-all-breakdown.png" src="https://camunda.github.io/zeebe-chaos/assets/images/combination-of-all-breakdown-3796dbecb61e2f55349b7e2b2fe9c58e.png" width="2502" height="907" class="img_ev3q"></p>
<p>The throttling of the CPU was reduced by half as well.</p>
<p><img decoding="async" loading="lazy" alt="combination-of-all-cpu.png" src="https://camunda.github.io/zeebe-chaos/assets/images/combination-of-all-cpu-76b39f387018b794f171bb676b8b3832.png" width="2538" height="324" class="img_ev3q"></p>
<p>This gives a great stable throughput again.</p>
<p><img decoding="async" loading="lazy" alt="combination-of-all-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/combination-of-all-general-285aa7b2d45b50d79f995ebffbbd697f.png" width="2531" height="684" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-3-observing-load-tests-and-further-experimenting">Day 3: Observing load tests and further experimenting<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#day-3-observing-load-tests-and-further-experimenting" class="hash-link" aria-label="Direct link to Day 3: Observing load tests and further experimenting" title="Direct link to Day 3: Observing load tests and further experimenting">â€‹</a></h2>
<p>Yesterday, I have started several load tests for things I have tried out in code (like PathPattern or direct response handling), but also from different commits of the main branch (the current SNASPHOT, some commits that touch the rest gateway, and from begin of the week).</p>
<p>From what we observed is that some load tests can run stable for quite a while, until they break down. It is often related to restarts/rescheduling, or is already in general suboptimal resource distribution. At some point, the CPU throttling increases, and then the performance breaks down.</p>
<p><img decoding="async" loading="lazy" alt="all-namespaces-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/all-namespaces-throughput-1e62889524faaeec5cd7fb3052db4f04.png" width="2561" height="860" class="img_ev3q"></p>
<p>Interesting was that on all JFR recordings (with and without PathPattern), I still saw the Spring filter chain take a big chunk of the profile. This is because the filter chain itself doesn't change with using a different pattern parser.</p>
<p><img decoding="async" loading="lazy" alt="rest-base-v3-jfr.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-v3-jfr-03b09d7ca4ff602d0f55716b5e13c64f.png" width="1861" height="710" class="img_ev3q">
<img decoding="async" loading="lazy" alt="path-pattern-jfr.png" src="https://camunda.github.io/zeebe-chaos/assets/images/path-pattern-jfr-b3978d0f445b946a903d52f8651efbca.png" width="1886" height="724" class="img_ev3q">
<img decoding="async" loading="lazy" alt="combination-of-all-jfr.png" src="https://camunda.github.io/zeebe-chaos/assets/images/combination-of-all-jfr-96fe5ae899bbbab0a0739b88385e562e.png" width="1863" height="702" class="img_ev3q"></p>
<p>Based on the profile, we do not see much of a difference.</p>
<p>Today, I will validate the following:</p>
<ul>
<li>Is anti-affinity still enabled with our platform charts</li>
<li>Combination of virtual threads (to reduce the thread count and blocking behavior), with PathPattern (as this was the most stable test)</li>
<li>Maybe increasing the CPU limits again, to remove the K8 CPU throttling to better understand the system performance (until which the CPU consumption grows) and profile again</li>
<li>Investigate further - likely try a different profiler like asyncProfiler</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="anti-affinity">Anti-affinity<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#anti-affinity" class="hash-link" aria-label="Direct link to Anti-affinity" title="Direct link to Anti-affinity">â€‹</a></h3>
<p>Simply as a sanity check, I wanted to validate whether we still use our <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity" target="_blank" rel="noopener noreferrer">anti-affinity configuration</a> in our charts. This is to make sure that brokers are not scheduled on the same node. Unfortunately, this only works on the namespace level.</p>
<p>Indeed, we still have the configuration set:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">affinity</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">podAntiAffinity</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">requiredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">labelSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              </span><span class="token key atrule" style="color:#00a4db">matchExpressions</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> app.kubernetes.io/component</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> In</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token key atrule" style="color:#00a4db">values</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> core</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">topologyKey</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> kubernetes.io/hostname</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>While this helps in the same namespace, this doesn't prevent to have brokers from different namespaces from being scheduled on the same node (AFAIK). Potential for a noisy neighbor. But this is also the reason why we use smaller nodes, and try to assign most of the resources to the corresponding broker pods (which makes them effectively alone on the node).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rest-base-more-cpu">REST Base more CPU<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#rest-base-more-cpu" class="hash-link" aria-label="Direct link to REST Base more CPU" title="Direct link to REST Base more CPU">â€‹</a></h3>
<p>To validate once more how the base (simply with REST API enabled) performs with more CPU, we have set up a test with 6 CPUs (request + limit). This is an increase of factor three (from 2 CPU to 6 CPU).</p>
<p>In general, the test was stable.</p>
<p><img decoding="async" loading="lazy" alt="rest-base-more-cpu-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-general-2805c929e8b0c3e022f51d058680ce2c.png" width="2541" height="699" class="img_ev3q">
<img decoding="async" loading="lazy" alt="rest-base-more-cpu-latency.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-latency-7c06f38617becaa9911e4ac564384777.png" width="2516" height="869" class="img_ev3q"></p>
<p>As soon as we increased the CPU the throttling went down.
<img decoding="async" loading="lazy" alt="rest-base-more-cpu-throttle.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-throttle-97d5c48839b561b3e766f343e638c035.png" width="2543" height="332" class="img_ev3q"></p>
<p>The consumption went up to 3 CPU, comparing to our gRPC benchmarks, this is an increase of factor two!</p>
<p><img decoding="async" loading="lazy" alt="rest-base-more-cpu-usage.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-usage-99b9d828203b094e813586b4c0dc2e90.png" width="1272" height="348" class="img_ev3q"></p>
<p>While observing the test, we noticed some weird behavior of the workers. There are multiple regular job activation requests sent (while we still have Job Push enabled and in use).</p>
<p><img decoding="async" loading="lazy" alt="rest-base-more-cpu-throughput.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-throughput-7a7a9453614418df52669c0d94004e67.png" width="2541" height="293" class="img_ev3q"></p>
<p>This is also causing to have much higher job COMPLETE command rate, where most of them are actually rejected. We see ~500 job completion rejections per second!</p>
<p><img decoding="async" loading="lazy" alt="rest-base-more-cpu-logstream.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-logstream-7c26d6f0c3c061a89b206556a799ead6.png" width="2537" height="374" class="img_ev3q"></p>
<p>Why we have this behavior is not yet fully clear. The load test is stabilizing at a later point and running straight for several days.</p>
<p><img decoding="async" loading="lazy" alt="rest-base-more-cpu-longer-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-longer-general-94f15c958548f397d84b602000ade539.png" width="1899" height="891" class="img_ev3q"></p>
<p>At some-point it went into struggle again, as it run out of disk space. The exporter had a too big backlog, and was not able to catch up.</p>
<p><img decoding="async" loading="lazy" alt="rest-base-more-cpu-exporting.png" src="https://camunda.github.io/zeebe-chaos/assets/images/rest-base-more-cpu-exporting-337702395ccb834bb43806e79ec4c233.png" width="388" height="226" class="img_ev3q"></p>
<p>This might be related to the huge number of commands and rejections that need to be skipped.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="combination-of-vt-and-pathpattern">Combination of VT and PathPattern<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#combination-of-vt-and-pathpattern" class="hash-link" aria-label="Direct link to Combination of VT and PathPattern" title="Direct link to Combination of VT and PathPattern">â€‹</a></h3>
<p>As another experiment, we run a load test with enabling virtual threads and PathPattern parser on Spring.</p>
<p>To summarize, it doesn't help to reduce the CPU consumption to a level that the system can run stable.
At the beginning, the worker was able to complete at least ~30 jobs per second, but later it fully stopped.</p>
<p><img decoding="async" loading="lazy" alt="vt-pathpattern-cpu-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pathpattern-cpu-general-cb50efe294975dd6c0356af178a3715f.png" width="1905" height="678" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="vt-pathpattern-cpu-usage.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pathpattern-latency-4a7b9872c3a15fde686374dca02a88d4.png" width="1911" height="843" class="img_ev3q">
<img decoding="async" loading="lazy" alt="vt-pathpattern-cpu-usage.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pathpattern-throughput-f55ad671910ebaf6ac413e97fae7cadc.png" width="1905" height="222" class="img_ev3q"></p>
<p>In our JFR recording, we see a similar pattern, where the Spring filtering is still taking most of the samples.</p>
<p><img decoding="async" loading="lazy" alt="vt-pathpattern-cpu-jfr.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pathpattern-cpu-jfr-f072b798ee53305315e2f2111b2ba499.png" width="2541" height="697" class="img_ev3q"></p>
<p>Enabling the virtual threads on spring, at least seem to remove the HTTP threads we normally had in our profiles.</p>
<p>The CPU throttling is rather high, causing the performance problems we see here.</p>
<p><img decoding="async" loading="lazy" alt="vt-pathpattern-cpu-throttle.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pathpattern-cpu-throttle-674b1d2f70160c8a482470a50fe09a6f.png" width="2537" height="314" class="img_ev3q"></p>
<p>Zeebe-2 is often between 50-80% CPU throttling, as it is consuming 1.8 CPU (limit is 2).</p>
<p><img decoding="async" loading="lazy" alt="vt-pathpattern-cpu-usage.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pathpattern-cpu-usage-fb0fc34ea832fb6f36ecc5c5f507220f.png" width="1259" height="328" class="img_ev3q"></p>
<p>The workers stopped working at some point completely. Investigating this, we can see that it fails with some OOM as well.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Jul 05, 2025 07:16:48.330 [pool-4-thread-8] WARN  io.camunda.client.job.worker - Worker benchmark failed to handle job with key 2251799882041322 of type benchmark-task, sending fail command to broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">java.lang.IllegalStateException: Queue full</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Exception in thread "prometheus-http-1-6" java.lang.OutOfMemoryError: Java heap space</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Jul 05, 2025 7:18:48 AM io.prometheus.metrics.exporter.httpserver.HttpExchangeAdapter sendErrorResponseWithStackTrace</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SEVERE: The Prometheus metrics HTTPServer caught an Exception while trying to send the metrics response.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">java.io.IOException: Broken pipe</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/sun.nio.ch.SocketDispatcher.write0(Native Method)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:62)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:137)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:102)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:58)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:542)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.Request$WriteStream.write(Request.java:421)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.ChunkedOutputStream.writeChunk(ChunkedOutputStream.java:131)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.ChunkedOutputStream.flush(ChunkedOutputStream.java:165)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.ChunkedOutputStream.close(ChunkedOutputStream.java:140)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.PlaceholderOutputStream.close(ExchangeImpl.java:477)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.zip.DeflaterOutputStream.close(DeflaterOutputStream.java:272)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.prometheus.metrics.exporter.common.PrometheusScrapeHandler.handleRequest(PrometheusScrapeHandler.java:74)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.prometheus.metrics.exporter.httpserver.MetricsHandler.handle(MetricsHandler.java:33)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:98)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:101)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:871)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:98)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:847)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.lang.Thread.run(Thread.java:1583)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="async-profiler">Async profiler<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#async-profiler" class="hash-link" aria-label="Direct link to Async profiler" title="Direct link to Async profiler">â€‹</a></h3>
<p>To enrich our insights and inputs (have more data to investigate), we tried to set up <a href="https://github.com/async-profiler/async-profiler" target="_blank" rel="noopener noreferrer">async profiler</a> with our load tests.</p>
<p>We had some <a href="https://github.com/camunda/camunda/tree/main/zeebe/benchmarks/docs/debug#async-profiler" target="_blank" rel="noopener noreferrer">out dated documentation</a> in our mono repository. Due to several refactorings, restructurings, etc. this guide was no longer working.</p>
<p>I was able to create a script to set it up for now:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash -xeu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Usage:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#   ./executeProfiling.sh &lt;POD-NAME&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">set -oxe pipefail</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">node=$1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Download and extract latest async profiler</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">curl -L https://github.com/jvm-profiling-tools/async-profiler/releases/download/v4.0/async-profiler-4.0-linux-x64.tar.gz -o profiler.tar.gz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cat profiler.tar.gz | tar xzv </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Copy async profiler to pod</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl cp async-profiler-4.0-linux-x64/bin/asprof "$node":/usr/local/camunda/data/asprof</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl exec "$node" -- mkdir -p /usr/local/camunda/data/lib</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl cp async-profiler-4.0-linux-x64/lib/libasyncProfiler.so "$node":/usr/local/camunda/data/libasyncProfiler.so</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl exec "$node" -- chmod +x /usr/local/camunda/data/asprof</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Run profiling</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">filename=flamegraph-$(date +%Y-%m-%d_%H-%M-%S).html</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PID=$(kubectl exec "$node" -- jps | grep Standalone | cut -d " " -f 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl exec "$node" -- ./data/asprof -e itimer -d 100 -t -f "/usr/local/camunda/data/$filename" --libpath /usr/local/camunda/data/libasyncProfiler.so "$PID"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Copy result</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl cp "$node:/usr/local/camunda/data/$filename" "$node-$filename"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The results need to be investigated next.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="follow-up-questions">Follow-up questions<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#follow-up-questions" class="hash-link" aria-label="Direct link to Follow-up questions" title="Direct link to Follow-up questions">â€‹</a></h3>
<ol>
<li>Why are benchmark applications targeted at the same gateway? How does the IP resolution work with the headless service (which returns an array of IPs)? It looks like it is picking always the same gateway.</li>
<li>Why are the workers sending so often job activations, while the job push is active?</li>
<li>Why do we have 500+ job completions per second? Overloading the cluster?</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="day-4-investigate-profiles-and-experiments">Day 4: Investigate profiles and experiments<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#day-4-investigate-profiles-and-experiments" class="hash-link" aria-label="Direct link to Day 4: Investigate profiles and experiments" title="Direct link to Day 4: Investigate profiles and experiments">â€‹</a></h2>
<p>We will continue with investigating certain areas of our REST API, checking profiles, and experimenting with ideas.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="combination-with-more-cpu">Combination with more CPU<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#combination-with-more-cpu" class="hash-link" aria-label="Direct link to Combination with more CPU" title="Direct link to Combination with more CPU">â€‹</a></h3>
<p>The virtual threads and PathPattern parser setting test was combined with more CPUs (from 2 to 3 CPUs).</p>
<p><img decoding="async" loading="lazy" alt="vt-pp-more-cpu-general" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-more-cpu-general-26a90fdcf6b39068121037b78a2ae693.png" width="1894" height="699" class="img_ev3q">
<img decoding="async" loading="lazy" alt="vt-pp-more-cpu-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-more-cpu-latency-426cff7ce93d998d9cfecb7a04050d32.png" width="1889" height="904" class="img_ev3q"></p>
<p>The test is running stable, but needs to be further observed (as we have seen, they might fail at a later point in time).</p>
<p><img decoding="async" loading="lazy" alt="vt-pp-cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-cpu-5079fd7215db24f34be6f4812f807b42.png" width="1911" height="573" class="img_ev3q"></p>
<p>The CPU consumption and throttling looks rather stable.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="running-for-a-day">Running for a day<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#running-for-a-day" class="hash-link" aria-label="Direct link to Running for a day" title="Direct link to Running for a day">â€‹</a></h4>
<p><img decoding="async" loading="lazy" alt="vt-pp-later-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-latern-general-96509b51933ea37e9642d25dfe82fb68.png" width="1889" height="682" class="img_ev3q"></p>
<p>The test was running stably for a good amount of time, but suddenly broke down.
The CPU usage increases heavily, causing throttling and breaking the system again, but this is just a symptom.</p>
<p><img decoding="async" loading="lazy" alt="vt-pp-later-cpu.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-later-cpu-1d750c077153e327bbe6c29226326d0d.png" width="1884" height="572" class="img_ev3q"></p>
<p>When we investigate further the metrics, we can see that the latency, especially the commit latency, is increasing at the same time.</p>
<p><img decoding="async" loading="lazy" alt="vt-pp-later-latency.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-later-latency-9f2d4ab1fb68c535739983f273c9756f.png" width="1894" height="265" class="img_ev3q"></p>
<p>This is likely because we might exhaust our available I/O. Indeed, we write or commit more at this point in time.</p>
<p><img decoding="async" loading="lazy" alt="vt-pp-later-commit-rate.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-later-commit-rate-d32992c19ffeb7b2a86f1665427b13ce.png" width="1918" height="299" class="img_ev3q"></p>
<p>Further investigation highlights that the rejections of JOB completions are spiking high</p>
<p><img decoding="async" loading="lazy" alt="vt-pp-increase-of-rejections.png" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-increase-of-rejections-94d9092237d99dcb7295e1bed9eabdaf.png" width="1889" height="351" class="img_ev3q"></p>
<p>It looks like that a new job stream has been started, at which time the cluster starts to go into a failure mode.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-later-stream-start-0570880679983aa837aa093b9f11dd3a.png" width="645" height="213" class="img_ev3q"></p>
<p>Additionally, more jobs are pushed out to the clients, causing more to complete (duplicate), increasing the rejections.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-later-more-push-4bb3245ec49ef3e42502c639502c74c6.png" width="1908" height="649" class="img_ev3q"></p>
<p>We can also see that the workers start to crash the loop, because they receive too many jobs.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/vt-pp-later-worker-restart-1e6674c009b72589cb8a5c9f71721ffb.png" width="552" height="228" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="investigating-command-distribution">Investigating command distribution<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#investigating-command-distribution" class="hash-link" aria-label="Direct link to Investigating command distribution" title="Direct link to Investigating command distribution">â€‹</a></h3>
<p>Running all of these tests, I investigate several things, and realized that for all of these tests, there is always one Camunda pod doing more than the others. To me, it looks like our load is not even distributed.</p>
<p><img decoding="async" loading="lazy" alt="gateway-cmd-distribution" src="https://camunda.github.io/zeebe-chaos/assets/images/gateway-cmd-distribution-ad6a04a30d2e5d8b1d6731a4cbb861e9.png" width="2555" height="845" class="img_ev3q"></p>
<p>Due to the imbalanc,e one pod is doing more than the others, this pod is sacrificing of CPU throttling.</p>
<p><img decoding="async" loading="lazy" alt="gateway-cmd-distribution-cpu.png" src="https://camunda.github.io/zeebe-chaos/assets/images/gateway-cmd-distribution-cpu-b1007184fb6188c17ff378e5efa9fb7a.png" width="2544" height="640" class="img_ev3q"></p>
<p>I think the challenge we face here is related to our setup using <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services" target="_blank" rel="noopener noreferrer">a headless service</a> in our <a href="https://github.com/camunda/camunda-platform-helm/blob/main/charts/camunda-platform-8.8/templates/core/service.yaml" target="_blank" rel="noopener noreferrer">Camunda Platform Helm Chart</a>.</p>
<p>This means we have a service deployed in K8 that is returning all IPs for all PODs when resolving. Likely, our client applications simply use the first IP they retrieve (instead of doing some more clever).
I think this would be something we should further investigate. Potential options are to have client load balancing (with the multiple IPs), use a different service, or
Deploy the standalone gateway (again) to better separate the concerns.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="profiling-with-async-profiler">Profiling with Async Profiler<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#profiling-with-async-profiler" class="hash-link" aria-label="Direct link to Profiling with Async Profiler" title="Direct link to Profiling with Async Profiler">â€‹</a></h3>
<p>As mentioned the other day, I have run the async profiler to get some more information/details from a different angle of the application execution.</p>
<p>Again, what we can see is that the web filter chaining is taking a big chunk of the samples.</p>
<p><img decoding="async" loading="lazy" alt="async-profile-rest-more-cpu-filter.png" src="https://camunda.github.io/zeebe-chaos/assets/images/async-profile-rest-more-cpu-filter-45875207d59ca6d1e49f1b4752852e4f.png" width="1905" height="946" class="img_ev3q"></p>
<p>Furthermore, logging is also a big part of the profile.</p>
<p><img decoding="async" loading="lazy" alt="async-profile-rest-more-cpu-logging.png" src="https://camunda.github.io/zeebe-chaos/assets/images/async-profile-rest-more-cpu-logging-2cd0ca8b7e1bc0ba2fc52e5172e0f642.png" width="1910" height="947" class="img_ev3q"></p>
<p>At the time of profiling, we were retrieving a lot of errors from the Brokers, due to rejections, etc. (see above).</p>
<p>We can see that we repeatedly log exceptions with no message at all.</p>
<p><img decoding="async" loading="lazy" alt="logging-null" src="https://camunda.github.io/zeebe-chaos/assets/images/logging-null-a55ddfcc3bdc1d3cf5e009f64b017f0d.png" width="1497" height="588" class="img_ev3q">
<img decoding="async" loading="lazy" alt="logs-repeating" src="https://camunda.github.io/zeebe-chaos/assets/images/logs-repeating-68bf15987c6eb6f37f31c339862a5b09.png" width="979" height="576" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="usage-metrics">Usage metrics<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#usage-metrics" class="hash-link" aria-label="Direct link to Usage metrics" title="Direct link to Usage metrics">â€‹</a></h4>
<p>When I investigated this further and checked our logging, I saw that we wrote a LOT of usage metrics logs</p>
<p><img decoding="async" loading="lazy" alt="usage-metrics-rest-logs.png" src="https://camunda.github.io/zeebe-chaos/assets/images/usage-metrics-rest-logs-7e8059c9f2da56a472abcaadb56a1226.png" width="1845" height="518" class="img_ev3q"></p>
<p>Based on the metrics, the exporting of usage metrics seem to be correlating to the state size growing.
<img decoding="async" loading="lazy" alt="usage-metrics-rest-state-size.png" src="https://camunda.github.io/zeebe-chaos/assets/images/usage-metrics-rest-test-223a5e1c7017d4883483e06d63640a63.png" width="2523" height="342" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="usage-metrics-rest-state-size.png" src="https://camunda.github.io/zeebe-chaos/assets/images/usage-metrics-rest-state-size-1e3f9754c526ac949b8fe6ec73af64ab.png" width="1262" height="290" class="img_ev3q"></p>
<p>This needs to be further clarified, whether this is expected.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="last-day-experimenting">Last day (experimenting)<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#last-day-experimenting" class="hash-link" aria-label="Direct link to Last day (experimenting)" title="Direct link to Last day (experimenting)">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="load-balance">Load balance<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#load-balance" class="hash-link" aria-label="Direct link to Load balance" title="Direct link to Load balance">â€‹</a></h3>
<p>As discovered on the previous day, we are sending requests mainly to one node. This is because of the usage of a <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services" target="_blank" rel="noopener noreferrer">headless service</a> in our <a href="https://github.com/camunda/camunda-platform-helm/blob/main/charts/camunda-platform-8.8/templates/core/service.yaml" target="_blank" rel="noopener noreferrer">Camunda Platform Helm Chart</a>.</p>
<p>Today, I experimented with using a different service to access the Gateway API with the clients.</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Manifest</summary><div><div class="collapsibleContent_i85q"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Service</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">annotations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">meta.helm.sh/release-name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ck</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">rest</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">baseload</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">balancer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">meta.helm.sh/release-namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ck</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">rest</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">baseload</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">balancer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/component</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gateway</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/instance</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ck</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">rest</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">baseload</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">balancer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/managed-by</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Helm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/part-of</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/version</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ck</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">rest</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">base</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">more</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">cpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">cd459997</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">helm.sh/chart</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">13.0.0</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">alpha4.2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ck</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">rest</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">baseload</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">balancer</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">core</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ck</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">rest</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">baseload</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">balancer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ClusterIP </span><span class="token comment" style="color:#999988;font-style:italic"># &lt;---- That is the important part</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">ports</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> http</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">port</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8080</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">protocol</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TCP</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">targetPort</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8080</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> internal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">port</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">26502</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">protocol</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TCP</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">targetPort</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">26502</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> command</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">port</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">26501</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">protocol</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TCP</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">targetPort</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">26501</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> server</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">port</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">9600</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">protocol</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TCP</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">targetPort</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">9600</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gateway</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">port</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">26500</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">protocol</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TCP</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">targetPort</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">26500</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">selector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/component</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> core</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/instance</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ck</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">rest</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">baseload</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">balancer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/managed-by</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Helm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/part-of</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></details>
<p>By deploying this service and changing the client application deployments, we can see the effect directly.</p>
<p><img decoding="async" loading="lazy" alt="service-differences-load.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-load-613fc9b84be02bf1c85f19c869ed738f.png" width="2546" height="434" class="img_ev3q"></p>
<p>The load is well distributed, and the CPU is as well.</p>
<p><img decoding="async" loading="lazy" alt="service-differences-cpu.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-cpu-7847598c889896f2c9aed9e0d7aca023.png" width="2521" height="304" class="img_ev3q"></p>
<p>In general the performance looks pretty stable and good.
<img decoding="async" loading="lazy" alt="service-differences-general.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-general-92bbf0df630e027f8c27be8c0d6d86cc.png" width="2557" height="685" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="after-the-night">After the night<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#after-the-night" class="hash-link" aria-label="Direct link to After the night" title="Direct link to After the night">â€‹</a></h4>
<p>After running it for a while, the cluster was still looking quite stable.</p>
<p><img decoding="async" loading="lazy" alt="service-differences-general-later.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-general-later-17413ad623850d0f188ebf6ab33e1d2c.png" width="2530" height="679" class="img_ev3q">
<img decoding="async" loading="lazy" alt="service-differences-cpu-later.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-cpu-later-e057bf19890c0e660dee2745d03dde4e.png" width="2549" height="577" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="after-lunch">After lunch<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#after-lunch" class="hash-link" aria-label="Direct link to After lunch" title="Direct link to After lunch">â€‹</a></h4>
<p><img decoding="async" loading="lazy" alt="service-differences-general-later2.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-general-later2-b010f5338701d060a2226e5386a3fe12.png" width="2530" height="677" class="img_ev3q">
<img decoding="async" loading="lazy" alt="service-differences-cpu-later2.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-cpu-later2-807ffd401630456ce1001fe66f6e8545.png" width="2530" height="576" class="img_ev3q"></p>
<p>The general throughput looks still stable, even if the latency is much higher than for gRPC (was mostly ~3-5 ms).</p>
<p><img decoding="async" loading="lazy" alt="service-differences-latency-later.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-latency-later-c46ffdd546684517b98470c1488c1707.png" width="2533" height="814" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="exporter-runs-into-an-issue">Exporter runs into an issue<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#exporter-runs-into-an-issue" class="hash-link" aria-label="Direct link to Exporter runs into an issue" title="Direct link to Exporter runs into an issue">â€‹</a></h4>
<p>Observing the cluster, we have detected that the disk usage is increasing over time.</p>
<p><img decoding="async" loading="lazy" alt="service-differences-disk.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-disk-93e93917ee91b55454cf3e505e809588.png" width="829" height="229" class="img_ev3q"></p>
<p>The reason seem to be that the exporter is not able to catch up. Something that needs to be investigated separately.</p>
<p><img decoding="async" loading="lazy" alt="service-differences-exporter-not-catch-up.png" src="https://camunda.github.io/zeebe-chaos/assets/images/service-differences-exporter-not-catch-up-bb0dfa673863e0eac699b7f89ff12bfb.png" width="524" height="223" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p><strong>Quint essence:</strong> REST API is more CPU intense/heavy than gRPC.</p>
<p>In general, this is not surprising. The REST API (and incl. Spring) works completely differently and is not as optimized for performance as gRPC is.
We can see this also in our latencies, which are twice+ higher even when we have enough resources available.</p>
<p>When correctly and evenly distributing the load we are able to handle the expected load on the cluster. Of course, this goes just until a certain load (even higher load) until it dips (as the CPU is exhausted again).</p>
<p>With gRPC, the bad request distribution was not an issue, as the overhead is low and has less of an impact.</p>
<p>The same behavior we had when assigning more resources to the cluster. Indicating CPU as the bottleneck (the issue is parallelizable)
The CPU consumption can't be pinpointed to one single thing, but multiple inefficiencies coming together.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="discovered-issues">Discovered issues:<a href="https://camunda.github.io/zeebe-chaos/2025/07/02/Follow-up-REST-API-performance#discovered-issues" class="hash-link" aria-label="Direct link to Discovered issues:" title="Direct link to Discovered issues:">â€‹</a></h3>
<p>During the investigation, the following issues have been discovered, which we should look at (and ideally fix).</p>
<ul>
<li><a href="https://github.com/camunda/camunda-platform-helm/issues/3784" target="_blank" rel="noopener noreferrer">Helm Chart 8.8 is using a headless service for the single Application</a></li>
<li><strong>REST API</strong>
<ul>
<li><a href="https://github.com/camunda/camunda/issues/35067" target="_blank" rel="noopener noreferrer">Investigate and improve web filter chain - as this was the dominator in all our profiles</a></li>
<li><a href="https://github.com/camunda/camunda/issues/35069" target="_blank" rel="noopener noreferrer">Sub-optimal logging in REST API v2</a></li>
<li><a href="https://github.com/camunda/camunda/issues/35076" target="_blank" rel="noopener noreferrer">REST API response handling is running into contention</a></li>
</ul>
</li>
<li><strong>Zeebe</strong>
<ul>
<li><a href="https://github.com/camunda/camunda/issues/35071" target="_blank" rel="noopener noreferrer">Usage metrics heavily looping</a></li>
<li><a href="https://github.com/camunda/camunda/issues/35072" target="_blank" rel="noopener noreferrer">Usage metrics records are divided unnecessary</a></li>
<li><a href="https://github.com/camunda/camunda/issues/35074" target="_blank" rel="noopener noreferrer">Job push vicious circle</a></li>
<li><a href="https://github.com/camunda/camunda/issues/35080" target="_blank" rel="noopener noreferrer">Camunda Exporter is not able to catch up on all partitions</a></li>
</ul>
</li>
<li>Clients<!-- -->
<ul>
<li><a href="https://github.com/camunda/camunda/issues/34597" target="_blank" rel="noopener noreferrer">Client failure handling ends in Stackoverflow (causing the client to completelty stop working)</a></li>
<li><a href="https://github.com/camunda/camunda/issues/35077" target="_blank" rel="noopener noreferrer">Workers and Starters are holding futures in a queue</a></li>
</ul>
</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Performance of REST API]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API"/>
        <updated>2025-06-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In today's Chaos day we wanted to experiment with the new REST API (v2) as a replacement for our previous used gRPC API.]]></summary>
        <content type="html"><![CDATA[<p>In today's Chaos day we wanted to experiment with the new REST API (v2) as a replacement for our previous used gRPC API.</p>
<p>Per default, our load tests make use of the gRPC, but as we want to make REST API the default and release this fully with 8.8, we want to make sure to test this accordingly in regard to reliability.</p>
<p><strong>TL;DR;</strong> We observed severe performance regression when using the REST API, even when job streaming is in use by the job workers (over gRPC). Our client seems to have a higher memory consumption, which caused some instabilities in our tests as well. With the new API, we lack certain observability, which makes it harder to dive into certain details. We should investigate this further and find potential bottlenecks and improvements.</p>
<p><img decoding="async" loading="lazy" alt="general" src="https://camunda.github.io/zeebe-chaos/assets/images/general-overview-a0c6c48be94b9a8aa8cbbd3b44830a67.png" width="1879" height="879" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment-pt-1">Chaos Experiment (Pt. 1)<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#chaos-experiment-pt-1" class="hash-link" aria-label="Direct link to Chaos Experiment (Pt. 1)" title="Direct link to Chaos Experiment (Pt. 1)">â€‹</a></h2>
<p>To experiment with the REST API, we have to adjust our client applications to make use of the REST API. This is done by the following PR <a href="https://github.com/camunda/camunda/pull/34527" target="_blank" rel="noopener noreferrer">#34527</a>. We can take our normal benchmark/load tests where we run 150 PI/s, and enable the REST API usage. To make this possible, the charts have been adjusted by this PR <a href="https://github.com/camunda/zeebe-benchmark-helm/pull/269" target="_blank" rel="noopener noreferrer">#269</a>.</p>
<p>As a base to compare we can use our weekly benchmarks. We use gRPC here as the default in the client applications (starter + worker).
In our weekly benchmarks, we can see that we are able to create and complete 150 process instances per second.</p>
<p><img decoding="async" loading="lazy" alt="base-general" src="https://camunda.github.io/zeebe-chaos/assets/images/base-general-e28fa9defe09774a06b06e1875411d34.png" width="1911" height="990" class="img_ev3q"></p>
<p>The performance is stable, and we have low backpressure. As the process instances are quite simple (with one service task), the execution time is rather low with 0.2 seconds on average.</p>
<p><img decoding="async" loading="lazy" alt="base-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/base-latency-0a48e74f5c1bb7b726086f290ab82c15.png" width="1897" height="644" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When using the REST API, we expect some more overhead (maybe ~10%), like serializing and sending data over the wire (as gRPC is optimized for it). In general, we expect a stable performing system.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Observing the first experiment, we saw a degradation of performance <strong>by more than 70%</strong>. Additionally, we seem to have no metrics for the REST API requests. Backpressure seems to be zero, while we're not performing as expected.</p>
<p><img decoding="async" loading="lazy" alt="exp1-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp1-general-666de10e428ddacf15eec4af011831a4.png" width="1903" height="967" class="img_ev3q"></p>
<p>The process instance completion latency has been increased to above than one minute.</p>
<p><img decoding="async" loading="lazy" alt="exp1-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/exp1-latency-6780630818b87b53dd473beb01ddc29e.png" width="1905" height="649" class="img_ev3q"></p>
<p>We can observe with our metrics that job push is still in use, and the job workers get to work on the available jobs.</p>
<p><img decoding="async" loading="lazy" alt="exp1-push" src="https://camunda.github.io/zeebe-chaos/assets/images/exp1-push-c50f1b764452b3be53ee861f4c111731.png" width="1894" height="339" class="img_ev3q"></p>
<p>The issue we are seeing is related to crash looping workers (which we can also see in the panels above about Pod restarts).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                                              READY   STATUS             RESTARTS         AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">benchmark-worker-5765dbfb55-2gckc                                 1/1     Running            34 (5m40s ago)   4h1m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">benchmark-worker-5765dbfb55-6mckn                                 1/1     Running            26 (69m ago)     3h46m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">benchmark-worker-5765dbfb55-qtrmm                                 0/1     CrashLoopBackOff   33 (4m20s ago)   4h1m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ck-bojan-rest-benchmark-prometheus-elasticsearch-exporter-v7nqk   1/1     Running            0                3h46m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ck-bojan-rest-benchmark-zeebe-0                                   1/1     Running            0                4h1m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ck-bojan-rest-benchmark-zeebe-1                                   1/1     Running            0                107m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ck-bojan-rest-benchmark-zeebe-2                                   1/1     Running            0                4h1m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elastic-0                                                         1/1     Running            0                3h45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elastic-1                                                         1/1     Running            0                4h1m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elastic-2                                                         1/1     Running            0                4h1m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-29188095-9gdhd                                    0/1     Completed          0                8m39s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-677bc5cb4-pr7xq                                           1/1     Running            0                3h46m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Investigating the respective pods, we can see that they are failing because of OOM errors.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    Last State:     Terminated</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Reason:       OOMKilled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Exit Code:    137</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Started:      Mon, 30 Jun 2025 14:15:14 +0200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Finished:     Mon, 30 Jun 2025 14:18:00 +0200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Ready:          True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Restart Count:  34</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Limits:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      cpu:     500m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      memory:  256Mi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Requests:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      cpu:     500m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      memory:  256Mi</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>Our first experiment failed to validate our expectation of:</p>
<blockquote>
<p>When using the REST API we expect some more overhead (maybe ~10%), like serializing and sending data over the wire (as gRPC is optimized for it). In general, we expect a stable performing system.</p>
</blockquote>
<ul>
<li>âŒ<!-- --> We were not able to prove that our load tests run with simply enabling the REST API with minimal impact</li>
<li>âŒ<!-- --> The performance of the system was not stable.</li>
<li>âŒ<!-- --> The workers, can't work with the same amount of memory they used before for gRPC.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment-pt-2">Chaos Experiment (Pt. 2)<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#chaos-experiment-pt-2" class="hash-link" aria-label="Direct link to Chaos Experiment (Pt. 2)" title="Direct link to Chaos Experiment (Pt. 2)">â€‹</a></h2>
<p>To validate whether our experiment would work with the REST API and the workers having more memory, we increase the resource usage of the workers.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    State:          Running</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Started:      Mon, 30 Jun 2025 14:25:40 +0200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Ready:          True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Restart Count:  0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Limits:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      cpu:     500m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      memory:  1Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Requests:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      cpu:     500m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      memory:  1Gi</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h2>
<p>When the client applications have enough resources the expected performance of the REST API usage should be minimally lower than with the gRPC API. The system should perform stable.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h2>
<p>As soon as we configured the workers, and gave them more memory, they stopped to crash loop. Still we are not able to reache the same performance (not even close) as with our normal base (weekly benchmark).</p>
<p><img decoding="async" loading="lazy" alt="exp2-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp2-general-0406467c1e3f8ae9f58baf590ea95e4f.png" width="1901" height="903" class="img_ev3q"></p>
<p>The performance (after 1430) looks more stale (less fluctuating), but still not well.</p>
<p><img decoding="async" loading="lazy" alt="exp2-push" src="https://camunda.github.io/zeebe-chaos/assets/images/exp2-push-aae3cba4d20f09d18e83303fa116cdc7.png" width="1892" height="341" class="img_ev3q"></p>
<p>We seem to push more jobs out, on a constant rate. Looking at the logstream metrics, we can see that we rejecting a lot of commands, especially COMPLETEs and FAILs.</p>
<p><img decoding="async" loading="lazy" alt="exp2-log" src="https://camunda.github.io/zeebe-chaos/assets/images/exp2-log-8c650f58f451d54cad986da8f575e166.png" width="1893" height="336" class="img_ev3q"></p>
<p>We see interesting warning logs by the workers:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">12:40:07.532 [pool-4-thread-2] WARN  io.camunda.client.job.worker - Worker benchmark failed to handle job with key 4503599643648545 of type benchmark-task, sending fail command to broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">java.lang.IllegalStateException: Queue full</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ArrayBlockingQueue.add(ArrayBlockingQueue.java:329) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.Worker.lambda$handleJob$1(Worker.java:122) ~[classes/:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.JobRunnableFactoryImpl.executeJob(JobRunnableFactoryImpl.java:45) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.JobRunnableFactoryImpl.lambda$create$0(JobRunnableFactoryImpl.java:40) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.BlockingExecutor.lambda$execute$0(BlockingExecutor.java:50) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.lang.Thread.run(Thread.java:1583) [?:?]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>I think it is not fully clear what the user should do with this. AFAIK, based on the implementation, it is also not how we expected it to behave, as we wanted to block in this case.</p>
<p><img decoding="async" loading="lazy" alt="exp2-snapshot" src="https://camunda.github.io/zeebe-chaos/assets/images/exp2-snapshots-81650c422f7258308963327c14669cb8.png" width="940" height="318" class="img_ev3q"></p>
<p>We can see that even when we recover the workers, with more memory, we are not able to come back to a performing system. This is likely because we aggregated already quite some data, and are running in some weird timeout and completion/fail loops. This needs further investigation (follow-up).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment-pt-3">Chaos Experiment (Pt. 3)<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#chaos-experiment-pt-3" class="hash-link" aria-label="Direct link to Chaos Experiment (Pt. 3)" title="Direct link to Chaos Experiment (Pt. 3)">â€‹</a></h2>
<p>With our third experiment, we want to validate how our load tests perform with some clean state, and workers set up correctly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>See above.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>With no previous data and stable workers, we seem to be able to reach higher throughput again.</p>
<p><img decoding="async" loading="lazy" alt="exp3-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-general-aeb1fc9dd70c0196e2d8dc69606a372c.png" width="1877" height="884" class="img_ev3q"></p>
<p>The latency looks fairly similar to our base (weekly) benchmarks. Here again, 99% of PIs need less than 0.25 seconds to complete.</p>
<p><img decoding="async" loading="lazy" alt="exp3-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-latency-55ecd2393d8199b12edb2cd098c83249.png" width="1892" height="611" class="img_ev3q"></p>
<p>After a while, the load tests seem to behave similarly to the previous ones, reporting several timeouts and completion rejections.</p>
<p><img decoding="async" loading="lazy" alt="exp3-jobs" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-jobs-rejections-09cfb799b115c8ae5ebbc9c70fbf870e.png" width="1898" height="337" class="img_ev3q"></p>
<p>This is degrading the performance completely.</p>
<p><img decoding="async" loading="lazy" alt="exp3-general-drop" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-general-drop-b6c30790b698047dd290286c8861f203.png" width="1884" height="912" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="exp3-latency-mess" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-latency-mess-bfc491d125d481bc98e8a0e036c0ffed.png" width="1886" height="636" class="img_ev3q"></p>
<p>Our workers seem to report similar issues as before, regarding having a full queue:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">13:25:14.684 [pool-4-thread-3] WARN  io.camunda.client.job.worker - Worker benchmark failed to handle job with key 4503599628992806 of type benchmark-task, sending fail command to broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">java.lang.IllegalStateException: Queue full</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ArrayBlockingQueue.add(ArrayBlockingQueue.java:329) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.Worker.lambda$handleJob$1(Worker.java:122) ~[classes/:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.JobRunnableFactoryImpl.executeJob(JobRunnableFactoryImpl.java:45) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.JobRunnableFactoryImpl.lambda$create$0(JobRunnableFactoryImpl.java:40) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.client.impl.worker.BlockingExecutor.lambda$execute$0(BlockingExecutor.java:50) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>âŒ<!-- --> Right now it seems that the usage of the REST API can impact the general performance of the system (even with the usage of the Job streaming in the workers). As of now it is not clear why, which we have to further investigate and clarify.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://camunda.github.io/zeebe-chaos/2025/06/30/Performance-of-REST-API#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h2>
<p>Following issues and follow ups have been noted down</p>
<ul>
<li>REST API usage affects highly general performance of the system</li>
<li>REST API observability is missing</li>
<li>Clients using the REST API have higher memory usage</li>
<li>Worker seem to fail with unexpected error/warning messages when receiving jobs.</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[How does Zeebe behave with NFS]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS"/>
        <updated>2025-06-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[This week, we (Lena, Nicolas, Roman, and I) held a workshop where we looked into how Zeebe behaves with network file storage (NFS).]]></summary>
        <content type="html"><![CDATA[<p>This week, we (<a href="https://github.com/lenaschoenburg" target="_blank" rel="noopener noreferrer">Lena</a>, <a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer">Nicolas</a>, <a href="https://github.com/romansmirnov" target="_blank" rel="noopener noreferrer">Roman</a>, and <a href="https://github.com/ChrisKujawa" target="_blank" rel="noopener noreferrer">I</a>) held a workshop where we looked into how Zeebe behaves with network file storage (NFS).</p>
<p>We ran several experiments with NFS and Zeebe, and messing around with connectivity.</p>
<p><strong>TL;DR;</strong> We were able to show that NFS can handle certain connectivity issues, just causing Zeebe to process slower. IF we completely lose the connection to the NFS server, several issues can arise, like IOExceptions on flush (where RAFT goes into inactive mode) or SIGBUS errors on reading (like replay), causing the JVM to crash.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#setup" class="hash-link" aria-label="Direct link to Setup" title="Direct link to Setup">â€‹</a></h2>
<blockquote>
<p>Note:</p>
<p>You can skip this section if you're not interested in how we set up the NFS server</p>
</blockquote>
<p>For our experiments, we want to have a quick feedback loop and small blast radius, meaning avoiding using K8, or any other cloud services. The idea was to set up a NFS server via docker, and mess with the network, to cause NFS errors.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="run-nfs-docker-container">Run NFS Docker Container<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#run-nfs-docker-container" class="hash-link" aria-label="Direct link to Run NFS Docker Container" title="Direct link to Run NFS Docker Container">â€‹</a></h3>
<p>After a smaller research we were able <a href="https://github.com/normal-computing/docker-nfs-server" target="_blank" rel="noopener noreferrer">to find a project</a>, that provides us a NFS server docker image.</p>
<p>This can be run via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo podman run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   # Needs privileged access for setting up the exports rule, etc\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --privileged</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  # Mounting a local directory as volume into the container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -v /home/cqjawa/nfs-workshop/nfs:/mnt/data:rw  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   # expose the NFS por</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -p 2049:2049t \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   # Allowing the local host IP to access the NFS server </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e NFS_SERVER_ALLOWED_CLIENTS=10.88.0.0/12 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   # Enable DEBUG LOGS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e NFS_SERVER_DEBUG=1 \ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ghcr.io/normal-computing/nfs-server:latest</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mount-the-nfs-to-local-file-storage">Mount the NFS to local file storage<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#mount-the-nfs-to-local-file-storage" class="hash-link" aria-label="Direct link to Mount the NFS to local file storage" title="Direct link to Mount the NFS to local file storage">â€‹</a></h3>
<p>To use the NFS server and make it available to our Zeebe container, we first have to mount it via the NFS client.</p>
<p>This can be done via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo mount -v -t nfs4 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -o proto=tcp,port=2049,soft,timeo=10 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  localhost:/ \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ~/nfs-workshop/nfs-client-mount/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li><code>-v</code> verbose</li>
<li><code>-t</code> file system type: tells the client to use NFS4</li>
<li><code>-o</code> Options for the mount: <code>proto=tcp,port=2049,soft,timeo=10</code>
<ul>
<li>Protocol options, like transport via <code>tcp</code>, port to be used, <a href="https://kb.netapp.com/on-prem/ontap/da/NAS/NAS-KBs/What_are_the_differences_between_hard_mount_and_soft_mount" target="_blank" rel="noopener noreferrer">soft mount</a> to make sure to retry on unavailability and not block, timeout after 10s</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="run-the-zeebe-container">Run the Zeebe Container<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#run-the-zeebe-container" class="hash-link" aria-label="Direct link to Run the Zeebe Container" title="Direct link to Run the Zeebe Container">â€‹</a></h3>
<p>After we mounted the NFS to our local filesystem, we can start our Zeebe container.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> podman run -d \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   -v /home/cqjawa/nfs-workshop/nfs-client-mount/:/usr/local/zeebe/data \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   -p 26500:26500 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   -p 9600:9600 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   gcr.io/zeebe-io/zeebe:8.7.5-root</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This is mounting our NFS mounted directory into the container as the data directory for the Zeebe container.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="running-load">Running load<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#running-load" class="hash-link" aria-label="Direct link to Running load" title="Direct link to Running load">â€‹</a></h3>
<p>For simplicity, we used <code>zbctl</code> to start some load. As a first step, we had to deploy a process model.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> zbctl --insecure deploy one_task.bpmn </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This was using the <a href="https://github.com/camunda/zeebe-chaos/blob/main/go-chaos/internal/bpmn/one_task.bpmn" target="_blank" rel="noopener noreferrer">one_task.bpmn</a> from <code>go-chaos/</code>.</p>
<p>Creating instances in a loop:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">while [[ true ]];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">do </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    zbctl --insecure \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    create instance 2251799813685250;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sleep 5;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">done</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Running worker:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> zbctl --insecure \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   create worker "benchmark-task"  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   --handler "echo {\"result\":\"Pong\"}"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment---use-iptables-with-containerized-nfs-server">Chaos Experiment - Use iptables with containerized NFS Server<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#chaos-experiment---use-iptables-with-containerized-nfs-server" class="hash-link" aria-label="Direct link to Chaos Experiment - Use iptables with containerized NFS Server" title="Direct link to Chaos Experiment - Use iptables with containerized NFS Server">â€‹</a></h2>
<p>We wanted to disrupt the NFS connections with <code>iptables</code> and cause some errors.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We can drop packages with <code>iptables</code>, and we can observe errors in the Zeebe container logs.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Setting up the following iptables rule should allow us to disrupt the NFS connection, but it didn't worked.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo iptables -A OUTPUT -p tcp --dport 2049 --sport 2049 -d localhost -j DROP</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>At the end we were setting up a lots of different rules, but nothing seem to work.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Every 1.0s: sudo iptables -L -v                                                                                                             cq-p14s: Thu Jun 12 16:01:28 2025</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Chain INPUT (policy ACCEPT 6090K packets, 11G bytes)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> pkts bytes target     prot opt in     out     source               destination</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             cq-p14s              tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             10.0.88.5            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             10.0.88.1            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             10.88.0.5            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             cq-p14s              tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             anywhere             tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> pkts bytes target     prot opt in     out     source               destination</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Chain OUTPUT (policy ACCEPT 6182K packets, 22G bytes)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> pkts bytes target     prot opt in     out     source               destination</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             0.0.0.0              tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             cq-p14s              tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             localhost            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             11.0.88.5            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             10.0.88.5            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             0.0.0.0              tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             10.0.88.1            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             10.88.0.5            tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             cq-p14s              tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    0     0 DROP       tcp  --  any    any     anywhere             anywhere             tcp spt:nfs dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We even suspended the NFS server, via <code>docker pause</code>. We were able to observe that data was still synced between directories.</p>
<p>This was some indication for us, that the kernel might do some magic behind the scenes, and the NFS server didn't worked as we expected it to.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment---use-iptables-with-an-external-nfs-server">Chaos Experiment - Use iptables with an external NFS Server<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#chaos-experiment---use-iptables-with-an-external-nfs-server" class="hash-link" aria-label="Direct link to Chaos Experiment - Use iptables with an external NFS Server" title="Direct link to Chaos Experiment - Use iptables with an external NFS Server">â€‹</a></h2>
<p>As we were not able to disrupt the network, we thought it might make sense to externalize the NFS server (to a different host).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup-external-nfs">Setup external NFS<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#setup-external-nfs" class="hash-link" aria-label="Direct link to Setup external NFS" title="Direct link to Setup external NFS">â€‹</a></h3>
<p>We followed <a href="https://idroot.us/install-nfs-server-fedora-41" target="_blank" rel="noopener noreferrer">this guide</a>, to set up a NFS server running on a different machine.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mount-external-nfs">Mount external NFS<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#mount-external-nfs" class="hash-link" aria-label="Direct link to Mount external NFS" title="Direct link to Mount external NFS">â€‹</a></h3>
<p>The mounting was quite similar to before, now using a different host</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo  mount -v -t nfs4 -o proto=tcp,port=2049,soft,timeo=10 192.168.24.110:/ ~/nfs-workshop/nfs-client-mount/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="run-zeebe-container">Run Zeebe Container<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#run-zeebe-container" class="hash-link" aria-label="Direct link to Run Zeebe Container" title="Direct link to Run Zeebe Container">â€‹</a></h3>
<p>The same for running the Zeebe container.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">podman run -d -v /home/cqjawa/nfs-workshop/nfs-client-mount/srv/nfs/:/usr/local/zeebe/data -p 26500:26500 -p 9600:9600 gcr.io/zeebe-io/zeebe:8.7.5-root</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We were expecting some errors during processing and writing when the connection was completely dropped.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Similar to previous <code>iptables</code> we dropped all outgoing packages for the port <code>2049</code> with the new destination.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo iptables -A OUTPUT -p tcp --dport 2049 -d 192.168.24.110 -j DROP</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Every 1.0s: sudo iptables -L -v                                                                                                            cq-p14s: Thu Jun 12 16:13:44 2025</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Chain INPUT (policy ACCEPT 6211K packets, 11G bytes)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> pkts bytes target     prot opt in     out     source               destination</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> pkts bytes target     prot opt in     out     source               destination</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Chain OUTPUT (policy ACCEPT 6297K packets, 23G bytes)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> pkts bytes target     prot opt in     out     source               destination</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   35 2064K DROP       tcp  --  any    any     anywhere             192.168.24.110	 tcp dpt:nfs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now we were actually able to observe some errors. The clients were receiving <code>DEADLINE EXCEEDED</code> exceptions (starter and worker).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2025/06/12 16:14:03 Failed to activate jobs for worker 'zbctl': rpc error: code = DeadlineExceeded desc = context deadline exceeded</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Error: rpc error: code = DeadlineExceeded desc = context deadline exceeded</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Error: rpc error: code = DeadlineExceeded desc = context deadline exceeded</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Error: rpc error: code = DeadlineExceeded desc = stream terminated by RST_STREAM with error code: CANCEL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Error: rpc error: code = DeadlineExceeded desc = context deadline exceeded</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After some time running with the disconnected NFS server, Zeebe actually failed to flush</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:02:00.819] [raft-server-0-1] [{actor-name=raft-server-1, actor-scheduler=Broker-0, partitionId=1, raft-role=LEADER}] ERROR</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        io.atomix.raft.impl.RaftContext - An uncaught exception occurred, transition to inactive role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">java.io.UncheckedIOException: java.io.IOException: Input/output error (msync with parameter MS_SYNC failed)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.nio.MappedMemoryUtils.force(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.nio.Buffer$2.force(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/jdk.internal.misc.ScopedMemoryAccess.forceInternal(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/jdk.internal.misc.ScopedMemoryAccess.force(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.nio.MappedByteBuffer.force(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.nio.MappedByteBuffer.force(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.camunda.zeebe.journal.file.Segment.flush(Segment.java:125) ~[zeebe-journal-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.camunda.zeebe.journal.file.SegmentsFlusher.flush(SegmentsFlusher.java:58) ~[zeebe-journal-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.camunda.zeebe.journal.file.SegmentedJournalWriter.flush(SegmentedJournalWriter.java:125) ~[zeebe-journal-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.camunda.zeebe.journal.file.SegmentedJournal.flush(SegmentedJournal.java:173) ~[zeebe-journal-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.raft.storage.log.RaftLogFlusher$DirectFlusher.flush(RaftLogFlusher.java:73) ~[zeebe-atomix-cluster-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.raft.storage.log.RaftLog.flush(RaftLog.java:196) ~[zeebe-atomix-cluster-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.raft.impl.RaftContext.setCommitIndex(RaftContext.java:538) ~[zeebe-atomix-cluster-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.raft.roles.LeaderAppender.appendEntries(LeaderAppender.java:560) ~[zeebe-atomix-cluster-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.raft.roles.LeaderRole.replicate(LeaderRole.java:740) ~[zeebe-atomix-cluster-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.raft.roles.LeaderRole.safeAppendEntry(LeaderRole.java:735) ~[zeebe-atomix-cluster-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.raft.roles.LeaderRole.lambda$appendEntry$15(LeaderRole.java:701) ~[zeebe-atomix-cluster-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at io.atomix.utils.concurrent.SingleThreadContext$WrappedRunnable.run(SingleThreadContext.java:178) ~[zeebe-atomix-utils-8.7.5.jar:8.7.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.lang.Thread.run(Unknown Source) [?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: java.io.IOException: Input/output error (msync with parameter MS_SYNC failed)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        at java.base/java.nio.MappedMemoryUtils.force0(Native Method) ~[?:?]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ... 24 more</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This caused the RAFT Leader role to become inactive, and uninstalling all related services.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">INFO io.atomix.raft.impl.RaftContext - Transitioning to INACTIVE</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Furthermore, interesting is that the <code>DiskSpaceMonitor</code> was detecting OOD and pausing the stream processor.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:02:00.795] [zb-actors-0] [{actor-name=DiskSpaceUsageMonitorActor, actor-scheduler=Broker-0}] WARN </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        io.camunda.zeebe.broker.system - Out of disk space. Current available 0 bytes. Minimum needed 2147483648 bytes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:02:00.796] [zb-actors-0] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] WARN </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        io.camunda.zeebe.broker.system - Disk space usage is above threshold. Pausing stream processor.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>At the end, the system was not running anymore. This means availability was impacted, but not durability, as we do not write anything wrong (or do not continue with dirty data)</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment-3---random-dropping-packages">Chaos Experiment 3 - Random dropping packages<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#chaos-experiment-3---random-dropping-packages" class="hash-link" aria-label="Direct link to Chaos Experiment 3 - Random dropping packages" title="Direct link to Chaos Experiment 3 - Random dropping packages">â€‹</a></h2>
<p>It is possible with <code>iptables</code> to randomly drop packages, allow to validate how the system behaves on certain package loss.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expected that here the system might also fail, potentially, with some exceptions.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Running the following command sets up an <code>iptables</code> rule that drops random packets with <code>80%</code> probability for destination port <code>2049</code></p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo iptables -A OUTPUT -p tcp --dport 2049 -d 192.168.24.110 -m statistic --mode random --probability 0.80 -j DROP</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>As NFS is TCP based it seem to be that NFS can handle certain data/package loss, and is repeating the packages.</p>
<p>The general processing was much slower, this was observed by the rate of how many instances were created and jobs completed.</p>
<p>Other than that the system continued to run healthy.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment-4---drop-connection-on-reading">Chaos Experiment 4 - Drop connection on reading<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#chaos-experiment-4---drop-connection-on-reading" class="hash-link" aria-label="Direct link to Chaos Experiment 4 - Drop connection on reading" title="Direct link to Chaos Experiment 4 - Drop connection on reading">â€‹</a></h2>
<p>We wanted to cause some SIGBUS errors, as we knew this can happen with mmapped files, like it is used in Zeebe. This might be reproduced on reading of memory mapped data.</p>
<p>For this we planned to create a lot of data on our Zeebe system and restarting it, causing Zeebe to fail on replay when the connection is blocked.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-3">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#expected-3" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expected that during read, we would cause a SIGBUS, causing the system to crash</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-3">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#actual-3" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>To make sure we are creating continuous segments, and not compacting (causing longer replay) we increased the snapshot period and reduced the log segment size.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">podman run -d \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -v /home/cqjawa/nfs-workshop/nfs-client-mount/srv/nfs/:/usr/local/zeebe/data \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -p 26500:26500 -p 9600:9600 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e ZEEBE_BROKER_THREADS_CPUTHREADCOUNT=2 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e ZEEBE_BROKER_THREADS_IOTHREADCOUNT=2 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e ZEEBE_BROKER_DATA_LOGSEGMENTSIZE=16MB \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e ZEEBE_BROKER_DATA_SNAPSHOTPERIOD=8h \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  gcr.io/zeebe-io/zeebe:8.7.5-root</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>First we set up an <code>iptable</code> rule to make sure that the reading was slower from NFS (by random dropping ~80% of packages).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo iptables -A OUTPUT -p tcp --dport 2049 -d 192.168.24.110 -m statistic --mode random --probability 0.80 -j DROP</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.543] [zb-actors-1] [{actor-name=StreamProcessor-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.processor - Processor starts replay of events. [snapshot-position: 611, replay-mode: PROCESSING]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>When we saw that the StreamProcessor was starting with replay we started to drop packages again completely.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo iptables -A OUTPUT -p tcp --dport 2049 -d 192.168.24.110 -j DROP</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After a certain period of time, we ran into a SIGBUS Error</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.543] [zb-actors-1] [{actor-name=StreamProcessor-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.processor - Processor starts replay of events. [snapshot-position: 611, replay-mode: PROCESSING]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.545] [zb-actors-1] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - Transition to LEADER on term 4 - transitioning CommandApiService</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.547] [zb-actors-1] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - Transition to LEADER on term 4 - transitioning SnapshotDirector</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.549] [zb-actors-1] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - Transition to LEADER on term 4 - transitioning ExporterDirector</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.555] [zb-actors-1] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - Transition to LEADER on term 4 - transitioning BackupApiRequestHandler</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.557] [zb-actors-1] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - Transition to LEADER on term 4 - transitioning Admin API</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.558] [zb-actors-1] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - Transition to LEADER on term 4 completed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.561] [zb-actors-1] [{actor-name=ZeebePartition-1, actor-scheduler=Broker-0, partitionId=1}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - ZeebePartition-1 recovered, marking it as healthy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2025-06-12 09:25:00.562] [zb-actors-1] [{actor-name=HealthCheckService, actor-scheduler=Broker-0}] INFO </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	io.camunda.zeebe.broker.system - Partition-1 recovered, marking it as healthy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># A fatal error has been detected by the Java Runtime Environment:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#  SIGBUS (0x7) at pc=0x00007f89ec4601a5, pid=2, tid=49</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># JRE version: OpenJDK Runtime Environment Temurin-21.0.7+6 (21.0.7+6) (build 21.0.7+6-LTS)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Java VM: OpenJDK 64-Bit Server VM Temurin-21.0.7+6 (21.0.7+6-LTS, mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, linux-amd64)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Problematic frame:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># v  ~StubRoutines::updateBytesCRC32C 0x00007f89ec4601a5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Core dump will be written. Default location: Core dumps may be processed with "/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %d" (or dumping to /usr/local/zeebe/core.2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># An error report file with more information is saved as:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># /usr/local/zeebe/hs_err_pid2.log</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[275.689s][warning][os] Loading hsdis library failed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># If you would like to submit a bug report, please visit:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#   https://github.com/adoptium/adoptium-support/issues</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This caused the JVM to crash and stop the Docker container, as expected.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://camunda.github.io/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">â€‹</a></h2>
<p>With the workshop on experimenting with NFS, we got several learnings on how Zeebe and NFS behave on connectivity issues, summarized as follows:</p>
<ul>
<li>We could confirm that network errors lead to unrecoverable SIGBUS errors, which cause the broker to crash.<!-- -->
<ul>
<li>This is due primarily to our usage of mmap both in RocksDB and Zeebe.</li>
<li>There is an easy workaround with RocksDB where you can simply turn off mmap, but no such workaround exists in Zeebe at the moment.</li>
<li>This only impacts availability as the application crashes, but since Zeebe is designed to be crash resilient, so no inconsistencies or data corruption.</li>
<li>We donâ€™t have a clear idea of the frequency of these errors - itâ€™s essentially environment-based (i.e., how bad the network connectivity is).</li>
</ul>
</li>
<li>With only partial connectivity (simulated by dropping packets, e.g. 70% of packets), we mostly observed performance issues, as things got slower; however, messages were retried, so no errors occurred.</li>
<li>Network errors when using normal file I/O resulted in IOException as expected.<!-- -->
<ul>
<li>This caused the Raft partition to go inactive, for example, when the leader fails to flush on commit (a known issue which is already planned to be fixed for graceful error handling).</li>
</ul>
</li>
<li>When the NFS server was unavailable, the disk space monitor detected that there was no more disk space available, and writes stopped.</li>
<li>Did not test that it recovers when the server is back, but we expect it would.</li>
<li><strong>Minor</strong>, but we should open an issue for it:<!-- -->
<ul>
<li>When the leader goes inactive, we report an internal error that there is no message handler for command-api-1, but really we should be returning an UNAVAILABLE as a proper error, and not logging this as error level (we have other means to detect this).</li>
</ul>
</li>
</ul>
<p>What does this mean?</p>
<ul>
<li>We can say Zeebe can work with NFS, but it is not yet supported.</li>
<li>We need to improve certain error handling, like flushing errors, to better support it.</li>
<li>When operating Zeebe on bare-metal and having an unreliable environment SIGBUS might be more likely and crashin JVM be more problematic then using an K8 deployment, where pods automatically getting rescheduled</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lower memory consumption of Camunda deployment]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment</id>
        <link href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment"/>
        <updated>2025-06-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[I'm back to finally do some load testing again.]]></summary>
        <content type="html"><![CDATA[<p>I'm back to finally do some load testing again.</p>
<p>In the past months, we have changed our architecture. This was to deploy instead all of our components as a separate deployment,
we now have one single statefulset. This statefulset is running our single Camunda standalone application,
combining all components together.</p>
<p><img decoding="async" loading="lazy" alt="simpler deployment" src="https://camunda.github.io/zeebe-chaos/assets/images/simpler-deployment-a09568ddfb813f18a49e6b930b43cd02.png" width="1550" height="744" class="img_ev3q"></p>
<p>More details on this change we will share on a separate blog post. For simplicity, in our load tests (benchmark helm charts), we
combined all the resources we had split over multiple deployments together, see related PR <a href="https://github.com/camunda/zeebe-benchmark-helm/pull/213" target="_blank" rel="noopener noreferrer">#213</a>.</p>
<p>We are currently running our test with the following resources by default:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Limits</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">     </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">  12Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">      </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">   6Gi</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In today's Chaos day, I want to look into our resource consumption and whether we can reduce our used requests and limits.</p>
<p><strong>TL;DR;</strong> We have focused on experimenting with different memory resources, and were able to show that we can reduce the used memory by 75%, and our previous provisioned resources by more than 80% for our load tests.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="checking-weekly-benchmarks">Checking weekly benchmarks<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#checking-weekly-benchmarks" class="hash-link" aria-label="Direct link to Checking weekly benchmarks" title="Direct link to Checking weekly benchmarks">â€‹</a></h2>
<p>Before I started to experiment and reduce it. I validated whether we actually have room for improvement. For that, I check our
weekly load tests. These are tests we start every week, that are running for four weeks straight. These can be used as a good reference point (base).</p>
<p>I picked the mixed load test, which is running our realistic benchmark using a  more complex process model, covering more elements, etc.</p>
<p><img decoding="async" loading="lazy" alt="base general" src="https://camunda.github.io/zeebe-chaos/assets/images/base-general-1810c584609ed65136c09a5f71d8a37c.png" width="2536" height="814" class="img_ev3q"></p>
<p>When we look at the general metrics, we can see it reaches, on average, ~100 task completions per second. As we use pre-emptive nodes, it might happen that workers, starters, or even the Camunda application are restarted in between.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="memory-consumption">Memory consumption<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#memory-consumption" class="hash-link" aria-label="Direct link to Memory consumption" title="Direct link to Memory consumption">â€‹</a></h3>
<p>Looking at the memory consumption, we can see that we still have quite some headroom.</p>
<p><img decoding="async" loading="lazy" alt="base-memory" src="https://camunda.github.io/zeebe-chaos/assets/images/base-memory-0b344e9b0b510706893f539ddf6cd706.png" width="2526" height="679" class="img_ev3q"></p>
<p>Our deployments use between three and four gigabytes of memory, which is divided by the JVM heap, JVM metaspace, native memory usage like RocksDB, off-heap usage etc.</p>
<p>For example, we can see that the JVM uses less than one gigabyte for the heap, but can use up to ~3.5 gigabytes for its heap. This is related to the default JVM settings, which are ~25% of the available memory on the machine.</p>
<p><img decoding="async" loading="lazy" alt="base-jvm-mem" src="https://camunda.github.io/zeebe-chaos/assets/images/base-jvm-mem-d5f051e14aa368b1d2c62e34a2f63e9f.png" width="2525" height="814" class="img_ev3q"></p>
<p><a href="https://rocksdb.org/" target="_blank" rel="noopener noreferrer">RocksDB</a>, the embedded key-value store that Zeebe uses to store its state, is per default configured to use 512 MB per partition. We can observe via exposed metrics this as well.</p>
<p><img decoding="async" loading="lazy" alt="base-rocksdb" src="https://camunda.github.io/zeebe-chaos/assets/images/base-rocksdb-422c1286330affafa269cf82a78f67f6.png" width="1291" height="445" class="img_ev3q"></p>
<p>We can set this memory limit for RocksDB via an <a href="https://github.com/camunda/camunda/blob/main/zeebe/broker/src/main/java/io/camunda/zeebe/broker/system/configuration/RocksdbCfg.java#L23" target="_blank" rel="noopener noreferrer">experimental configuration</a>. For example, via environment variable: <code>ZEEBE_BROKER_EXPERIMENTAL_ROCKSDB_MEMORYLIMIT</code> or property: <code>zeebe.broker.experimental.rocksdb.memoryLimit</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cpu-consumption">CPU Consumption<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#cpu-consumption" class="hash-link" aria-label="Direct link to CPU Consumption" title="Direct link to CPU Consumption">â€‹</a></h3>
<p>After having checked the memory consumption, we can look at the CPU consumption. As mentioned earlier, we are running a rather more complex orchestration use case that involves more work on processing, exporting, etc.</p>
<p>Here we can already see that we scratch on our limits, we can observe some throttling for some of our pods.</p>
<p><img decoding="async" loading="lazy" alt="base-cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/base-cpu-6119877156e48cc719837cbea83f6406.png" width="2536" height="836" class="img_ev3q"></p>
<p>For today, I will focus on the memory consumption to improve it. We might want to look into the CPU consumption on another day.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-experiment-reduce-memory-limits-generally">1. Experiment: Reduce memory limits generally<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#1-experiment-reduce-memory-limits-generally" class="hash-link" aria-label="Direct link to 1. Experiment: Reduce memory limits generally" title="Direct link to 1. Experiment: Reduce memory limits generally">â€‹</a></h2>
<p>As a first experiment, I tried to reduce the general memory to something which I thought made sense based on the observation I made earlier. This means setting requests and limits to four gigabytes.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Limits</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">     </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">  4Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">      </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">   4Gi</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>This is a 66% decrease from the previous limit and a 33% decrease from the previous used requests!</strong></p>
<p>Be aware that I set both to the same value on purpose. This is to make sizing, scheduling, and memory management more predictable. Furthermore, to reduce the chance of getting OOMs/killed/evicted.</p>
<p>The memory request is used for Kubernetes pod scheduling. This means the limit is not a guaranteed size, but more like a guard to prevent the container to use more. If a container uses more than its requests <a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#how-pods-with-resource-limits-are-run" target="_blank" rel="noopener noreferrer">there is a chance to be evicted</a>, if the node becomes memory pressure. If it exceeds its limits, it will be killed eventually by the kernel.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>As we observed in our weekly load test, we are able to use less than 1 gigabyte of Java Heap, which is ~25% of four gigabytes, and we normally use three partitions, a 512 MB (~1,5 Gi). I expect that four gigabytes of memory should perform well.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>The general performance is comparable to our base, we do not spot any frequent restarts.</p>
<p><img decoding="async" loading="lazy" alt="exp1-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp1-general-7128fa232db70f766d4d151b7615dc66.png" width="2537" height="812" class="img_ev3q"></p>
<p>Looking at the memory, we see that we are able to run with the reduced memory as well.</p>
<p><img decoding="async" loading="lazy" alt="exp1-memory" src="https://camunda.github.io/zeebe-chaos/assets/images/exp1-memory-a0022c52dbde111fc9f7672bd0233358.png" width="2542" height="686" class="img_ev3q"></p>
<p>The JVM memory usage even shows us that we are able to use less memory; previously, we used ~1 gig as heap, now it is around 256 MB.</p>
<p><img decoding="async" loading="lazy" alt="exp1-jvm-mem" src="https://camunda.github.io/zeebe-chaos/assets/images/exp1-jvm-c6425242afa3b3d55ee336e1d900a00b.png" width="2529" height="943" class="img_ev3q"></p>
<p><strong>This gives us room for further improvement. Let's continue with Experiment 2</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-experiment-reduce-memory-limits-and-rocksdb-memory">2. Experiment: Reduce memory limits and RocksDB memory<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#2-experiment-reduce-memory-limits-and-rocksdb-memory" class="hash-link" aria-label="Direct link to 2. Experiment: Reduce memory limits and RocksDB memory" title="Direct link to 2. Experiment: Reduce memory limits and RocksDB memory">â€‹</a></h2>
<p>With the results from Experiment 1, I was confident that we could run with less memory. I was wondering what if we reduced the memory limit of RocksDB.</p>
<p>As mentioned earlier can be done via a property or an environment variable. For our next experiment, I set our limit
to 128 MB. This is a 75% reduction of previous used memory for RocksDB per partition.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">zeebe.broker.experimental.rocksdb.memoryLimit: 128MB</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We are running similar configurations in our SaaS environment, so I knew this is working, but I don't know how this behaves on a more complex use case and benchmark.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>My expectation would be that the general memory consumption is reduced, not affecting the JVM. Our load test should run stable still.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Indeed, the general performance looks similar, with some smaller outliers but still performing good.</p>
<p><img decoding="async" loading="lazy" alt="exp2-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp1-general-7128fa232db70f766d4d151b7615dc66.png" width="2537" height="812" class="img_ev3q"></p>
<p>We reduced the memory consumption for the process by half! It is now around 1.5 gigabytes, while it was in the previous experiment around three gigabytes, and at the start, close to four.</p>
<p><img decoding="async" loading="lazy" alt="exp2-mem" src="https://camunda.github.io/zeebe-chaos/assets/images/exp2-mem-75890aed27482f1dd3ada3d784ede776.png" width="2533" height="678" class="img_ev3q"></p>
<p>In our RocksDB related metrics, we are able to observe the actual size of our RocksDB instance as well, which is indeed 128 MB.</p>
<p><img decoding="async" loading="lazy" alt="exp2-rocks" src="https://camunda.github.io/zeebe-chaos/assets/images/exp2-rocks-10e1ac00111667891aba4ac170e4c539.png" width="1252" height="483" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-experiment-half-it">3. Experiment: Half it<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#3-experiment-half-it" class="hash-link" aria-label="Direct link to 3. Experiment: Half it" title="Direct link to 3. Experiment: Half it">â€‹</a></h2>
<p>As we were still running fine, and wanted to reach a point where it doesn't run well anymore. I simply thought about reducing our resources by half again.</p>
<p>Changing our deployment resources to two gigabytes:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Limits</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">     </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">  2Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">      </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">   2Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Configuring RocksDB memory limit to 64MB</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">zeebe.broker.experimental.rocksdb.memoryLimit: 64MB</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Similar to above, I was still expecting that it works, as we saw that the JVM usage was rather low and still performing good.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>The performance of the test still looks acceptable. We see some restarts, but they seem not to be related to memory pressure.</p>
<p><img decoding="async" loading="lazy" alt="exp3-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-general-049ecb5e64be94e0a4f4b2e14a2e70df.png" width="2540" height="821" class="img_ev3q"></p>
<p>Again, we were able to reduce the memory, but not with such big steps as before. For this load test, we have on average a ~1.2 G memory usage per pod.</p>
<p><img decoding="async" loading="lazy" alt="exp3-mem" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-mem-a52b60783e780da90b755ef2e27917aa.png" width="2529" height="680" class="img_ev3q"></p>
<p>When we look at the JVM metrics, we can see that we are getting closer to our maximum, commited, and used heap values. Still, the used heap was reduced and is now around ~128 MB in many cases.</p>
<p><img decoding="async" loading="lazy" alt="exp3-jvm" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-jvm-bcd495a0ca21ad0c2e7e44008219aaff.png" width="2523" height="815" class="img_ev3q"></p>
<p>The RocksDB instance now uses 64MB as expected.</p>
<p><img decoding="async" loading="lazy" alt="exp3-rocks" src="https://camunda.github.io/zeebe-chaos/assets/images/exp3-rocks-b70c8d2ef045b7aa63c78806f4251a84.png" width="1266" height="487" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-experiment-half-it-again">4. Experiment: Half it (again)<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#4-experiment-half-it-again" class="hash-link" aria-label="Direct link to 4. Experiment: Half it (again)" title="Direct link to 4. Experiment: Half it (again)">â€‹</a></h2>
<p>As I want to bring it to its limits, I reduced the memory resources once more by half.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Limits</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">     </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">  1Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">Requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">      </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">   1Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>But to not change too many things at once (sorry for doing it earlier <!-- -->:D<!-- -->), I kept the previous RocksDB configuration:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">zeebe.broker.experimental.rocksdb.memoryLimit: 64MB</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-3">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#expected-3" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>I felt that this might be quite low on its limits, but still expected it to work, looking at the JVM heap usage metrics.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-3">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#actual-3" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As we can see, this was a tremendous fail. The pods were in an OOM loop and never became stable.</p>
<p><img decoding="async" loading="lazy" alt="exp4-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp4-general-1bdb5219c9d872145658c9433fe2c4ec.png" width="2543" height="814" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="exp-mem" src="https://camunda.github.io/zeebe-chaos/assets/images/exp4-mem-9da511ab399a880d78f54e348223bed6.png" width="2539" height="674" class="img_ev3q"></p>
<p>With this, we were able to find our limits.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-experiment-half-rocksdb-once-more">5. Experiment: Half RocksDb once more<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#5-experiment-half-rocksdb-once-more" class="hash-link" aria-label="Direct link to 5. Experiment: Half RocksDb once more" title="Direct link to 5. Experiment: Half RocksDb once more">â€‹</a></h2>
<p>Not accepting the previous failure, I simply wanted to try out what happens when I reduce once more the RocksDB memory limit.</p>
<p>This means setting the limit to 32 MB.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">zeebe.broker.experimental.rocksdb.memoryLimit: 32MB</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-4">Expected<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#expected-4" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>At this point, this was really exploration, I had the feeling that it might help if we reduce a little the RocksDB memory.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-4">Actual<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#actual-4" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Reducing the RocksDB memory limit allowed the Camunda application to perform as before! Without any performance impact <!-- -->ðŸš€<!-- --> At the end we experienced a restart of all applications.</p>
<p><img decoding="async" loading="lazy" alt="exp5-general" src="https://camunda.github.io/zeebe-chaos/assets/images/exp5-general-e40a0738408af6ee0eed2522794ecbfa.png" width="2537" height="815" class="img_ev3q"></p>
<p>Looking at the process memory metrics, we can see that it is slowly increasing until it was OOM killed. This smells like a memory leak here.</p>
<p><img decoding="async" loading="lazy" alt="exp5-mem" src="https://camunda.github.io/zeebe-chaos/assets/images/exp5-mem-32fb8d2fdc10b858231c3b3e2e2e6cf6.png" width="2528" height="673" class="img_ev3q"></p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">   Last State:     Terminated</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Reason:       OOMKilled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Exit Code:    137</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Started:      Wed, 04 Jun 2025 20:55:59 +0200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Finished:     Thu, 05 Jun 2025 12:07:51 +0200</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The JVM seem to perform correctly, and here we can observe any increasing usage. That indicates that there might be an issue with off heap (native) memory usage.</p>
<p><img decoding="async" loading="lazy" alt="exp5-jvm" src="https://camunda.github.io/zeebe-chaos/assets/images/exp5-jvm-1174e721dc521313cec547d80141daf0.png" width="2533" height="950" class="img_ev3q"></p>
<p>Our current native memory metrics don't highlight any specific ones either. While we can see that the metaspace uses a lot of space already, which also indicates that we likely can't reduce our memory usage more (except tuning this as well).</p>
<p><img decoding="async" loading="lazy" alt="exp5-native" src="https://camunda.github.io/zeebe-chaos/assets/images/exp5-native-e04e3c78177c6a24890a79b847676d2a.png" width="2515" height="804" class="img_ev3q"></p>
<p>The RocksDB memory usage looks stable as well.</p>
<p><img decoding="async" loading="lazy" alt="exp5-rocks" src="https://camunda.github.io/zeebe-chaos/assets/images/exp5-rocks-63a34f86376ae4fa1713852623fd5ced.png" width="1266" height="482" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>With today's experiments and investigations, we were able to show that we are able to reduce our memory consumption.</p>
<p>From previously used 12 Gi limit and 6 Gi request, we were able to show that it is running with 1 Gi limit and request, when we reduce the RocksDB memory limit as well. <strong>This is an over 80-90% reduction for the assigned memory.</strong> Looking at our usage, we showed that the actual process memory usage has been reduced from ~4 Gi to 1 Gi, that is a <strong>75% reduction</strong>!</p>
<p>To reduce the chance of getting OOM more frequently (until we investigated the potential resource leak), I propose to use 2 Gi as limits and requests and 64 MB RocksDb memory limit, which was running stable as well (see <a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#3-experiment--half-it">Experiment 3</a>). This showed a memory usage of around ~1.2 Gi, which is still a <strong>70% reduction</strong> to previously, and ~70-80% reduction of assigned resources.</p>
<p>We can say this Chaos Day was a success, and I'm looking forward to the next one <!-- -->ðŸš€</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://camunda.github.io/zeebe-chaos/2025/06/05/Lower-memory-consumption-of-Camunda-deployment#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h2>
<ul>
<li>Several panels were broken related to memory, and their tooltip and legends. I fixed this during the investigation.</li>
<li>Potential native memory leak</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[News from Camunda Exporter project]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project"/>
        <updated>2024-12-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this Chaos day, we want to verify the current state of the exporter project and run benchmarks with it. Comparing]]></summary>
        <content type="html"><![CDATA[<p>In this Chaos day, we want to verify the current state of the exporter project and run benchmarks with it. Comparing
with a previous version (v8.6.6) should give us a good hint on the current state and potential improvements.</p>
<p><strong>TL;DR;</strong> The latency of user data availability has improved due to our architecture change, but we still need to fix some bugs before our planned release of the Camunda Exporter. This experiment allows us to detect three new bugs, fixing this should allow us to make the system more stable.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarks">Benchmarks<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#benchmarks" class="hash-link" aria-label="Direct link to Benchmarks" title="Direct link to Benchmarks">â€‹</a></h3>
<p>We have seen in previous experiments and benchmarks that the realistic benchmarks are not yet totally reliable, as they seem to overload at some point the system. This can happen if there is a hiccup and jobs take longer to process. Jobs in the queue are getting delayed, and time out, they are sent out to different workers, but we will reach them at some point again the jobs, and we will publish also for this job a message. This in general increases the load of the system as we have to timeout jobs, we have to handle additional message publish, etc.</p>
<p>Additionally, message publish can be rejected, when this happens we wait for another timeout adding again load on the system, more and more retries happen, etc. This breaks the benchmark performance.</p>
<p>To avoid this, we reduce the benchmark payload for now, which is in charge of creating multiple instances and call activities, etc. To be specific, they reduced the items from 50 to 5
but scaled the starter to start more instances. With this payload, we can scale more fine granular. Each instance can create 5 sub-instances, when creating three process instances  we create effectively 15 instances/token.</p>
<p>As this benchmark runs quite stable, it allows us to better compare the latency between base and main.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="details-experiment">Details Experiment<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#details-experiment" class="hash-link" aria-label="Direct link to Details Experiment" title="Direct link to Details Experiment">â€‹</a></h3>
<p>We will run two benchmarks one against 8.6.6, call based, and one against the current main branch (commit a1609130).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When running the base and the main and comparing each other we expect that the general throughput should be similar.
Furthermore, we expect that the latency until the user sees data (or data is written into ES and searchable) should be lowered on the main branch rather than on the base.</p>
<p>Note: Right now we don't have a good metric to measure that data is available for the user, we plan to implement this in the starter benchmark application at some point via querying the REST API. For now, we calculate different average latencies together, whereas we take as elastic search flush a constant of 2 seconds.</p>
<p>We expect a reduction of latency as we reduce one additional hop/usage of ES as intermediate storage, before aggregation.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">â€‹</a></h4>
<p><img decoding="async" loading="lazy" alt="current-8.6" src="https://camunda.github.io/zeebe-chaos/assets/images/current-miro-659b193b670b1b604ebb32ff30b067a4.png" width="1096" height="885" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="main">Main<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#main" class="hash-link" aria-label="Direct link to Main" title="Direct link to Main">â€‹</a></h4>
<p><img decoding="async" loading="lazy" alt="main-target" src="https://camunda.github.io/zeebe-chaos/assets/images/target-1781d302fcf5b933b427a8f5d5df7bd7.png" width="1114" height="736" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We have set up both benchmarks, running as described above with changed payloads.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="general-performance">General Performance<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#general-performance" class="hash-link" aria-label="Direct link to General Performance" title="Direct link to General Performance">â€‹</a></h4>
<p>The general throughput performance looks similar. The resource consumption looks similar as well, but we didn't investigate this more deeply. Will be done separate.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="base-general">Base general<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#base-general" class="hash-link" aria-label="Direct link to Base general" title="Direct link to Base general">â€‹</a></h5>
<p><img decoding="async" loading="lazy" alt="base-general" src="https://camunda.github.io/zeebe-chaos/assets/images/base-general-452effab191f32fcf5a140949ec5a024.png" width="1901" height="780" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="main-general">Main general<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#main-general" class="hash-link" aria-label="Direct link to Main general" title="Direct link to Main general">â€‹</a></h5>
<p><img decoding="async" loading="lazy" alt="main-general" src="https://camunda.github.io/zeebe-chaos/assets/images/main-general-a2f75f96be9f6682c54ab3cdfb931a8f.png" width="1889" height="784" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency">Latency<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#latency" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>This experiment aims to show the difference in the data availability for the user.</p>
<p>In order to better visualize the dashboard has been adjusted for this experiment.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="base-latency">Base latency<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#base-latency" class="hash-link" aria-label="Direct link to Base latency" title="Direct link to Base latency">â€‹</a></h5>
<p><img decoding="async" loading="lazy" alt="base-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/base-latencies-tree-17aa593ad5dc16c9ca89726c38155b82.png" width="1134" height="793" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="main-latency">Main latency<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#main-latency" class="hash-link" aria-label="Direct link to Main latency" title="Direct link to Main latency">â€‹</a></h5>
<p>As we expected we were able to reduce the latency data is available for the user by the additional ES flush, reducing it by ~2 seconds.</p>
<p><img decoding="async" loading="lazy" alt="main-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/main-latencies-tree-7908eb4f973bd8e21f5fab8b2aec36bb.png" width="1078" height="581" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>We were able to show that the latency has been reduced under normal load.</p>
<p><strong>Note:</strong> Be aware this experiment only runs benchmarks with less-to-normal load, on higher load this might change, and need to be tested separately.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://camunda.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h4>
<p>Within the experiment, we run into several other issues. Especially after running for a while, when pods got restarted and importer have been enabled, the Camunda Exporter broke.</p>
<p><img decoding="async" loading="lazy" alt="exporting-fail" src="https://camunda.github.io/zeebe-chaos/assets/images/exporting-fail-2ddb3996ac30f721fe4e9a1ec8fcce7a.png" width="951" height="449" class="img_ev3q"></p>
<p>This caused to increase in the latency.</p>
<p><img decoding="async" loading="lazy" alt="exporting-fail-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/exporting-fail-latency-15efaf79627febc56dbe8ee0247c87d3.png" width="1888" height="193" class="img_ev3q"></p>
<p>The exporter was not able to detect correctly anymore that the importing was done but was still flushing periodically (which is as well wrong)</p>
<p>See related GitHub issue(s)</p>
<ul>
<li><a href="https://github.com/camunda/camunda/issues/26046" target="_blank" rel="noopener noreferrer">Importer(s) are not communicating import done correctly</a></li>
<li><a href="https://github.com/camunda/camunda/issues/26047" target="_blank" rel="noopener noreferrer">Exporter flushes periodically even when importer not completed</a></li>
</ul>
<p>Furthermore, based on logs we saw that the treePath hasn't been published correctly in the Exporter.</p>
<ul>
<li><a href="https://github.com/camunda/camunda/issues/26048" target="_blank" rel="noopener noreferrer">Camunda Exporter is not able to consume treePath</a></li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Impact of Camunda Exporter on processing performance]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance"/>
        <updated>2024-11-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In our last Chaos day we experimented with the Camunda Exporter MVP. After our MVP we continued with Iteration 2, where we migrated the Archiver deployments and added a new Migration component (allows us to harmonize indices).]]></summary>
        <content type="html"><![CDATA[<p>In our <a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP">last Chaos day</a> we experimented with the Camunda Exporter MVP. After our MVP we continued with Iteration 2, where we migrated the Archiver deployments and added a new Migration component (allows us to harmonize indices).</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/it2-migration-1c91d1203aba0c2d454ce583eac8703c.png" width="1088" height="888" class="img_ev3q"></p>
<p>Additionally, <a href="https://github.com/camunda/zeebe-benchmark-helm/pull/202" target="_blank" rel="noopener noreferrer">some fixes and improvements</a> have been done to the realistic benchmarks that should allow us to better compare the general performance with a realistic good performing benchmark.</p>
<p>Actually, this is what we want to explore and experiment with today.</p>
<ul>
<li>Does the Camunda Exporter (since the last benchmark) impact performance of the overall system?<!-- -->
<ul>
<li>If so how?</li>
</ul>
</li>
<li>How can we potentially mitigate this?</li>
</ul>
<p><strong>TL;DR;</strong> Today's, results showed that enabling the Camunda Exporter causes a 25% processing throughput drop. We identified the CPU as a bottleneck. It seems to be mitigated by either adjusting the CPU requests or removing the ES exporter. With these results, we are equipped to make further investigations and decisions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarks">Benchmarks<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmarks" class="hash-link" aria-label="Direct link to Benchmarks" title="Direct link to Benchmarks">â€‹</a></h2>
<p>As in the <a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP">last Chaos day</a> we use the new realistic benchmarks, that contain a much more complex process model and workload.
We recently found some smaller issues in our benchmarks, related to <a href="https://github.com/camunda/zeebe-benchmark-helm/pull/204" target="_blank" rel="noopener noreferrer">CPU throttling</a> and <a href="https://github.com/camunda/zeebe-benchmark-helm/pull/202" target="_blank" rel="noopener noreferrer">undersized workers</a>, these issues have been fixed. This allowed us to reach a much better workload/throughput on our weekly benchmarks, which we take here as a base for our comparison.</p>
<p>The newest benchmark helm charts have been updated to the first <a href="https://github.com/camunda/zeebe-benchmark-helm/releases/tag/zeebe-benchmark-0.3.8" target="_blank" rel="noopener noreferrer">Camunda Platform alpha1</a>, which includes the Camunda Exporter.</p>
<p>Today we run the following benchmarks</p>
<ul>
<li>Use Camunda Exporter, with disabled Importer in our benchmark</li>
<li>Use Camunda Exporter, with disabled Importer and disabled ES exporter</li>
<li>Use Camunda Exporter, with disabled Importer and higher CPU on brokers</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-base">Benchmark: Base<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-base" class="hash-link" aria-label="Direct link to Benchmark: Base" title="Direct link to Benchmark: Base">â€‹</a></h3>
<p>As we can see we can have a healthy cluster with a stable load where we reach to complete ~50 process instances, with that ~100 tasks, per second. All of this with a low backpressure.</p>
<p><img decoding="async" loading="lazy" alt="general" src="https://camunda.github.io/zeebe-chaos/assets/images/base-general-0d9b87e3c4c22e9a88803bb3d6c65356.png" width="2213" height="863" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-camunda-exporter">Benchmark: Camunda Exporter<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-camunda-exporter" class="hash-link" aria-label="Direct link to Benchmark: Camunda Exporter" title="Direct link to Benchmark: Camunda Exporter">â€‹</a></h3>
<p>When running our benchmarks with the Camunda Exporter the first thing we can observe is that the backpressure is much higher and the throughput went down by ~25-30%. We are now able to complete ~36 process instances, meaning 72 tasks, per second.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/it2-exporter-general-bb19c0d984757686f856a5e0817987e8.png" width="2216" height="870" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency">Latency<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#latency" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>Looking at the processing latency we can observe a significant increase</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">â€‹</a></h5>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/base-latency-53b85441222c4d658fe76896d4e970c7.png" width="2237" height="332" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/base-latency2-77df15ea527525cc0e2a17e7f2394435.png" width="2230" height="569" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="camunda-exporter">Camunda Exporter<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#camunda-exporter" class="hash-link" aria-label="Direct link to Camunda Exporter" title="Direct link to Camunda Exporter">â€‹</a></h5>
<p>The process instance execution p99 has been increased from ~4s to +60s, the p50 went from ~0,5s to ~3,7s.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/it2-exporter-latency-1c325d61ad7921f9fd60a5174f232047.png" width="2223" height="324" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/it2-exporter-latency2-e7fbece39a4cf20fcf5e7a9086fe7798.png" width="2228" height="562" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cpu">CPU<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#cpu" class="hash-link" aria-label="Direct link to CPU" title="Direct link to CPU">â€‹</a></h4>
<p>Investing this, we can look at the CPU. On our base Benchmark, we have CPU throttling at around 20%.</p>
<p><img decoding="async" loading="lazy" alt="cpu" src="https://camunda.github.io/zeebe-chaos/assets/images/base-cpu-2bd3f742bb3e63c939f4bcbb2e5abf35.png" width="2227" height="678" class="img_ev3q"></p>
<p>When comparing this with the Camunda Exporter benchmark, we can see that the CPU throttling went up to 80%. The benchmark is close to its limits.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/it2-exporter-cpu-0364f523f3197afc5a588c6a6720a491.png" width="2225" height="678" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-without-es-exporter">Benchmark: Without ES exporter<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-without-es-exporter" class="hash-link" aria-label="Direct link to Benchmark: Without ES exporter" title="Direct link to Benchmark: Without ES exporter">â€‹</a></h3>
<p>As we have seen the Camunda Exporter, causes the Brokers to consume a lot more CPU. This is kind of  expected as there is much more running now in our system.</p>
<p>As an additional experiment, we want to run the Benchmarks with the Camunda Exporter, without the Elasticsearch exporter. The hypothesis is that we can reduce the resource consumption and use it for the Camunda Exporter. The Elasticsearch exporter is with 8.7, only necessary for Optimize.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/no-es-general-371f07a7a870c2cf0aa69b513f2254da.png" width="1898" height="861" class="img_ev3q"></p>
<p>After setting up the benchmark we can observe that the throughput went back to normal.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency-1">Latency<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#latency-1" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>The latency is reduced, and we can also observe that it seems to drop over time as well.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/no-es-latency-29c218d2f4f7032be0c97ac70aadc4aa.png" width="1896" height="338" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/no-es-latency2-e8f5eca0ae902ff1a29285d700d489c3.png" width="1896" height="566" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cpu-1">CPU<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#cpu-1" class="hash-link" aria-label="Direct link to CPU" title="Direct link to CPU">â€‹</a></h4>
<p>The CPU throttling is dropping at some point, which explains the other drop of latency.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/no-es-cpu-df76c342afd4c0e936dca6b8bfd8a1a0.png" width="1889" height="676" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-more-cpu">Benchmark: More CPU<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-more-cpu" class="hash-link" aria-label="Direct link to Benchmark: More CPU" title="Direct link to Benchmark: More CPU">â€‹</a></h3>
<p>As we're migrating logic from the actual Importer deployment to the Camunda Exporter, we can get rid of such extra deployment and bound resources. Arguably we can use these free resources and assign them to the brokers.</p>
<p>When we look at the Camunda Exporter benchmark, the Operate deployment itself doesn't use many resources and likely don't need the assigned ones.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/it2-exporter-operate-cpu-cd3a0bb1a0ad83932e56e8c228f90a65.png" width="1113" height="313" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/change-resources-90f0b2609a3be8ba06662ba3c003ed93.png" width="1207" height="827" class="img_ev3q"></p>
<p>This change allows us to bring the throughput as well back to normal.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/more-cpu-general-ef1023e3caa361ad74e2ce9292cebeb1.png" width="1898" height="877" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency-2">Latency<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#latency-2" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>The latency is similar to our base benchmark.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/more-cpu-latency-538c03c7b6b866deaf65d4ac62eeb47c.png" width="1891" height="334" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/more-cpu-latency2-e8a9e06a59bc6acfd6f1485162bfe663.png" width="1897" height="564" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cpu-2">CPU<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#cpu-2" class="hash-link" aria-label="Direct link to CPU" title="Direct link to CPU">â€‹</a></h4>
<p>The CPU throttling has been reduced to almost zero. Interesting is that we don't use much more CPU resources (just slightly more, before ~1350m now ~1450 CPU). Increasing our requests by a little, allowed us to remove the CPU throttling. This is something we likely want to investigate further.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/more-cpu-cpu-5a2492087066afabd9b25114a27aaa78.png" width="1887" height="680" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://camunda.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">â€‹</a></h3>
<p>As we have seen, introducing (or enabling) the Camunda Exporter, can or will increase our processing latency and reduce our potential processing throughput. This obviously depends on the cluster load.</p>
<p>We were able to pinpoint the problem due to limited resources, to be specific CPU is the bottleneck.</p>
<p>This is expected, as running the Camunda Exporter means we are running more logic inside the Zeebe system.</p>
<p>We can mitigate this with:</p>
<ul>
<li>reducing load from the system, via disabling the additional ES exporter</li>
<li>give the system more resources</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="performance" term="performance"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Camunda Exporter MVP]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP"/>
        <updated>2024-10-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[After a long pause, I come back with an interesting topic to share and experiment with. Right now we are re-architecture]]></summary>
        <content type="html"><![CDATA[<p>After a long pause, I come back with an interesting topic to share and experiment with. Right now we are re-architecture
Camunda 8. One important part (which I'm contributing to) is to get rid of Webapps Importer/Archivers and move
data aggregation closer to the engine (inside a Zeebe Exporter).</p>
<p>Today, I want to experiment with the first increment/iteration of our so-called MVP. The MVP targets green field installations where you simply deploy Camunda (with a new Camunda Exporter enabled) without Importers.</p>
<p><strong>TL;DR;</strong> All our experiments were successful. The MVP is a success, and we are looking forward to further improvements and additions. Next stop Iteration 2: Adding Archiving historic data and preparing for data migration (and polishing MVP).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="camunda-exporter">Camunda Exporter<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#camunda-exporter" class="hash-link" aria-label="Direct link to Camunda Exporter" title="Direct link to Camunda Exporter">â€‹</a></h2>
<p>The <a href="https://github.com/camunda/product-hub/issues/2128" target="_blank" rel="noopener noreferrer">Camunda Exporter project</a> deserves a complete own blog post, here is just a short summary.</p>
<p>Our current Camunda architecture looks something like this (simplified).</p>
<p><img decoding="async" loading="lazy" alt="current" src="https://camunda.github.io/zeebe-chaos/assets/images/current-miro-659b193b670b1b604ebb32ff30b067a4.png" width="1096" height="885" class="img_ev3q"></p>
<p>It has certain challenges, like:</p>
<ul>
<li>Space: duplication of data in ES</li>
<li>Maintenance: duplication of importer and archiver logic</li>
<li>Performance: Round trip (delay) of data visible to the user</li>
<li>Complexity: installation and operational complexity (we need separate pods to deploy)</li>
<li>Scalability: The Importer is not scalable in the same way as Zeebe or brokers (and workload) are.</li>
</ul>
<p>These challenges we obviously wanted to overcome and the plan (as mentioned earlier) is to get rid of the need of separate importers and archivers (and in general to have separate application; but this is a different topic).</p>
<p>The plan for this project looks something like this:</p>
<p><img decoding="async" loading="lazy" alt="plan" src="https://camunda.github.io/zeebe-chaos/assets/images/how-brown-field-929f9a23e6dfee9ede15e76b1a134fdc.png" width="1228" height="904" class="img_ev3q"></p>
<p>We plan to:</p>
<ol>
<li>Harmonize the existing indices stored in Elasticsearch/Opensearch<!-- -->
<ul>
<li>Space: Reduce the unnecessary data duplication</li>
</ul>
</li>
<li>Move importer and archiver logic into a new Camunda exporter<!-- -->
<ul>
<li>Performance: This should allow us to reduce one additional hop (as we don't need to use ES/OS as a queue)</li>
<li>Maintenance: Indices and business logic is maintained in one place</li>
<li>Scalability: With this approach, we can scale with partitions, as Camunda Exporters are executed for each partition separately (soon partition scaling will be introduced)</li>
<li>Complexity: The Camunda Exporter will be built-in and shipped with Zeebe/Camunda 8. No additional pod/application is needed.</li>
</ul>
</li>
</ol>
<p>Note: Optimize is right now out of scope (due to time), but will later be part of this as well.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mvp">MVP<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#mvp" class="hash-link" aria-label="Direct link to MVP" title="Direct link to MVP">â€‹</a></h3>
<p>After we know what we want to achieve what is the Minimum viable product (MVP)?</p>
<p>We have divided the Camunda Exporter in 3-4 iterations. You can see and read more about this <a href="https://github.com/camunda/issues/issues/803" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>The first iteration contains the MVP (the first breakthrough). Providing the Camunda Exporter with the basic functionality ported from the Operate and Tasklist importers, writing into harmonized indices.</p>
<p>The MVP is targeting green field installations (clean installations) of Camunda 8 with Camunda Exporter without running the old Importer (no data migration yet),</p>
<p><img decoding="async" loading="lazy" alt="mvp" src="https://camunda.github.io/zeebe-chaos/assets/images/it1-mvp-421ca897b91c0d03c1d77adde73b48a7.png" width="1069" height="870" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>What I want to verify today, when I deploy the Camunda 8 stack with Camunda Exporter (and Importer disabled):</p>
<ul>
<li>Are webapps schemas created in ES, by the new Camunda Exporter</li>
<li>Is data exported into the indices</li>
<li>Can Operate show data? (right now just checking for basic functionality)</li>
</ul>
<p>Additionally, I would like to understand what the performance looks like, how the system behaves with two ES exporters (the old ES exporter and the new Camunda Exporter), and more.</p>
<p>For our experiment, I use a <a href="https://github.com/camunda/camunda/issues/21472" target="_blank" rel="noopener noreferrer">newly defined realistic benchmark</a> (with a more complex process model). More about this in a separate blog post.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>I can deploy the newest helm charts (alpha stage), by disabling Importer manually, and will be able to use Zeebe and Operate together. See the verifications above.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As always we use our <a href="https://github.com/camunda/zeebe-benchmark-helm" target="_blank" rel="noopener noreferrer">benchmark-helm charts</a> (that building on top of our <a href="https://github.com/camunda/camunda-platform-helm" target="_blank" rel="noopener noreferrer">Camunda Platform Helm</a> charts).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="installation">Installation<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#installation" class="hash-link" aria-label="Direct link to Installation" title="Direct link to Installation">â€‹</a></h3>
<p>I had to adjust our benchmarks to <a href="https://github.com/camunda/zeebe-benchmark-helm/commit/db682a89788d6c511083ec743c6cf7d358155e3c" target="_blank" rel="noopener noreferrer">use the alpha snapshots </a></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">dependencies</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">repository</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"oci://ghcr.io/camunda/helm"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">version</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"0.0.0-snapshot-alpha"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">condition</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"camunda.enabled"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>and <a href="https://github.com/camunda/zeebe-benchmark-helm/commit/aafac6e9ec78e9cfd2e59a5b6f30bf887a4fcbd0" target="_blank" rel="noopener noreferrer">disable the Importer via ENV</a></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">env</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> CAMUNDA_OPERATE_IMPORTERENABLED</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">value</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"false"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With that, we can install our chart:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ helm install zeebe-benchmark-test charts/zeebe-benchmark/ --render-subchart-notes -f charts/zeebe-benchmark/values-realistic-benchmark.yaml --set global.elasticsearch.prefix=null</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-first-verification">Basic First Verification<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#basic-first-verification" class="hash-link" aria-label="Direct link to Basic First Verification" title="Direct link to Basic First Verification">â€‹</a></h3>
<p>After our benchmark chart is deployed we can already see the first time our Camunda Exporter running <!-- -->ðŸŽ‰</p>
<p><img decoding="async" loading="lazy" alt="firsttime" src="https://camunda.github.io/zeebe-chaos/assets/images/first-time-seeing-camunda-exporter-70ed9f616eb84150a74085d4c29a3bff.png" width="1253" height="528" class="img_ev3q"></p>
<p>Worth mentioning that the Camunda Export already comes with some metrics, visible on our Zeebe Dashboard</p>
<p><img decoding="async" loading="lazy" alt="metrics" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-c8-exporter-metrics-c26a2e069e64c8a894ec4d5ffa718a70.png" width="1293" height="751" class="img_ev3q">
<img decoding="async" loading="lazy" alt="metrics2" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-c8-exporter-metrics2-062900d6bdddbdc951da85805bf2d89e.png" width="1263" height="407" class="img_ev3q"></p>
<p>The general overview also looks good. No obvious problem.</p>
<p><img decoding="async" loading="lazy" alt="general" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-general-overview-ee162c7186d9914428efb78c3f57c8f1.png" width="2532" height="812" class="img_ev3q"></p>
<p>Looking into logs we can see that at the start it fails temporarily because ES is not yet ready to accept the schema creation.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ERROR - Failed to open exporter 'CamundaExporter'. Retrying...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="log" src="https://camunda.github.io/zeebe-chaos/assets/images/exporter-opened-ed454d2a9960e13dd721f43ff2fe47ec.png" width="1004" height="198" class="img_ev3q"></p>
<p>At some point, the exporter can be opened and the loop stops.</p>
<p>I think generally it shouldn't be an ERROR but more a WARN (but these are details we can fix). Follow-up.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verify-operate-data">Verify Operate Data<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#verify-operate-data" class="hash-link" aria-label="Direct link to Verify Operate Data" title="Direct link to Verify Operate Data">â€‹</a></h3>
<p>To make sure that Operate is not importing, I checked the Operate dashboard. We can see that there is no Importer metrics. Furthermore, in the configuration and logs we see no indication of importing.</p>
<p><img decoding="async" loading="lazy" alt="op-metrics" src="https://camunda.github.io/zeebe-chaos/assets/images/no-importer-metrics-4adf3f44ee863313bc7db7536fb82476.png" width="2548" height="531" class="img_ev3q"></p>
<p>We can now start to port-forward to operate:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">k port-forward svc/zeebe-benchmark-test-operate 8081:80</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>When opening Operate we see unfortunately no data.</p>
<p><img decoding="async" loading="lazy" alt="operate-no-data" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-no-data-operate-a93144c5143ac98ec9aef7e9a4b82329.png" width="2448" height="862" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="investigating-missing-data">Investigating missing data<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#investigating-missing-data" class="hash-link" aria-label="Direct link to Investigating missing data" title="Direct link to Investigating missing data">â€‹</a></h4>
<p>We need to understand why there is no data available for Operate.</p>
<p>What we saw is that the Camunda Exporter is open (logs), that it is also makes progress and data is written to elastic (metrics). What we haven't checked Elasticsearch in detail.</p>
<p>Looking into ES dashboard we can see that indices are created, but the Operate indices seem to be empty.</p>
<p><img decoding="async" loading="lazy" alt="es-indices" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-operate-indices-empty-546f9dc0740acb0c660046b97d81e621.png" width="2531" height="588" class="img_ev3q"></p>
<p>When checking the Zeebe indices:</p>
<p><img decoding="async" loading="lazy" alt="zeebe-indices" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-zeebe-indices-filled-1125b6776b8ca7d9e08b2c2e4043b3c5.png" width="2542" height="537" class="img_ev3q"></p>
<p>we can see that they are filled. An attentive reader will also chekc that there actuall some prefix problem in the indices.</p>
<p>Thanks to Deepthi which spotted this as well (and told me), we were exporting to the wrong index names. There was a <a href="https://github.com/camunda/camunda-platform-helm/blob/46f6ee9d828439b0b1cf37bae4d135ba5281a832/charts/camunda-platform-alpha/templates/zeebe/configmap.yaml#L66" target="_blank" rel="noopener noreferrer">bug</a> existing in the current alpha Helm chart version.</p>
<p><img decoding="async" loading="lazy" alt="wrong-prefix" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-wrong-prefix-817f26674c55ba97e399e60d0e7261fe.png" width="2530" height="429" class="img_ev3q"></p>
<p>This has been fixed with <a href="https://github.com/camunda/camunda-platform-helm/pull/2506" target="_blank" rel="noopener noreferrer">PR-2506</a>. Until this gets merged I changed this manually via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Get the templates </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm template zeebe-benchmark-test charts/zeebe-benchmark/ --render-subchart-notes -f charts/zeebe-benchmark/values-realistic-benchmark.yaml --output-dir templates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Adjust the config map - remove the prefix</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vim templates/zeebe-benchmark/charts/camunda-platform/templates/zeebe/configmap.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Apply all manifests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k apply -f . --recursive</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note:</strong></p>
<p>I also tried</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">helm template charts/zeebe-benchmark/ --version 0.0.0-snapshot-alpha     --show-only charts/camunda-platform/templates/zeebe/configmap.yaml --set global.elasticsearch.prefix=null</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>But this breaks the ES exporter.</p>
</blockquote>
<p>With this change we were can see that indices are correctly created and filled!</p>
<p><img decoding="async" loading="lazy" alt="indices-filled" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-fixed-prefix-indices-1fb3dae117514d6a849127d776edad93.png" width="1269" height="390" class="img_ev3q"></p>
<p>Finally, we are able to see data in Operate! <!-- -->ðŸš€<!-- --> <strong>WITHOUT ANY IMPORTER.</strong></p>
<p><img decoding="async" loading="lazy" alt="mvp-operate-data.png" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-operate-data-eb8f2bc8a636a72be68760c53817192a.png" width="1258" height="524" class="img_ev3q">
<img decoding="async" loading="lazy" alt="mvp-operate-instance.png" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-operate-instance-27c3cfefb626236cc70f14ae7fb55d17.png" width="2536" height="926" class="img_ev3q">
<img decoding="async" loading="lazy" alt="mvp-operate-pi.png" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-operate-pi-9a30d4606bee4f381e9643812a3b0471.png" width="1243" height="888" class="img_ev3q">
<img decoding="async" loading="lazy" alt="operate-overview" src="https://camunda.github.io/zeebe-chaos/assets/images/mvp-decisions-cea9463cdf38ecc36a14fbc131985a9b.png" width="1261" height="944" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>The MVP is a success. We were able to provide a Camunda Exporter that creates the necessary harmonized schema and migrate the basic business logic from Operate and Tasklist into the exporter. This allows us to use only the Camunda Exporter without running any Importer pod/application.</p>
<p>Great work Team <!-- -->ðŸš€<!-- --> <!-- -->ðŸŽ‰</p>
<p><strong>Next stop:</strong></p>
<p><em>Iteration 2:</em></p>
<ul>
<li>Implementing migration logic for old data</li>
<li>Moving Archiver logic (for historical data) into the Exporter</li>
<li>Polish MVP state (add some missing features like TreePath, etc.)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="additional-notes">Additional notes<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#additional-notes" class="hash-link" aria-label="Direct link to Additional notes" title="Direct link to Additional notes">â€‹</a></h3>
<p>This time I was not able to deep dive into performance or stability for this change. I plan to do this next.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://camunda.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h3>
<ul>
<li>ERROR log level for logs that are transitive</li>
<li>Auth/User indices are still prefixed with identity</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="performance" term="performance"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimizing cluster sizing using a real world benchmark]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark"/>
        <updated>2024-10-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Our first goal of this experiment is to use a benchmarks to]]></summary>
        <content type="html"><![CDATA[<p>Our first goal of this experiment is to use a benchmarks to
derive new optimized cluster configuration that can handle
at least 100 tasks per second, while maintaining low backpressure and low latency.</p>
<p>For our experiment, we use a newly defined realistic benchmark (with a more complex process model). More about this in a separate blog post.</p>
<p>The second goal is to scale out optimized cluster configuration
resources linearly and see if the performance scales accordingly.</p>
<p><strong>TL;DR;</strong></p>
<p>We used a realistic benchmark to derive a new
cluster configuration based on previous requirements.</p>
<p>When we scale this base configuration linearly we see that the performance
increases almost linearly as well, while maintaining low
backpressure and low latency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect that we can find a cluster configuration that can handle at 100
tasks second to be significantly reduced in resources in relation to our
smaller clusters (G3-S HA Plan) since these can process significantly above
our initial target.</p>
<p>We also expect that we can scale this base configuration linearly, and that
the processing tasks rate to grow initially a bit faster than linearly due to
the lower relative overhead, and if we keep expanding further to flatten due
to the partition count being a bottleneck.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="minimal-requirements-for-our-cluster">Minimal Requirements for our Cluster<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#minimal-requirements-for-our-cluster" class="hash-link" aria-label="Direct link to Minimal Requirements for our Cluster" title="Direct link to Minimal Requirements for our Cluster">â€‹</a></h4>
<p>Based on known customer usage, and our own previous experiments, we
determined that the new cluster would need to create and complete a
baseline of 100 tasks per second, or about 8.6 million tasks per day.</p>
<p>Other metrics that we want to preserve and keep track are the backpressure
to preserve user experience, guarantee that exporting speed can keep up
with the processing speed, write-to-import latency which tells us how long
it takes for a record to be written to being imported by our other
apps such as the operator.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="reverse-engineering-the-cluster-configuration">Reverse Engineering the Cluster Configuration<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#reverse-engineering-the-cluster-configuration" class="hash-link" aria-label="Direct link to Reverse Engineering the Cluster Configuration" title="Direct link to Reverse Engineering the Cluster Configuration">â€‹</a></h4>
<p>For our new configurations the only resources that we are going to change
are the ones relevant to the factors described above. These are the
resources allocated to our zeebe-brokers, gateway and elasticSearch.</p>
<p>Our starting point in resources was the configuration for our G3-S HA Plan
as this already had the capability to significantly outperform the current
goal of 100 tasks per second.</p>
<p>The next step was to deploy our realistic benchmark, with a payload of 5
customer disputes per instance and start 7 instances per second, this
generated approximately 120 tasks per second (some buffer was added to guarantee performance).</p>
<p>After this we reduced the resources iteratively until we saw any increase
in backpressure, given that no there was no backlog of records, and no
significant increase in the write to import latency.</p>
<p>The results for our new cluster are specified bellow in the tables, where
our starting cluster configuration is the G3-S HA Plan and the new
configuration cluster is the G3 - BasePackage HA.</p>
<table><thead><tr><th>G3-S HA</th><th>CPU Limit</th><th>Memory Limit in GB</th></tr></thead><tbody><tr><td>operate</td><td>2</td><td>2</td></tr><tr><td>operate.elasticsearch</td><td>6</td><td>6</td></tr><tr><td>optimize</td><td>2</td><td>2</td></tr><tr><td>tasklist</td><td>2</td><td>2</td></tr><tr><td>zeebe.broker</td><td>2.88</td><td>12</td></tr><tr><td>zeebe.gateway</td><td>0.9</td><td>0.8</td></tr><tr><td><strong>TOTAL</strong></td><td><strong>15.78</strong></td><td><strong>24.8</strong></td></tr></tbody></table>
<table><thead><tr><th>G3 - BasePackage HA</th><th>CPU Limit</th><th>Memory Limit in GB</th></tr></thead><tbody><tr><td>operate</td><td>1</td><td>1</td></tr><tr><td>operate.elasticsearch</td><td>3</td><td>4.5</td></tr><tr><td>optimize</td><td>1</td><td>1.6</td></tr><tr><td>tasklist</td><td>1</td><td>1</td></tr><tr><td>zeebe.broker</td><td>1.5</td><td>4.5</td></tr><tr><td>zeebe.gateway</td><td>0.6</td><td>1</td></tr><tr><td><strong>TOTAL</strong></td><td><strong>8.1</strong></td><td><strong>13.6</strong></td></tr></tbody></table>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="reduction-in-resources-for-our-optimized-cluster">Reduction in Resources for our Optimized Cluster<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#reduction-in-resources-for-our-optimized-cluster" class="hash-link" aria-label="Direct link to Reduction in Resources for our Optimized Cluster" title="Direct link to Reduction in Resources for our Optimized Cluster">â€‹</a></h5>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">CPU Reduction (%)</th><th style="text-align:right">Memory Reduction (%)</th></tr></thead><tbody><tr><td style="text-align:left">zeebe.broker</td><td style="text-align:right">47.92</td><td style="text-align:right">62.5</td></tr><tr><td style="text-align:left">zeebe.gateway</td><td style="text-align:right">33.33</td><td style="text-align:right">-25.0</td></tr><tr><td style="text-align:left">operate.elasticsearch</td><td style="text-align:right">50.00</td><td style="text-align:right">25.0</td></tr></tbody></table>
<p>Total cluster reduction:</p>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">G3-S HA</th><th style="text-align:right">G3 - BasePackage HA</th><th style="text-align:right">Reduction (%)</th></tr></thead><tbody><tr><td style="text-align:left">CPU Limits</td><td style="text-align:right">15.78</td><td style="text-align:right">8.1</td><td style="text-align:right">49</td></tr><tr><td style="text-align:left">Memory Limits</td><td style="text-align:right">24.8</td><td style="text-align:right">13.6</td><td style="text-align:right">45</td></tr></tbody></table>
<p>The process of reducing the hardware requirements was donne initially by
scaling down the resources of the zeebe-broker, gateway and elasticSearch.
The other components were left untouched, as they had no impact in our key
metrics, and were scaled down later in separate experiences to maintain
user experience.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-out-the-cluster">Scaling out the Cluster<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#scaling-out-the-cluster" class="hash-link" aria-label="Direct link to Scaling out the Cluster" title="Direct link to Scaling out the Cluster">â€‹</a></h4>
<p>Now for the scaling procedure we intend to see if we can linearly increase
the allocated resources and having a corresponding performance increase,
while keeping the backpressure low, low latency, and user experience.</p>
<p>For this we started with the G3 - BasePackage HA configuration and
incremented the load again until we saw any increase in backpressure,
capture our key metrics and repeated the process for the cluster
configuration resources respectively multiplied by 2x, 3x, and 4x.</p>
<p>This means that the resources allocated for our clusters were:</p>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">Base 1x</th><th style="text-align:right">Base 2x</th><th style="text-align:right">Base 3x</th><th style="text-align:right">Base 4x</th></tr></thead><tbody><tr><td style="text-align:left">CPU Limits</td><td style="text-align:right">8.7</td><td style="text-align:right">17.4</td><td style="text-align:right">26.1</td><td style="text-align:right">34.8</td></tr><tr><td style="text-align:left">Memory Limits</td><td style="text-align:right">14.9</td><td style="text-align:right">29.8</td><td style="text-align:right">44.7</td><td style="text-align:right">59.6</td></tr></tbody></table>
<p>The results in the table bellow show the performance of our several cluster
configurations:</p>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">Base 1x</th><th style="text-align:right">Base 2x</th><th style="text-align:right">Base 3x</th><th style="text-align:right">Base 4x</th></tr></thead><tbody><tr><td style="text-align:left">Process Instances/s</td><td style="text-align:right">7</td><td style="text-align:right">12</td><td style="text-align:right">23</td><td style="text-align:right">27</td></tr><tr><td style="text-align:left">Tasks/s</td><td style="text-align:right">125</td><td style="text-align:right">217</td><td style="text-align:right">414</td><td style="text-align:right">486</td></tr><tr><td style="text-align:left">Average Backpressure</td><td style="text-align:right">2%</td><td style="text-align:right">2%</td><td style="text-align:right">3%</td><td style="text-align:right">6%</td></tr><tr><td style="text-align:left">Write-to-Import Latency</td><td style="text-align:right">90s</td><td style="text-align:right">120s</td><td style="text-align:right">150s</td><td style="text-align:right">390s</td></tr><tr><td style="text-align:left">Write-to-Process Latency</td><td style="text-align:right">140ms</td><td style="text-align:right">89ms</td><td style="text-align:right">200ms</td><td style="text-align:right">160ms</td></tr><tr><td style="text-align:left">Records Processed Rate</td><td style="text-align:right">2500</td><td style="text-align:right">4700</td><td style="text-align:right">7800</td><td style="text-align:right">11400</td></tr><tr><td style="text-align:left">Records Exported Rate</td><td style="text-align:right">2100</td><td style="text-align:right">3900</td><td style="text-align:right">6500</td><td style="text-align:right">9200</td></tr></tbody></table>
<p>This first observations is that the performance scales particularly well by
just adding more resources to the cluster, particularly for a linear
increase of the resources the performance as measured by tasks completed
increases slightly less than linearly (comparing the 1x and 4x task/s we
get 388% the initial rate).</p>
<p>This a very good result as it means that we can scale our system linearly
(at least initially) to handle the expected increase in loads.</p>
<p>Importantly, the backpressure is kept low, and the write-to-import latency
only increases significantly if we leave the cluster running at max rate
for long periods of time. For slightly lower rates the write-to-import
latency is kept in the single digits of seconds or lower tens. This might
imply that a these sustained max rates, the amount records generated starts
to be too much for either ElasticSearch or our web apps that import these
records to handle. Some further investigation could be done here to
investigate the bottleneck.</p>
<p>Another metric also relevant but not shown in this table is the backlog of
records not exported, which kept at almost null through all the experiments
conducted.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-found">Bugs found<a href="https://camunda.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#bugs-found" class="hash-link" aria-label="Direct link to Bugs found" title="Direct link to Bugs found">â€‹</a></h3>
<p>During the initial tests, we had several OOM errors in the gateways pods.
After some investigation, we found that this was exclusive to the Camunda 8.
6.0 version, which consumes more memory in the gateway than the previous
versions. This explains why the gateway memory limits were the only
resource that was increased in the new reduced cluster configuration.</p>]]></content>
        <author>
            <name>Rodrigo Lopes</name>
            <uri>https://github.com/rodrigo-lourenco-lopes</uri>
        </author>
        <category label="performance" term="performance"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improve Operate import latency]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency"/>
        <updated>2024-08-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In our last Chaos Day we experimented with Operate and different load (Zeebe throughput). We observed that a higher load caused a lower import latency in Operate. The conclusion was that it might be related to Zeebe's exporting configuration, which is affected by a higher load.]]></summary>
        <content type="html"><![CDATA[<p><a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">In our last Chaos Day</a> we experimented with Operate and different load (Zeebe throughput). We observed that a higher load caused a lower import latency in Operate. The conclusion was that it might be related to Zeebe's exporting configuration, which is affected by a higher load.</p>
<p>In today's chaos day we want to verify how different export and import configurations can affect the importing latency.</p>
<p><strong>TL;DR;</strong> We were able to decrease the import latency by ~35% (from 5.7 to 3.7 seconds), by simply reducing the <code>bulk.delay</code> configuration. This worked on low load and even higher load, without significant issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="background">Background<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">â€‹</a></h2>
<p><em>In the following I want to briefly explain a bit more the background of how exporting and importing play together. If you are already aware feel free to jump to the <a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#chaos-experiment">next section</a>.</em></p>
<hr>
<p>To understand how the importing of Operate is affected and works, we first have to take a look at Zeebe.</p>
<p>Zeebe exports data to Elasticsearch via its Elasticsearch Exporter. The exporter collects data before sending it to Elasticsearch in bulk requests. The amount of data, which is collected in the exporter, is configurable and by default set to 1000 records per batch/bulk. Additionally, there is a memory limit which is taken into account that is set to 10 MB. When the bulk request is reaching that size, the request is sent as well. To cover cases of low load, there is a delay option, which is per default set to 5 seconds. This means, that every 5 seconds the bulk request is sent, even if it is not full.</p>
<p>This explains also the results from <a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">our last Chaos Day</a>, where the import latency was around 5 seconds on a lower load.</p>
<p>In the following, we have written down the sequence of steps a command has to take, and its resulting events until it is visible to the user in Operate. This should allow to better understand how and by what the import latency is affected, and what we might want to tune and experiment further.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">User Command is sent to Gateway </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt;Gateway sents Command to the right Broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">----&gt;Broker processes command and produces events</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">------&gt;Events are exported by Broker to ES (worst case: 5s flush) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--------&gt;ES refreshes after one second</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">----------&gt;Operate import processing/rewriting data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">------------&gt;ES refreshes after one second</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--------------&gt;Operate can query the data -&gt; User can see the data </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>About Elasticsearch and its default refresh configuration, etc. you can read <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html#_unset_or_increase_the_refresh_interval" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>Based on this, we know we have the following minimum delay:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">delay = 2 seconds (due to ES refresh)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + (5 seconds from exporter on low load)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + network delay </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + processing delay </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + Exporter and Operate data un/marshaling/processing</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Today, we will experiment with the Elasticsearch exporter configurations to improve the import latency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>As we have seen <a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">in a previous chaos day</a> high load affects the importing latency positively. The thesis is that this is due to the export flush delay, which is mostly affecting the exporting on lower load.</p>
<p>Today we want to prove the following:</p>
<blockquote>
<p><strong>Hypothesis</strong></p>
<p>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for lower load scenarios without affecting the system negatively.</p>
</blockquote>
<p>We can define the following <code>unknowns</code>, that we want to explore further as well:</p>
<ul>
<li>It is not clear how lower flush delay affects the system on higher loads.</li>
<li>It is not clear how smaller values (under 1 second) for the flush delay affect the system, no matter of high or low load.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<ol>
<li>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for lower load scenarios without affecting the system negatively.</li>
<li>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for higher load scenarios, <strong>but decreasing the import throughput</strong></li>
<li>When we set the exporting/flush delay to a small value (under 1 second), we are affecting the import throughput negatively</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As always, we set a base installation up to compare against. The load is moderate-to-low (15 PI/s). We can compare the data from the <a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">last chaos day</a> here as well.</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Base: Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=5 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=5 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=5 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p>We see similar results as on the <a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#base">last Chaos day</a>.</p>
<p><img decoding="async" loading="lazy" alt="base-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/base-latency-b7ca1d69a5c6419365516c262ccea9fa.png" width="949" height="340" class="img_ev3q">
<img decoding="async" loading="lazy" alt="base-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/base-throughput-55ff3e3256fa6ddc44ed107960c6a18d.png" width="948" height="262" class="img_ev3q"></p>
<p>We are able to import around 360 records per second, while Zeebe exports 413. Be aware that some are ignored by Operate.
A record has on average a delay of 5.69 seconds from being written by Zeebe to being imported by Operate (and written into the
end Elasticsearch index).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-lower-flush-delay">First experiment: Lower flush delay<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#first-experiment-lower-flush-delay" class="hash-link" aria-label="Direct link to First experiment: Lower flush delay" title="Direct link to First experiment: Lower flush delay">â€‹</a></h4>
<blockquote>
<p>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for lower load scenarios without affecting the system negatively.</p>
</blockquote>
<p>To reduce the exporter flush delay we use the following configuration:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">exporters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">elasticsearch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">bulk</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">delay</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This can be set in our <a href="https://github.com/camunda/zeebe-benchmark-helm" target="_blank" rel="noopener noreferrer">benchmark-helm</a> directly via: <code>--set zeebe.config.zeebe.broker.exporters.elasticsearch.args.bulk.delay=1</code></p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Lower flush delay: Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=5 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=5 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=5 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d <br>
<!-- -->--set zeebe.config.zeebe.broker.exporters.elasticsearch.args.bulk.delay=1</p></pre></div></div></details>
<p><img decoding="async" loading="lazy" alt="lower-delay" src="https://camunda.github.io/zeebe-chaos/assets/images/lower-delay-base-d12d1ae908d186eaa1e7c53db1c25df3.png" width="942" height="350" class="img_ev3q">
<img decoding="async" loading="lazy" alt="lower-delay-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/lower-delay-base-load-throughput-2f84411bbd0df079f7c760b882b00f1f.png" width="931" height="264" class="img_ev3q"></p>
<p>With setting the <code>bulk.delay</code> to one second, we were able to reduce the import latency by ~2 seconds, from 5.69 to 3.68 seconds.
That is a 35% decrease, while other factors stay the same. We can observe that the throughput stays the same (while of course, the load is rather moderate-to-low).</p>
<p>This proved our first hypothesis from above. <!-- -->âœ…</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-experiment-lower-delay-with-higher-load">Second Experiment: Lower delay with higher load<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#second-experiment-lower-delay-with-higher-load" class="hash-link" aria-label="Direct link to Second Experiment: Lower delay with higher load" title="Direct link to Second Experiment: Lower delay with higher load">â€‹</a></h4>
<blockquote>
<p>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for higher load scenarios, <strong>but decreasing the import throughput</strong></p>
</blockquote>
<p>Similar to the first experiment we set the delay to one second, and increased the load in the same way as we did
<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#high-load">here</a> before.</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Lower flush delay with high load: Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=50 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=50 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=50 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d <br>
<!-- -->--set zeebe.config.zeebe.broker.exporters.elasticsearch.args.bulk.delay=1</p></pre></div></div></details>
<p><img decoding="async" loading="lazy" alt="higher-load" src="https://camunda.github.io/zeebe-chaos/assets/images/lower-delay-high-load-latency-0e25d5853d6c133948c594bb1efb631b.png" width="1903" height="339" class="img_ev3q">
<img decoding="async" loading="lazy" alt="higher-load-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/lower-delay-high-load-throughput-30c09f7fe98dd22bd5f4199e48fd79bb.png" width="1895" height="252" class="img_ev3q"></p>
<p>We can see that the latency has been increased a bit, versus the lower load benchmark, but it has improved compared to the
benchmark <a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#high-load">the last chaos day</a>. :information: An interesting factor is that it seems that the throughput from Zeebe has changed as well, that in consequence increased the import throughput.</p>
<p>Looking into it further, we can see that the job and process instance creation and completion have changed by ~13-18 percent. Before we had around 130 process instance completion per second.</p>
<p><img decoding="async" loading="lazy" alt="backpressure-higher-load" src="https://camunda.github.io/zeebe-chaos/assets/images/backpressure-higher-load-7ea4904a9e4209bb0f55935db995a5a6.png" width="707" height="450" class="img_ev3q"></p>
<p>In the recent benchmark, we almost reach our target load (150 PI/s) with 147 process instance completions per second.</p>
<p><img decoding="async" loading="lazy" alt="backpressure-higher-load-lower-delay" src="https://camunda.github.io/zeebe-chaos/assets/images/backpressure-lower-delay-higher-load-690a52e13a2e7d988eb29d2cf103250f.png" width="709" height="454" class="img_ev3q"></p>
<p>The reason seem to be the different backpressure. Backpressure has been decreased from ~20 % to 5-10%. This might be because our backpressure strategy has recently changed and now takes exporting into account. See also <a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting">related chaos day about this topic</a>.</p>
<p><em><strong>Update</strong></em>:</p>
<p>Looking into it further, the backpressure is not affected by the newest feature (as it was not enabled by default). This was discussed internally with the Zeebe team.</p>
<p><img decoding="async" loading="lazy" alt="higher-load-less-throughput-commit-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/higher-load-less-throughput-commit-latency-9c60c6c92511ef060343e3628b6ff144.png" width="1906" height="519" class="img_ev3q"></p>
<p>The slower benchmark, seem to have a degraded commit latency, which in consequence slows down the whole system. It is unclear right now, why this is.</p>
<p>The faster benchmark, with the configured exporting, has a much better commit latency. It is unlikely that the exporter configuration affected this part of the system. We will have to retry the both benchmarks.</p>
<p><img decoding="async" loading="lazy" alt="higher-load-higher-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/higher-load-higher-throughput-commit-latency-fe734971e6c84fd5fcc91f0be184c03b.png" width="1909" height="525" class="img_ev3q"></p>
<p><em><strong>Update 20-08-2024</strong></em></p>
<p>We run additional benchmarks to verify the behavior on high load. This time we haven't seen any differences in terms
of processing performance in both benchmarks.</p>
<p>The benchmark without the configuration, reaches similar numbers (146 PI/s), as the other before.</p>
<p><img decoding="async" loading="lazy" alt="20-08-high-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/2024-08-20_high-load-throughput-9af777e2e4b2ca7f505630269e5dfc26.png" width="2539" height="383" class="img_ev3q"></p>
<p>Benchmark with configuring the flush delay reaches comparable numbers.</p>
<p><img decoding="async" loading="lazy" alt="20-08-high-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/2024-08-20_high-load-throughput-lower-delay-b7a3a17768405a0cf71ee848cb882bae.png" width="2539" height="376" class="img_ev3q"></p>
<p>During running the benchmarks we run into another issue, for which we opened the following <a href="https://github.com/camunda/camunda/issues/21376" target="_blank" rel="noopener noreferrer">issue #21376</a>.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="additional-finding">Additional finding<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#additional-finding" class="hash-link" aria-label="Direct link to Additional finding" title="Direct link to Additional finding">â€‹</a></h5>
<p>An interesting additional finding has been done. When the Operate import fails or restarts (that can easily happen with preemptive nodes), then the importer backlog can be significant. This is especially an issue on higher constant load.</p>
<p><img decoding="async" loading="lazy" alt="import-delay" src="https://camunda.github.io/zeebe-chaos/assets/images/import-delay-90beae953db149d42fff5c116f738a60.png" width="1908" height="446" class="img_ev3q"></p>
<p>In our benchmark after the importer failed, it took ~20 minutes until the backlog was processed and the import latency was back to normal.</p>
<p><img decoding="async" loading="lazy" alt="recover-import-delay" src="https://camunda.github.io/zeebe-chaos/assets/images/import-delay-recover-6be36a1bd65171855f7b87125cdea6b5.png" width="1906" height="349" class="img_ev3q"></p>
<p>This shows that Operate, especially the importer is quite sensitive to restarts. This is likely to be changed and improved when
Operates importing mechanism is moved into Zeebe, as a separate exporter see <a href="https://github.com/camunda/camunda/issues/16912" target="_blank" rel="noopener noreferrer">related GH issue</a>.</p>
<p>On a lower load, the impact of an importer restart is negligible, as we can see below.</p>
<p><img decoding="async" loading="lazy" alt="no-impoact-low-load-restart" src="https://camunda.github.io/zeebe-chaos/assets/images/no-import-delay-restart-low-load-181ded52fb60f7d19889f6663b5454d0.png" width="1900" height="446" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="third-experiment">Third experiment<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#third-experiment" class="hash-link" aria-label="Direct link to Third experiment" title="Direct link to Third experiment">â€‹</a></h4>
<blockquote>
<p>When we set the exporting/flush delay to a small value (under 1 second), we are affecting the import throughput negatively</p>
</blockquote>
<p>We were not able to set the <code>bulk.delay</code> to a smaller value than 1 second, as the configuration only accepts longs. The values seem to be expected to be seconds. When setting it to zero, no improvement has been observed (versus one second).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="potential-improvements">Potential improvements<a href="https://camunda.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#potential-improvements" class="hash-link" aria-label="Direct link to Potential improvements" title="Direct link to Potential improvements">â€‹</a></h2>
<ul>
<li>Allow to configure <code>bulk.delay</code> in non-second format (be able to specify the time/duration format)</li>
<li>The <code>bulk.delay</code> configures a timer, which gets triggered with the given value. This means the flush can happen, even if flush was executed before causing flush with little buffers.</li>
<li>Importing is highly affected by pod restarts, this can cause issues on higher load, due to a growing backlog. Making import idempotent, and scaling importers would help here.</li>
<li><a href="https://github.com/camunda/camunda/issues/21376" target="_blank" rel="noopener noreferrer">Zeebe exporting latency can increase significantly without clear root cause #21376</a>.</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="performance" term="performance"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Operate load handling]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling"/>
        <updated>2024-08-16T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Happy to announce that we are broadening the scope of our Chaos days, to look holistically at the whole Camunda Platform, starting today.]]></summary>
        <content type="html"><![CDATA[<p>ðŸŽ‰<!-- --> Happy to announce that we are broadening the scope of our Chaos days, to look holistically at the whole Camunda Platform, starting today.
In the past Chaos days we often had a close look (or concentrated mostly) at Zeebe performance and stability.</p>
<p>Today, we will look at the Operate import performance and how Zeebe processing throughput might affect (or not?) the throughput and latency of the Operate import. Is it decoupled as we thought?</p>
<p>The import time is an important metric, representing the time until data from Zeebe processing is
visible to the User (excluding Elasticsearch's indexing). It is measured from when the record is written to the log, by the Zeebe processor, until Operate reads/imports it from Elasticsearch and converts it into its data model. We got much feedback (and experienced this on our own) that
Operate is often lagging behind or is too slow, and of course we want to tackle and investigate this further.</p>
<p>The results from this Chaos day and related benchmarks should allow us to better understand how the current importing
of Operate performs, and what its affects. Likely it will be a series of posts to investigate this further. In general,
the data will give us some guidance and comparable numbers for the future to improve the importing time. See also related GitHub issue <a href="https://github.com/camunda/camunda/issues/16912" target="_blank" rel="noopener noreferrer">#16912</a> which targets to improve such.</p>
<p><strong>TL;DR;</strong> We were not able to show that Zeebe throughput doesn't affect Operate importing time. We have seen that Operate can be positively affected by the throughput of Zeebe. Surprisingly, Operate was faster to
import if Zeebe produced more data (with a higher throughput). One explanation of this might be that Operate was then less idle.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>As previously mentioned we will today look at the Operate's import latency and throughput. For that, I have created a
new Benchmark dashboard. That allows us to see Zeebe and Operate performance together, at once.</p>
<p><img decoding="async" loading="lazy" alt="default-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/default-latency-42bb59a3c0e41198245a39881eb5efe6.png" width="1898" height="344" class="img_ev3q">
<img decoding="async" loading="lazy" alt="default-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/default-throughput-633e5b518b1315340f16824249676ad4.png" width="1897" height="486" class="img_ev3q"></p>
<p>During building that dashboard I realized that we missed some detail metrics. For example, the latency of writing and then exporting a record,
is currently not measured. Furthermore, we have operating limited metrics, thus allowing us only to see the average
latency, not p99 nor p90. This needs to be enhanced in the future.</p>
<p>We will run three benchmarks (base, high load, and low load), and use again our <a href="https://github.com/camunda/zeebe-benchmark-helm" target="_blank" rel="noopener noreferrer">benchmark helm chart</a> for such.
All defaults from the helm charts are used, if not other specified. The most important ones, which are static over all benchmarks are listed below.</p>
<table><thead><tr><th>Config</th><th>Value</th></tr></thead><tbody><tr><td>Broker</td><td>3</td></tr><tr><td>Partitions</td><td>3</td></tr><tr><td>Replication</td><td>3</td></tr><tr><td>Broker Mem</td><td>4G</td></tr><tr><td>Broker CPU</td><td>1350m</td></tr><tr><td>Broker Disk</td><td>32g</td></tr><tr><td>Gateways</td><td>2</td></tr><tr><td>Gateway Mem</td><td>1G</td></tr><tr><td>Gateway CPU</td><td>450m</td></tr><tr><td>ES nodes</td><td>3</td></tr><tr><td>ES CPU</td><td>2</td></tr><tr><td>ES Mem</td><td>6G</td></tr><tr><td>ES Disk</td><td>128g</td></tr><tr><td>Operate replicas</td><td>1</td></tr><tr><td>Operate Memory</td><td>2g</td></tr><tr><td>Operate CPU</td><td>2</td></tr></tbody></table>
<p>With the base, we should see how the import performs normally. As base, we will use the same configuration as we use in our weekly benchmarks, see
<a href="https://github.com/camunda/camunda/blob/main/.github/workflows/zeebe-medic-benchmarks.yml#L78-L89" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>We use the same applications that we use for our other benchmarks, the code can be found <a href="https://github.com/camunda/camunda/tree/main/zeebe/benchmarks/project" target="_blank" rel="noopener noreferrer">here</a></p>
<p>The base looks like the following:</p>
<table><thead><tr><th>Config</th><th>Value</th></tr></thead><tbody><tr><td>Starter</td><td>5 PI/s</td></tr><tr><td>Worker</td><td>1 Replica</td></tr><tr><td>Timer</td><td>5  PI/s</td></tr><tr><td>Publisher</td><td>5   PI/s</td></tr><tr><td>Variables</td><td>46 Kb</td></tr></tbody></table>
<p>The "Starter" deploys a process model with one task and creates instances at a rate of 5 process instances per second (PI/s). The "Worker" is handling such related tasks. The "Timer" deploys a process model with one timer catch event, and creates instances in a rate of 5 PI/s. The "Publisher" deploys a process model with a message catch event, and publishes messages at a rate of 5 per second. On each process instance variables of the size of 46 kilobytes are sent as payload, to mimic a more realistic scenario.</p>
<p>Going out of the base configuration we are adjusting the rate to a higher value (multiplied by 10), and to a lower value (divided by 5). This means for the high load benchmark we will have a rate of 50 PI/s per application (~150 PI/s), and for the lower load, we will have a rate of 1 PI/s per application (~3 PI/s).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>With the base benchmark, we will see how Operate is performing on a moderate load. As the importing of Operate is decoupled the higher load nor the lower load should have a significant impact on the importing time. It might be that due to a higher load on Zeebe, and a slightly bigger backlog the import time might be a bit higher for Operate.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">â€‹</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=5 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=5 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=5 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p>With a moderate load (as described above) we can see how large the import delay already is.</p>
<p><img decoding="async" loading="lazy" alt="base-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/default-latency-42bb59a3c0e41198245a39881eb5efe6.png" width="1898" height="344" class="img_ev3q"></p>
<p>The import latency from Operate is above 5 seconds.</p>
<p>As expected we can see that we complete 15 process instances per second. We process around 145 records per second, and export 415 records per second. Operate is only reading 370 records per second because not all records are consumed by Operate.</p>
<p><img decoding="async" loading="lazy" alt="base-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/default-throughput-633e5b518b1315340f16824249676ad4.png" width="1897" height="486" class="img_ev3q"></p>
<p>Here it might make sense to configure the exporter, to only export the important ones.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="high-load">High load<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#high-load" class="hash-link" aria-label="Direct link to High load" title="Direct link to High load">â€‹</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=50 <br>
<!-- -->--set worker.replicas=3 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=50 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=50 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p>Looking at the high load benchmark, we can see something surprising. The Operate import latency has been decreased. From ~5.7 to 4.4 seconds, which is a 30% improvement. The Zeebe processing latency has been increased due to the higher load.</p>
<p><img decoding="async" loading="lazy" alt="high-load-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/high-load-latency-e3e962e93add61bbff99b5bb718735f7.png" width="1904" height="346" class="img_ev3q"></p>
<p>We can see that Zeebe is not able to handle ~150 instances, this can have multiple causes, too few workers, or other configurations, but this is irrelevant for today's benchmark.</p>
<p><img decoding="async" loading="lazy" alt="high-load-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/high-load-throughput-a7467757d779975bc0daa55c7214a683.png" width="1904" height="493" class="img_ev3q"></p>
<p>A huge amount of records (3158) are imported by Operate per second, with the same configuration as for the base benchmark. It looks like there is still room (we might investigate this further next time).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="low-load">Low load<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#low-load" class="hash-link" aria-label="Direct link to Low load" title="Direct link to Low load">â€‹</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=1 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=1 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=1 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p><img decoding="async" loading="lazy" alt="low-load-latency" src="https://camunda.github.io/zeebe-chaos/assets/images/low-load-latency-c26a6962a6679f059431e24501a86518.png" width="1897" height="343" class="img_ev3q"></p>
<p>Unexpected or even counterintuitive is that on a lower load the import time went up again or is similar to the base benchmark ~5.7 seconds to import a record.</p>
<p><img decoding="async" loading="lazy" alt="low-load-throughput" src="https://camunda.github.io/zeebe-chaos/assets/images/low-load-throughput-87a6f32932cbb31cea39dc24a4f2af8c.png" width="1905" height="494" class="img_ev3q"></p>
<p>Zeebe is reaching the 3 PI/s and exporting again a bit more than Operate is importing, as described before likely to some filters.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>We were not able to prove that Zeebe throughput doesn't affect Operate's import time. What we have seen is that higher throughput on the Zeebe side positively affects Operate's import time (import delay decreases from 5.7 seconds to 4.4 seconds). This was not just a short outlier, it was shown over a long period.</p>
<p>It is likely related to how Zeebe exporting and Operate importing work together. Zeebe exporting collects several data before it is sent to Elasticsearch. Either if a certain time is due or a certain amount is reached. Operate might be idle from time to time and "sleep" and wake up every certain seconds to import again.</p>
<p>We have to investigate this further to understand all the details, but I think this as already an interesting learning.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next">Next<a href="https://camunda.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#next" class="hash-link" aria-label="Direct link to Next" title="Direct link to Next">â€‹</a></h2>
<p>In the following, I listed some potential improvements and investigations we might want to do next:</p>
<ul>
<li>We need better metrics in Operate, e.g. histograms to have p99, and p90 for import latency</li>
<li>We need the measure the export latency, to better understand and compare how long the import time really is</li>
<li>Investigate whether we can better configure exporting and importing, to reduce delays.</li>
<li>Can we filter more records and this affects positively the importing?</li>
</ul>]]></content>
        <author>
            <name>Christopher Kujawa</name>
            <uri>https://github.com/ChrisKujawa</uri>
        </author>
        <category label="performance" term="performance"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using flow control to handle bottleneck on exporting]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting"/>
        <updated>2024-07-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).]]></summary>
        <content type="html"><![CDATA[<p>Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).
Limiting the write rate is a new feature that can be used to prevent building up an excessive exporting backlog.
There are two ways to limit the write rate, either by setting a static limit or by enabling throttling that dynamically adjust the write rate based on the exporting backlog and rate.
In these experiments, we will test both ways of limiting the write rate and observe the effects on processing and exporting.</p>
<p><strong>TL;DR;</strong>
Both setting a static write rate limit and enabling throttling of the write rate can be used to prevent building up an excessive exporting backlog.
For users, this will be seen as backpressure because processing speed is limited by the rate at which it can write processing results.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="static-write-limit">Static write limit<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#static-write-limit" class="hash-link" aria-label="Direct link to Static write limit" title="Direct link to Static write limit">â€‹</a></h2>
<p>We will construct a cluster under normal utilization and then artificially degrade the exporting process.
After this we will apply flow control settings to statically rate limit all writes.
The limit will be set slightly lower than the observed exporting rate.</p>
<p>For this we will use the flow control endpoint to temporarily configure the write rate limit.</p>
<p>To fetch the current configuration we can port forward to one of the zeebe pods and use the command:</p>
<div class="language-Shell language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">GET /actuator/flowControl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="original-configuration" src="https://camunda.github.io/zeebe-chaos/assets/images/original-configuration-568ece5f5f513848f06d772b821f7ba6.png" width="586" height="532" class="img_ev3q"></p>
<p>To configure the write rate limit we use the same endpoint, for example:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "write": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "limit": 400</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we start to degrade the exporting rate, we expect to see the exporting backlog to increase steadily.</p>
<p>Once a static write rate limit below the degraded exporting rate is applied, we expect fewer rates and slower processing.
The exporting backlog should decrease again until we eventually reach zero backlog again.
Backpressure should increase because processing has slowed down and some requests will be rejected by the write rate limit.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>After we artificially degrade the exporter performance, we see a constant increase in records not exported since the processing is still happening at the same rate.</p>
<p><img decoding="async" loading="lazy" alt="exporting-per-partition" src="https://camunda.github.io/zeebe-chaos/assets/images/exporting-per-partition-post-degraded-exporting-45c6750dac85bf4a0a2b949833b6dfd0.png" width="1999" height="379" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition" src="https://camunda.github.io/zeebe-chaos/assets/images/processing-per-partition-post-degraded-exporting-0e056df5c7a61f47f01c6a3cee5a3c41.png" width="1999" height="378" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="exporter-backlog" src="https://camunda.github.io/zeebe-chaos/assets/images/number-of-records-not-exported-post-degraded-exporting-6df4c3931c2367ce522bac8f9a3a7698.png" width="1362" height="534" class="img_ev3q"></p>
<p>After applying a static rate limit of 400 to be slightly lower than the observed 500-600 of the exporting rate, we see that the processing speed changes accordingly.</p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition-post-rate-limit" src="https://camunda.github.io/zeebe-chaos/assets/images/processing-per-partition-post-rate-limit-3cf3e06b8171ca675e12333dce4385aa.png" width="1999" height="371" class="img_ev3q"></p>
<p>As expected we also see this reflected in backpressure that sees the user commands being rejected in a much higher portion.</p>
<p><img decoding="async" loading="lazy" alt="backpressure" src="https://camunda.github.io/zeebe-chaos/assets/images/backpressure-post-rate-limit-90eba93cb2dd681bfa3d67074ff83713.png" width="1532" height="460" class="img_ev3q"></p>
<p>We also observe that the backlog of records not exported starts to decrease at the rate of the difference between exported and written records.</p>
<p><img decoding="async" loading="lazy" alt="exporter-backlog-post-rate-limit" src="https://camunda.github.io/zeebe-chaos/assets/images/number-of-records-not-exported-post-rate-limit-0e96e608f6826f596b09a32806640ea3.png" width="1360" height="540" class="img_ev3q"></p>
<p>These observations match our expectations and show that a static write rate limit can be used to prevent building up an excessive exporting backlog.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dynamic-write-rate-throttling">Dynamic write rate throttling<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#dynamic-write-rate-throttling" class="hash-link" aria-label="Direct link to Dynamic write rate throttling" title="Direct link to Dynamic write rate throttling">â€‹</a></h2>
<p>Choosing a static write rate limit is not a full solution because we can't predict the actual exporting rates.
To address this, we can enable write rate throttling that will dynamically adjust the write rate based on the exporting backlog and rate.</p>
<p>To enable write rate throttling we can use the flow control endpoint again, for example:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "write": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "limit": 2500,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "throttling": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "acceptableBacklog": 100000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "minimumLimit": 100,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "resolution": "15s"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Similar to the first experiment, we expect to see the exporting backlog increase when we artificially degrade the exporting performance.
After enabling write rate throttling, we expect that the write rate is reduced significantly and eventually matches the exporting rate.
The reduced write rate should show up as backpressure.
Eventually, the exporting backlog settles at the configured acceptable backlog.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Re-running the same setup, but using the throttling of writes with an acceptable backlog at 100,000  of not exported records, and a limit higher than our processing speed (so has to not impact the experience), we get the following results:</p>
<p><img decoding="async" loading="lazy" alt="number-of-records-not-exported-post-throttling" src="https://camunda.github.io/zeebe-chaos/assets/images/number-of-records-not-exported-post-throttling-89e888362474746d19c4047766c42cd0.png" width="1098" height="454" class="img_ev3q"></p>
<p>The orange underline metric displays when the throttled write rate is applied.</p>
<p><img decoding="async" loading="lazy" alt="exporting-per-partition-post-throttling" src="https://camunda.github.io/zeebe-chaos/assets/images/exporting-per-partition-post-throttling-725f5e30d24caaef42c564ce2a986dcd.png" width="1999" height="293" class="img_ev3q"></p>
<p>From the panels of the â€œExporting per Partitionâ€ and â€œNumber of records not exportedâ€, we can observe that during the re-run of the experience our artificially degrading of the exporters only affected Exporters 2 and 3.
After we enable throttling, the backlog on these affected exporters starts to decrease as expected, later stabilizing on around 100,000 records.
This will drop back to 0 once we remove the artificial degrading of the exporters.</p>
<p><img decoding="async" loading="lazy" alt="backpressure-post-throttling" src="https://camunda.github.io/zeebe-chaos/assets/images/backpressure-post-throttling-77bb875c059269233e3d7b30c81ca1b9.png" width="1984" height="460" class="img_ev3q"></p>
<p>In the backpressure, we observe that this increases mostly on the affected partitions 2 and 3, and once the number of records not exported reaches the acceptable level this lowers slightly and stabilizes.</p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition-post-throttling" src="https://camunda.github.io/zeebe-chaos/assets/images/processing-per-partition-post-throttling-9aa68235837dd795cbb5a10bd875f3b5.png" width="1999" height="290" class="img_ev3q"></p>
<p>Finally, on the panel that shows the processing per partition, we also confirm the expectation that since one of the exporters was not affected by the artificial degrading of the exporter, some additional traffic gets re-routed to this partition, after the throttling gets applied.
On the affected partitions we see the processing decreasing slightly in line with the exporting on the same partitions.</p>
<p>Overall the observations match our expectations and show that write rate throttling succeeds and keeps exporting backlog limited.</p>]]></content>
        <author>
            <name>Rodrigo Lopes</name>
            <uri>https://github.com/rodrigo-lourenco-lopes</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using flow control to handle uncontrolled process loops]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops"/>
        <updated>2024-07-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).]]></summary>
        <content type="html"><![CDATA[<p>Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).</p>
<p>Limiting the write rate is a new feature that can be used to prevent building up an excessive exporting backlog.</p>
<p>In these experiments we will test what happens with the deployment of endless
loops that result in high processing load, and how we can use the new
flow control to keep the cluster stable.</p>
<p><strong>TL;DR;</strong></p>
<p>Enabling the write rate limiting can help mitigate the effects caused by
process instances that contain uncontrolled loops by preventing building up an
excessive exporting backlog.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mitigating-the-performance-impacts-of-deployed-loops">Mitigating the performance impacts of deployed loops:<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#mitigating-the-performance-impacts-of-deployed-loops" class="hash-link" aria-label="Direct link to Mitigating the performance impacts of deployed loops:" title="Direct link to Mitigating the performance impacts of deployed loops:">â€‹</a></h2>
<p>When an uncontrolled loop is accidentally deployed this tends to use of
most of the
processing resources of the partitions where instances are running.</p>
<p>Such instances completely occupies its partition, starves other instances and results in slow response times.</p>
<p>Usually, these problems should be addressed before other issues arise, such as full disk due to a large backlog of not exported records (max exporting speed tends to be slower than max processing speed).</p>
<p>Using the write rate limiter, we can slow down the processing speed and
give us more time to address the issue, while at the same time enabling us to reduce or maintain the backlog size and reduce risks of side effects.</p>
<p>To reduce the rate write limit we will use the unified control endpoint and configure write limit to be significantly lower than the processing speed.</p>
<p>To fetch the current configuration we can port forward to one of the zeebe pods and use the command:</p>
<div class="language-Shell language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">GET /actuator/flowControl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="original-configuration" src="https://camunda.github.io/zeebe-chaos/assets/images/original-configuration-568ece5f5f513848f06d772b821f7ba6.png" width="586" height="532" class="img_ev3q"></p>
<p>To configure the write rate limit we use the same endpoint:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   "write": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        "limit": 3000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For this experiment we will test the impact of write rate limits both in
single loops and dual loops.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="single-loop-processing">Single loop processing:<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#single-loop-processing" class="hash-link" aria-label="Direct link to Single loop processing:" title="Direct link to Single loop processing:">â€‹</a></h2>
<p><img decoding="async" loading="lazy" alt="single-loop" src="https://camunda.github.io/zeebe-chaos/assets/images/single-loop-2c6d288753c26789a55ac011536dcf6a.png" width="1090" height="634" class="img_ev3q"></p>
<p>This single-loop process will hoard the processing resources and never complete but will append to the processing queue only the next step in the process.</p>
<p>This means that the number of records not processed will only grow if many other processes or requests are arriving at the same time, at a faster rate than the cluster can process.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-results">Expected results:<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#expected-results" class="hash-link" aria-label="Direct link to Expected results:" title="Direct link to Expected results:">â€‹</a></h3>
<p>When deploying a process instance with a single loop we should see the
processing rate in the partition increases significantly.</p>
<p>This can lead to processing speed to surpass the exporting speed, which
results in increase in the backlog of exported records.</p>
<p>Using the rate write limits to restrict the processing speed enables us to
reduce the backlog size and give more time for the user to fix the
underlying issues with the cluster.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>By deploying a single loop model we can see that the processing and writing
increases in the same partition and stabilizes around 5 000, later at
around 17:55 we apply the write rate limit of 3 000, and the processing
gets limited accordingly.</p>
<p>This leads to some of the requests being
redirected to
the other partitions which cause the processing in these to increase.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-processing-per-partition" src="https://camunda.github.io/zeebe-chaos/assets/images/single-loop-processing-per-partition-5a64caa8af538a2e888591a0d00f7ab1.png" width="1999" height="290" class="img_ev3q"></p>
<p>When observing the backpressure, we can draw the same conclusions as from
the processing per partition graph, after the model gets deployed, we see an
increase in the backpressure to around 7% in the partition where the loop
instance was deployed.</p>
<p>Once the limit gets set at around 17:55 the backpressure in this partition
increases even more, to around 22% with the backpressure in the other partitions also increasing significantly.</p>
<p>This follows the expected results since with the limiting processing, the after partition will reject even more commands, which get redirected to the remaining partitions which also cause their load to increase and therefore their backpressure as well.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-backpressure" src="https://camunda.github.io/zeebe-chaos/assets/images/single-loop-backpressure-3a91001378b847e1184ccb2e1e36d13a.png" width="1972" height="456" class="img_ev3q"></p>
<p>Observing the exporting per partition panel we can see that the exporting also increases in the affected partition, and this gets reduced after the limit gets imposed.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-exporting-per-partition" src="https://camunda.github.io/zeebe-chaos/assets/images/single-loop-exporting-per-partition-c72cfee7a14b98c2a7e45945c63f2e99.png" width="1999" height="293" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dual-loop-processing">Dual loop processing:<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#dual-loop-processing" class="hash-link" aria-label="Direct link to Dual loop processing:" title="Direct link to Dual loop processing:">â€‹</a></h2>
<p><img decoding="async" loading="lazy" alt="double-loop" src="https://camunda.github.io/zeebe-chaos/assets/images/dual-loop-629f9c9afa1f36b5bab529656d32cf42.png" width="976" height="612" class="img_ev3q"></p>
<p>On the other hand, this dual loop process during its run will always create more records than can be processed since it doubles in the last step.</p>
<p>This will create a steady increase in records not processed even if no other processes or requests are competing for processing time.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h2>
<p>When deploying a process instance with a dual loop we should expect to see
a rapid increase in the processing speed and also in the number of records
not processed.</p>
<p>In this case, restricting the processing speed should not decrease the
backlog of processed records since on each run of the loop more records are
created than
processed.</p>
<p>However, it should help us at least in reducing the pace of the increase in
the backlog and therefore give us more time to address the
underlying problem.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://camunda.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h2>
<p>After deploying the dual loop we can see that the processing quickly jumps to its peak, at around 18:11 we configure the write rate limit at 3000.</p>
<p>Unlike the previous experience here we can observe that the processing speed in the other partitions was already increasing before the configuration gets applied.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-processing-per-partition" src="https://camunda.github.io/zeebe-chaos/assets/images/dual-loop-processing-per-partition-89041e42051a2123a5c442c197ad08fe.png" width="1999" height="288" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="dual-loop-exporting-per-partition" src="https://camunda.github.io/zeebe-chaos/assets/images/dual-loop-exporting-per-partition-65937890949ec823d82338a744ad7ffe.png" width="1999" height="295" class="img_ev3q"></p>
<p>Observing the backpressure we get the answer as to why the processing in the other partitions was already increasing before the configuration gets applied.</p>
<p>The backpressure had already reached at 100% which means that the dual loop process by itself hoarded completely the processing resources of the partition.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-backpressure" src="https://camunda.github.io/zeebe-chaos/assets/images/dual-loop-backpressure-824800471f8562faea35e72be8d9be05.png" width="1966" height="462" class="img_ev3q"></p>
<p>Observing the number of records not processed we conclude as expected that
limiting the write rate cannot stop the records backlog from continuing to increase, but we can see that the slope of the curve is smaller after configuring the limit.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-records-not-exported" src="https://camunda.github.io/zeebe-chaos/assets/images/dual-loop-number-of-records-not-processed-7e4a14070299c6842e16c7496e6b99cd.png" width="1106" height="462" class="img_ev3q"></p>
<p>Overall the results match our expectations that the flow control configuration can be leveraged to give us more control of the cluster, which in the case of acting on deployed loop instances can give us more tools to address these issues.</p>
<p><em>Footnote:
(As of the latest release, it is no longer possible to deploy processes that
contain a straight-through processing loops such as the ones used in this
experience).</em></p>]]></content>
        <author>
            <name>Rodrigo Lopes</name>
            <uri>https://github.com/rodrigo-lourenco-lopes</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reducing the job activation delay]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency</id>
        <link href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency"/>
        <updated>2024-01-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:]]></summary>
        <content type="html"><![CDATA[<p>With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:</p>
<ul>
<li>How much is a single job activation latency reduced?</li>
<li>How much is the activation latency reduced between each task of the same process instance?</li>
<li>How much is the activation latency reduced on large clusters with a high broker and partition count?</li>
</ul>
<p>Additionally, we wanted to guarantee that every component involved in streaming, including clients, would remain resilient in the face of load surges.</p>
<p><strong>TL;DR;</strong> Job activation latency is greatly reduced, with task based workloads seeing up to 50% reduced overall execution latency. Completing a task now immediately triggers pushing out the next one, meaning the latency to activate the next task in a sequence is bounded by how much time it takes to process its completion in Zeebe. Activation latency is unaffected by how many partitions or brokers there in a cluster, as opposed to job polling, thus ensuring scalability of the system. Finally, reuse of gRPC's flow control mechanism ensure clients cannot be overloaded even in the face of load surges, without impacting other workloads in the cluster.</p>
<p><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#job-streaming" target="_blank" rel="noopener noreferrer">Head over to the documentation to learn how to start using job push!</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-job-activation-latency-matters">Why job activation latency matters<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#why-job-activation-latency-matters" class="hash-link" aria-label="Direct link to Why job activation latency matters" title="Direct link to Why job activation latency matters">â€‹</a></h2>
<p>Jobs are one of the fundamental building blocks of Zeebe, representing primarily all tasks (e.g. service, send, user), as well as some less obvious symbols (e.g. intermediate message throw event). In essence, they represent the actual unit of work in a process, the part users will implement, i.e. the actual application code. To reduce the likelihood of a job being worked on by multiple clients at the same time, it first goes through an activation process, where it is soft-locked for a specific amount of time. Soft-locked here means anyone can still interact with it - they can complete the job, fail it, etc. Only the activation is locked out, meaning no one else can activate the job until it's timed out.</p>
<p>This means that most workloads will consist mostly of job interactions: creation, activation, completion, etc. As such, it's critical to ensure clients receive jobs as fast as possible in order to make progress.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="polling-a-first-implementation">Polling: a first implementation<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#polling-a-first-implementation" class="hash-link" aria-label="Direct link to Polling: a first implementation" title="Direct link to Polling: a first implementation">â€‹</a></h2>
<p>Back in 2018, Zeebe introduced the <code>ActivateJobs</code> RPC for its gRPC clients, analogous to fetching and locking <a href="https://docs.camunda.org/manual/7.20/user-guide/process-engine/external-tasks/" target="_blank" rel="noopener noreferrer">external tasks in Camunda 7.x</a>. This endpoint allowed clients to activate fetch and activate a specific number of available jobs. In other words, it allowed them to <em>poll</em> for jobs.</p>
<p>This was the first implementation to activate and work on jobs in Zeebe for multiple reason:</p>
<ul>
<li>It follows a simple request/response pattern</li>
<li>Flow control is delegated to the client/user</li>
<li>Most other approaches will build onto the building blocks used by polling</li>
<li>You will likely implement polling anyway as a fallback for other approaches (e.g. pushing)</li>
</ul>
<p>Grossly simplified, the implementation worked like this:</p>
<p><img decoding="async" loading="lazy" alt="Job polling" src="https://camunda.github.io/zeebe-chaos/assets/images/job-poll-fbf0a5b11cac5467c5daba1424bc9230.png" width="784" height="554" class="img_ev3q"></p>
<ul>
<li>A client initiates an <code>ActivateJobs</code> call by sending an initial request</li>
<li>The gateway receives the request and validates it</li>
<li>The gateway starts polling each partition synchronously one by one</li>
<li>Whenever jobs are received from a partition, it forwards them to the client</li>
<li>When all partitions are exhausted, or the maximum number of jobs have been activated, the request is closed</li>
</ul>
<p>Already we can infer certain performance bottle necks based on the following:</p>
<ul>
<li>Every request - whether client to gateway, or gateway to broker - adds delay to the activation latency</li>
<li>In the worst case scenario, we have to poll <em>every</em> partition.</li>
<li>The gateway does not know in advance which partitions have jobs available.</li>
<li>Scaling out your clients may have adverse effects by sending out too many requests which all have to be processed independently</li>
<li><a href="https://github.com/camunda/camunda/issues/11813" target="_blank" rel="noopener noreferrer">If you have a lot of jobs, you can run into major performance issues when accessing the set of available jobs</a></li>
</ul>
<p>So if we have, say, 30 partitions, and each gateway-to-broker request takes 100ms, fetching the jobs on the last partition will take up to 3 seconds, even though the actual activation time on that partition was only 100ms.</p>
<p>Furthermore, if we have a sequence of tasks, fetching the next task in the sequence requires, in the worst case scenario, another complete round of polling through all the partitions, even though the task may already be available.</p>
<p>One would think a workaround to this issue would simply be to poll more often, but this can have an adverse impact: each polling request has to be processed by the brokers, and sending too many will simply flood your brokers and slow down all processing, further compounding the problem.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="long-polling-a-second-implementation">Long polling: a second implementation<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#long-polling-a-second-implementation" class="hash-link" aria-label="Direct link to Long polling: a second implementation" title="Direct link to Long polling: a second implementation">â€‹</a></h3>
<p>To simplify things, the Zeebe team introduced <a href="https://github.com/camunda/camunda/issues/2825" target="_blank" rel="noopener noreferrer">long polling in 2019</a>. <a href="https://en.wikipedia.org/wiki/Push_technology#Long_polling" target="_blank" rel="noopener noreferrer">Long polling</a> is a fairly common technique to emulate a push or streaming approach while maintaing the request-response pattern of polling. Essentially, if the server has nothing to send to the client, instead of completing the request it will hold it until content is available, or a timeout is reached.</p>
<p>In Zeebe, this means that if we did not reach the maximum number of jobs to activate after polling all partitions, the request is parked but not closed. Eventually when jobs are available, the brokers will make this information known to the gateways, who will then unpark the oldest request and start a new polling round.</p>
<p><img decoding="async" loading="lazy" alt="Job polling" src="https://camunda.github.io/zeebe-chaos/assets/images/job-long-poll-87a951a59369f8452d9a3e2f36421d8e.png" width="784" height="835" class="img_ev3q"></p>
<p>This solved certain problems:</p>
<ul>
<li>We reduced the amount of requests sent by clients, thus reducing load on the cluster.</li>
<li>In some cases, we reduced the latency when activating the next task in sequence.</li>
</ul>
<p>However, there are still some issues:</p>
<ul>
<li>When receiving the notification we <em>still</em> have to poll all partitions.</li>
<li>If you have multiple gateways, all gateways will start polling if they have parked requests. Some of them may not get any jobs, but they will still have sent requests to brokers which still all have to be processed.</li>
<li>In high load cases, you still need another client request/poll cycle to fetch the next task in a sequence.</li>
<li>Scaling out your clients still add more load on the system, even if the poll less often</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="job-push-third-times-the-charm">Job push: third time's the charm<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#job-push-third-times-the-charm" class="hash-link" aria-label="Direct link to Job push: third time's the charm" title="Direct link to Job push: third time's the charm">â€‹</a></h2>
<p>In order to solve these issues, the team decided to implement <a href="https://github.com/camunda/camunda/issues/11231" target="_blank" rel="noopener noreferrer">a push-based approach to job activation</a>.</p>
<p>Essentially, we added a new <code>StreamActivatedJobs</code> RPC to our gRPC protocol, a so-called <a href="https://grpc.io/docs/what-is-grpc/core-concepts/#server-streaming-rpc" target="_blank" rel="noopener noreferrer">server streaming RPC</a>. In our case, this is meant to be a long-lived stream, such that the call is completed only if the client terminates it, or if the server is shutting down.</p>
<p>The stream itself has the following lifecycle:</p>
<p><img decoding="async" loading="lazy" alt="Job push" src="https://camunda.github.io/zeebe-chaos/assets/images/job-push-a314bcca5464ddee542b00633cc58d1b.png" width="784" height="612" class="img_ev3q"></p>
<ul>
<li>The client initiates the stream by sending a job activation request much like with the <code>ActivateJobs</code> RPC.<!-- -->
<ul>
<li>Since the stream is meant to be long lived, however, there is no upper bound on the number of jobs to activate.</li>
</ul>
</li>
<li>The gateway registers the new stream with all brokers in the cluster<!-- -->
<ul>
<li>Note that there is no direct connection between brokers and client; the gateway acts as a proxy for the client.</li>
</ul>
</li>
<li>When jobs are available for activation (e.g. on creation, on timeout, on backoff, etc.), the broker activates the job and pushes it to the gateway.</li>
<li>The gateway forwards the job to the client.</li>
</ul>
<p><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#how-it-works" target="_blank" rel="noopener noreferrer">You can read more about the implementation as part of our docs.</a></p>
<blockquote>
<p>Experienced readers will immediately spot that push-based approaches run the risk of overloading the client. Thanks to the built-in flow control facilities of gRPC, we can still ensure clients are resilient in the face of load surges. See <a href="https://docs.camunda.io/docs/components/concepts/job-workers/#backpressure" target="_blank" rel="noopener noreferrer">here for an explanation</a>.</p>
</blockquote>
<p>This solved most, if not all, of the problems listed above:</p>
<ul>
<li>Brokers push jobs out immediately as they become available, removing the need for a gateway-to-broker request.</li>
<li>Since the stream is long lived, there are almost no client requests required after the initial one.</li>
<li>No need to poll every partition anymore.</li>
<li>No thundering herd issues if you have many gateways all polling at the same time due to a notification.</li>
<li>Scaling out your clients adds little to no load to the system, as idle clients simply do nothing.</li>
<li>Even if you have a lot of jobs, in the average case, you never have to iterate over them and instead the broker pushes the job out on creation.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tests-results-and-comparisons">Tests, results, and comparisons<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#tests-results-and-comparisons" class="hash-link" aria-label="Direct link to Tests, results, and comparisons" title="Direct link to Tests, results, and comparisons">â€‹</a></h3>
<p>In order to compare the advantages of pushing to polling, we did three different experiments.</p>
<blockquote>
<p>Note that all throughput measurements are in process instances executed per second, shortened to PI/s. Additionally, in the results shown below, dotted lines in graphs always refer to job polling measurements, and filled lines to job pushing.</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cluster-specifications">Cluster specifications<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#cluster-specifications" class="hash-link" aria-label="Direct link to Cluster specifications" title="Direct link to Cluster specifications">â€‹</a></h4>
<p>Note that, unless specificed otherwise, we used the following clusters to run the tests: 3 brokers, 2 gateways, 3 partitions, replication factor 3.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="brokers">Brokers<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#brokers" class="hash-link" aria-label="Direct link to Brokers" title="Direct link to Brokers">â€‹</a></h5>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>1350m</td></tr><tr><td>Memory request</td><td>4Gi</td></tr><tr><td>CPU thread count</td><td>3</td></tr><tr><td>IO thread count</td><td>3</td></tr><tr><td>Disk type</td><td><a href="https://cloud.google.com/compute/docs/disks#disk-types" target="_blank" rel="noopener noreferrer">pd-ssd</a></td></tr><tr><td>Disk size</td><td>32Gi</td></tr></tbody></table>
<blockquote>
<p>Disk type, size, and vCPU count in GCP is used to determine your maximum IOPS.</p>
</blockquote>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="gateways">Gateways<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#gateways" class="hash-link" aria-label="Direct link to Gateways" title="Direct link to Gateways">â€‹</a></h5>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>450m</td></tr><tr><td>Kubernetes memory request</td><td>1Gi</td></tr><tr><td>Management thread count</td><td>2</td></tr></tbody></table>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="workers">Workers<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#workers" class="hash-link" aria-label="Direct link to Workers" title="Direct link to Workers">â€‹</a></h5>
<p>To simulate work, whenever workers receive an activated job, they will wait 50ms before completing it.</p>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>500m</td></tr><tr><td>Kubernetes memory request</td><td>256Mi</td></tr><tr><td>Thread count</td><td>10</td></tr><tr><td>Max jobs active</td><td>60</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="one-task">One task<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#one-task" class="hash-link" aria-label="Direct link to One task" title="Direct link to One task">â€‹</a></h4>
<p>As our baseline test, we ran a constant throughput of 150 PI/s of a single task process workload:</p>
<p><img decoding="async" loading="lazy" alt="A single task BPMN process: start -&amp;gt; task -&amp;gt; end" src="https://camunda.github.io/zeebe-chaos/assets/images/single-task-bpmn-99ed3a15761cf3fbe8bfdc20807d4c7e.png" width="999" height="276" class="img_ev3q"></p>
<p>Since each job takes at least 50ms of work, the lower bound execution latency for this process is 50ms.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s single task process" src="https://camunda.github.io/zeebe-chaos/assets/images/single-task-benchmark-4ef8a419140fd42094f359a54a74000b.png" width="1907" height="867" class="img_ev3q"></p>
<p>The results show a sharp decrease in both the p50 and p99 of the job lifetime (i.e. the time between creation and completion). Since this workload only consists of a single task, this is mirrored in the overall process execution latency. Overall, we see that switching to a push approach yields a p50 latency improvement of 50%, and a p99 improvement of 75%!</p>
<p>Additionally, we can see with job push that the Zeebe the p50 processing overhead is ~14ms, and the p99 ~390ms. For job polling, the p50 overhead is ~70ms, and the p99 overhead is ~1.7s.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ten-tasks">Ten tasks<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#ten-tasks" class="hash-link" aria-label="Direct link to Ten tasks" title="Direct link to Ten tasks">â€‹</a></h4>
<p>For our next test, we ran a constant throughput of 150 PI/s of a ten tasks sequence process:</p>
<p><img decoding="async" loading="lazy" alt="A ten tasks sequence BPMN process: start -&amp;gt; task_1 -&amp;gt; task_2 -&amp;gt; ... -&amp;gt; task_10 -&amp;gt; end" src="https://camunda.github.io/zeebe-chaos/assets/images/ten-tasks-bpmn-2617d2c0ddb0a87947bd2019efb66e74.png" width="2247" height="1137" class="img_ev3q"></p>
<p>Since each job takes at least 50ms of work, the lower bound execution latency for this process is 500ms.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s single task process" src="https://camunda.github.io/zeebe-chaos/assets/images/ten-tasks-benchmark-bdae0ac5942ee080b193dbe7294ced1f.png" width="1901" height="864" class="img_ev3q"></p>
<p>The results show a sharp decrease in both the p50 and p99 of the job lifetime (i.e. the time between creation and completion). In this case, the process consists of several tasks, so the process execution latency is noticeably higher. But we can see that the p50 latency for job push is ~640ms. Overall, we see that switching to a push approach yields a p50 latency improvement of 30%, and a p99 improvement of 50%!</p>
<p>Additionally, we can see with job push that the Zeebe the p50 processing overhead is ~140ms, and the p99 ~1.8s. For job polling, the p50 overhead is ~1.4s, and the p99 overhead is ~4.3s.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="large-cluster">Large cluster<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#large-cluster" class="hash-link" aria-label="Direct link to Large cluster" title="Direct link to Large cluster">â€‹</a></h4>
<p>In order to verify that the approach will scale along with the cluster size, we next compared polling and pushing with a cluster of 30 brokers and 30 partitions. Again, we tested with the single task process as above, and a constant throughput of 150 PI/s.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s against a large cluster" src="https://camunda.github.io/zeebe-chaos/assets/images/thirty-partitions-benchmark-63cde3904d51c5b209efc0a1e9aad02e.png" width="1905" height="859" class="img_ev3q"></p>
<p>For job push, we see a greatly improved p99 - since each partition is doing less work than before with 3 partitions, we can achieve much more stable performance, with the p99 being quite close to the p50.</p>
<p>For job poll however, we see the downside of having to poll each partition in turn: the p50 is worse than before, and even though the p99 is greatly improved, we can see a wave pattern where it will spike up to 3s, so a decrease compared to the smaller cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="client-backpressure--load-surges">Client backpressure &amp; load surges<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#client-backpressure--load-surges" class="hash-link" aria-label="Direct link to Client backpressure &amp; load surges" title="Direct link to Client backpressure &amp; load surges">â€‹</a></h4>
<p>One of the downsides of switching to a push approach, unfortunately, is that the client is now at risk of receiving more work than it can safely handle.</p>
<p>Thankfully, HTTP/2 and gRPC both have mechanisms to ensure flow control for server streaming RPCs.</p>
<p><a href="https://camunda.github.io/zeebe-chaos/2023/11/30/Job-push-overloading" target="_blank" rel="noopener noreferrer">You can find our tests results in a separate blog post</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="further-reading">Further reading<a href="https://camunda.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#further-reading" class="hash-link" aria-label="Direct link to Further reading" title="Direct link to Further reading">â€‹</a></h2>
<p>You can read more about job push here:</p>
<ul>
<li><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#job-streaming" target="_blank" rel="noopener noreferrer">Streaming job workers</a></li>
<li><a href="https://docs.camunda.io/docs/apis-tools/java-client/job-worker/#job-streaming" target="_blank" rel="noopener noreferrer">Job push for the Java client</a></li>
<li><a href="https://docs.camunda.io/docs/apis-tools/go-client/job-worker/#job-streaming" target="_blank" rel="noopener noreferrer">Job push for the Go client</a></li>
<li><a href="https://github.com/camunda-community-hub/spring-zeebe#enable-job-streaming" target="_blank" rel="noopener noreferrer">Job push for spring-zeebe</a></li>
</ul>
<p>Additionally, we've already written two other blog posts:</p>
<ul>
<li><a href="https://camunda.github.io/zeebe-chaos/2023/11/30/Job-push-overloading" target="_blank" rel="noopener noreferrer">Client backpressure resilience</a></li>
<li><a href="https://camunda.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency" target="_blank" rel="noopener noreferrer">Job stream fault tolerance</a></li>
</ul>]]></content>
        <author>
            <name>Nicolas Pepin-Perreault</name>
            <uri>https://github.com/npepinpe</uri>
        </author>
        <category label="availability" term="availability"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Broker Scaling and Performance]]></title>
        <id>https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance</id>
        <link href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance"/>
        <updated>2023-12-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[With Zeebe now supporting the addition and removal of brokers to a running cluster, we wanted to test three things:]]></summary>
        <content type="html"><![CDATA[<p>With Zeebe now supporting the addition and removal of brokers to a running cluster, we wanted to test three things:</p>
<ol>
<li>Is there an impact on processing performance while scaling?</li>
<li>Is scaling resilient to high processing load?</li>
<li>Can scaling up improve processing performance?</li>
</ol>
<p><strong>TL;DR;</strong> Scaling up works even under high load and has low impact on processing performance. After scaling is complete, processing performance improves in both throughput and latency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="impact-of-scaling-on-processing-performance">Impact of scaling on processing performance<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#impact-of-scaling-on-processing-performance" class="hash-link" aria-label="Direct link to Impact of scaling on processing performance" title="Direct link to Impact of scaling on processing performance">â€‹</a></h2>
<p>Scaling up and down is an expensive operation where partition data is transferred between brokers, and leadership for partitions changes.
We wanted to test how much impact this has on regular processing performance.</p>
<p>To do this, we ran a benchmark with 3 brokers, 6 partitions and replication factor 3.</p>
<p>The brokers are limited to 1.35 CPUs and 4GiB RAM each.
They run with additional safety checks that are usually disabled in production and that slightly decrease the baseline processing performance.
Each broker uses a small 32GiB SSD for storage, limiting them to a few thousand IOPS.</p>
<p>The processing load was 150 processes per second, with a large payload of 32KiB each.
Each process instance has a single service task:</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/one_task-f083f237e568d87cc17eef056cb45d73.png" width="999" height="276" class="img_ev3q"></p>
<p>The processing load is generated by our own <a href="https://github.com/camunda/camunda/tree/9e723b21b0e408fc2b97fd7d3f6b092af8e62dbe/benchmarks" target="_blank" rel="noopener noreferrer">benchmarking application</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we scale up from 3 to 6 brokers, we expect a small impact on processing performance.
Request latency may increase slightly, some requests may time out and some will be rejected due to backpressure.
The overall throughput in terms of created and completed process instances as well as jobs may similarly decrease slightly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Following are screenshots of collected metrics.
The blue annotation marks the time where scaling occurred.</p>
<p>We see a short increase in process instance duration, meaning that some process instances were finished slightly slower than before.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/increased_process_duration-3bc31b565412bb200dd5004cf1a393f9.png" width="840" height="296" class="img_ev3q"></p>
<p>The throughput in terms of created and completed process instances and jobs remained very stable.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/stable_throughput-92c3e8b4711794408ae03779025d148b.png" width="1665" height="296" class="img_ev3q"></p>
<p>We see a small increase in requests timing out or getting rejected by backpressure.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/failed_requests-47e5e20dec7558d9bf262572e4bceef2.png" width="840" height="296" class="img_ev3q"></p>
<p>Overall, this matches our expectation and shows that scaling up has a small impact on processing performance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-under-load">Scaling under load<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#scaling-under-load" class="hash-link" aria-label="Direct link to Scaling under load" title="Direct link to Scaling under load">â€‹</a></h2>
<p>Since scaling up is supposed to alleviate high processing load for brokers, it's important that it works even under high load.
For this test, we increased the load on the same cluster setup as before to 210 instead of 150 process instances per second.
This is roughly the maximum throughput that the 3 brokers with 6 partitions and replication factor 3 can handle.
We can see this from the relatively high backpressure, as well as high process instance duration.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/high_load_backpressure-5c264822dfc52c8f31072e9a41e892e3.png" width="628" height="220" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/high_load_latency-75cc8b8a9b6ceb63a32d418e96a649f4.png" width="840" height="296" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect that scaling up to 6 brokers will still complete successfully, even under high load.
The time it takes until scaling is complete might be slightly higher.
The impact on processing performance, both in terms of throughput and latency, may be slightly larger than in the previous experiment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>The process instance duration did not increase, and even decreased slightly.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/high_load_scaling_latency-bda55e145412ae73d60bcefa7129ea4c.png" width="840" height="296" class="img_ev3q"></p>
<p>Similarly, the throughput in terms of created and completed process instances and jobs remained relatively stable.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/high_load_scaling_throughput-d1da75d1c6483a9801c0cb46c85dd112.png" width="1687" height="296" class="img_ev3q"></p>
<p>The number of failed requests increased slightly, but still well within an acceptable range.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/high_load_scaling_failed_requests-74619f4fae76f750b3dd1a7e548ae5a9.png" width="840" height="296" class="img_ev3q"></p>
<p>The scaling operation took 5 minutes, a good portion of which is waiting for the new brokers to get scheduled and start up.</p>
<p>Overall, this matches our expectation and shows that scaling can complete fast and with low impact on processing performance, even under high load.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-up-to-improve-performance">Scaling up to improve performance<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#scaling-up-to-improve-performance" class="hash-link" aria-label="Direct link to Scaling up to improve performance" title="Direct link to Scaling up to improve performance">â€‹</a></h2>
<p>The most obvious goal of scaling brokers is to unlock additional processing performance.
While vertical scaling is also a great option, this can hit limits imposed by your infrastructure provider.
For example, some machine types may offer great CPU performance but are severely limited in IOPS.
Additionally, vertical scaling is often more expensive than horizontal scaling.
It also comes with increased risk when a single machine fails because the remaining machines may already run at their limits and will then struggle to handle the additional load during failover.</p>
<p>To show how broker scaling can improve processing performance, we reused the same cluster setup as before.
We have 3 brokers, 6 partitions and replication factor 3.</p>
<p>The brokers are limited to 1.35 CPUs and 4GiB RAM each.
They run with additional safety checks that are usually disabled in production and that slightly decrease the baseline processing performance.
Each broker uses a small 32GiB SSD for storage, limiting them to a few thousand IOPS.</p>
<p>We changed the processing load slightly to simulate a more realistic scenario.
The new process model consists of 10 tasks with two timers in-between, each delaying the process instance by 1 minute.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/ten_tasks-97eff1de6db0dbb79ae9681cedd14a93.png" width="5823" height="576" class="img_ev3q"></p>
<p>The processing load is generated by our own <a href="https://github.com/camunda/camunda/tree/9e723b21b0e408fc2b97fd7d3f6b092af8e62dbe/benchmarks" target="_blank" rel="noopener noreferrer">benchmarking application</a>, initially starting 40 process instances per second.</p>
<p>This results in 400 jobs created and completed per second.</p>
<p>This stresses the 3 brokers and we see backpressure on all partitions.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_initial_backpressure-ff99c218bd0d2169e80612db06918bee.png" width="628" height="220" class="img_ev3q"></p>
<p>We also see a few jobs timing out, indicating that the cluster is unable to handle this load consistency:
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_initial_timeouts-184ec92cae00e964d1cb981d81c9094c.png" width="840" height="220" class="img_ev3q"></p>
<p>We also see that many jobs are active for much longer than 1 second, even though the workers only delay completion by 50ms.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_initial_job_lifetime-aa635408ad750e58f3c4d5aba42cfb71.png" width="840" height="296" class="img_ev3q"></p>
<p>As hinted at before, much of this performance limit can be attributed to the limited IOPS of the small SSDs.
We see this in a very high commit and write latency, while the IOPS remain stable, right at the limit of what the SSDs can handle.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_initial_iops-ef1bfdab00c42f7e496bb8361b82837f.png" width="840" height="296" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_initial_commit_latency-1618c887bba63eaf893d2073070c58a6.png" width="840" height="258" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_initial_write_latency-fdfbc2b5a7814ded4ce935a4432c27b2.png" width="840" height="258" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we scale up to 6 brokers, and thus distribute the partitions such that each broker is only leader for 1 instead of 2 partitions, we expect that processing performance improves.</p>
<p>As these things usually go, we don't expect a doubling in performance but aiming for a 1.5x improvement seems reasonable.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://camunda.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Shortly after scaling up and after partition leadership has balanced, we see a significant improvement in backpressure.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_after_backpressure-8ea0858dc7e2dbd99c1d9072ad4e9d9e.png" width="628" height="220" class="img_ev3q"></p>
<p>The job lifetime decreases dramatically, with most jobs now taking &lt; 50ms from creation until completion.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_after_job_lifetime-1484937ab54af54c7c9c62e4d3f40bed.png" width="840" height="296" class="img_ev3q"></p>
<p>Overall processing latency improves similarly.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_after_processing_latency-0dc8cc62dc0d3416af386c2f7f3b8a7a.png" width="1688" height="258" class="img_ev3q"></p>
<p>Much of this improvement can be attributed to the reduced IOPS.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_after_iops-9d4cfe0e830dc5b2172dba4cf77c772b.png" width="840" height="296" class="img_ev3q"></p>
<p>Commit and write latency improves accordingly.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_after_commit_latency-3038b133286dfe6303ae585152b74ddf.png" width="840" height="258" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_after_write_latency-83d3d31f30acf064ee5c31792718e02c.png" width="840" height="258" class="img_ev3q"></p>
<p>Another source for improved performance is reduced CPU load.
With 3 brokers being leader for 2 partitions each, they were hitting their CPU limits and got throttled by the underlying infrastructure.
With 6 brokers, each only being leader for 1 partition, the CPU load is reduced and brokers are no longer throttled.
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_after_cpu-27360ba363b21f8be99ae11009830041.png" width="840" height="296" class="img_ev3q"></p>
<p>While this is already a success, we can push things further now.
We are able to increase the load from 40 to 65 process instances per second, resulting in 650 jobs created and completed per second.
This is a 1.6x improvement over the initial load while achieving similar backpressure.</p>
<p><img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_increased_load_backpressure-50539a70042461e4c0f57395ab9a2981.png" width="628" height="220" class="img_ev3q"></p>
<p>Job lifetime and overall processing latency is still better than before scaling up, even though load increased by 1.6x
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_increased_load_job_lifetime-357a5db1cfce78fb1788dc3bd8dd83c5.png" width="840" height="296" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://camunda.github.io/zeebe-chaos/assets/images/perf_increased_load_processing_latency-629f9fc40962d34a30a3a51c2b62c7ba.png" width="1688" height="258" class="img_ev3q"></p>
<p>Overall, this shows that scaling up can improve processing performance significantly, especially when the initial cluster setup is resource limited and vertical scaling is not possible.</p>]]></content>
        <author>
            <name>Lena SchÃ¶nburg</name>
            <uri>https://github.com/lenaschoenburg</uri>
        </author>
        <author>
            <name>Deepthi Akkoorath</name>
            <uri>https://github.com/deepthidevaki</uri>
        </author>
        <category label="availability" term="availability"/>
        <category label="performance" term="performance"/>
    </entry>
</feed>