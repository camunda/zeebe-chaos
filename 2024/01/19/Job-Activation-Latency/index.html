<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.6.3">
<title data-rh="true">Reducing the job activation delay | Zeebe Chaos</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Reducing the job activation delay | Zeebe Chaos"><meta data-rh="true" name="description" content="With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:"><meta data-rh="true" property="og:description" content="With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-01-19T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/npepinpe"><meta data-rh="true" property="article:tag" content="availability"><link data-rh="true" rel="icon" href="/zeebe-chaos/img/zeebe-logo.png"><link data-rh="true" rel="canonical" href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency"><link data-rh="true" rel="alternate" href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency" hreflang="en"><link data-rh="true" rel="alternate" href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency","mainEntityOfPage":"https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency","url":"https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency","headline":"Reducing the job activation delay","name":"Reducing the job activation delay","description":"With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:","datePublished":"2024-01-19T00:00:00.000Z","author":{"@type":"Person","name":"Nicolas Pepin-Perreault","description":"Senior Software Engineer @ Zeebe","url":"https://github.com/npepinpe","image":"https://github.com/npepinpe.png"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://zeebe-io.github.io/zeebe-chaos/","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/zeebe-chaos/rss.xml" title="Zeebe Chaos RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zeebe-chaos/atom.xml" title="Zeebe Chaos Atom Feed"><link rel="stylesheet" href="/zeebe-chaos/assets/css/styles.09e3c82e.css">
<script src="/zeebe-chaos/assets/js/runtime~main.f16cbbd7.js" defer="defer"></script>
<script src="/zeebe-chaos/assets/js/main.9aca7aa3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zeebe-chaos/"><div class="navbar__logo"><img src="/zeebe-chaos/img/zeebe-logo.png" alt="Zeebe" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/zeebe-chaos/img/zeebe-logo.png" alt="Zeebe" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Zeebe Chaos</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zeebe-chaos/">Chaos Summaries</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/zeebe-io/zeebe-chaos" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project">News from Camunda Exporter project</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance">Impact of Camunda Exporter on processing performance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP">Camunda Exporter MVP</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark">Optimizing cluster sizing using a real world benchmark</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/08/19/Operate-improve-import-latency">Improve Operate import latency</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/08/16/Operate-load-handling">Operate load handling</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting">Using flow control to handle bottleneck on exporting</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops">Using flow control to handle uncontrolled process loops</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/zeebe-chaos/2024/01/19/Job-Activation-Latency">Reducing the job activation delay</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2023</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/20/Broker-scaling-performance">Broker Scaling and Performance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss">Dynamic Scaling with Dataloss</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers">Dynamically scaling brokers</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/12/06/Job-Push-resiliency">Job push resiliency</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/11/30/Job-push-overloading">Job push overloading</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing">Hot backups impact on processing</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance">Using Large Multi-Instance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle">Continuing SST Partitioning toggle</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/05/15/SST-Partitioning-toggle">SST Partitioning toggle</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/04/06/gateway-termination">Gateway Termination</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2023/02/23/Recursive-call-activity">Recursive call activity</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2022</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition">Message Correlation after Network Partition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/08/02/deployment-distribution">Bring Deployment distribution experiment back</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS">Standalone Gateway in CCSaaS</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/02/01/High-Snapshot-Frequency">High Snapshot Frequency</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2022/01/19/big-variables">Handling of Big Variables</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2021</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance">Worker count should not impact performance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys">Not produce duplicate Keys</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/10/29/Throughput-on-big-state">Throughput on big state</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/10/05/recovery-time">Recovery (Fail Over) time</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/09/23/Old-Clients">Old-Clients</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/07/06/Slow-Network">Slow Network</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/06/08/Full-Disk">Full Disk Recovery</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/05/25/Reset-Clock">Time travel Experiment</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/04/29/Corrupted-Snapshot">Corrupted Snapshot Experiment Investigation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/04/03/bpmn-meets-chaos-engineering">BPMN meets Chaos Engineering</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/03/30/set-file-immutable">Set file immutable</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/03/23/camunda-cloud-network-partition">Camunda Cloud network partition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/03/09/cont-workflow-instance">Fault-tolerant processing of process instances</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/02/23/automate-deployments-dist">Automating Deployment Distribution Chaos Experiment</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/01/26/deployments">Deployment Distribution</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/01/19/network-partition">Network partitions</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2021/01/07/disconnect-leader-and-follower">Disconnect Leader and one Follower</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2020</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/11/24/message-correlation-after-failover">Message Correlation after Failover</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/11/11/job-timeouts">Many Job Timeouts</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/11/03/investigate-failing-tests">Investigate failing Chaos Tests</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/20/non-graceful-shutdown">Non-graceful Shutdown Broker</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/27/standalone-gw-memory">Gateway memory consumption</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/13/multiple-leader-changes">Multiple Leader Changes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/10/06/toxi-proxy">Play around with ToxiProxy</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/08/20/experiment-with-camunda-cloud">Experiment with Camunda Cloud</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/08/06/low-load">Experiment with Low Load</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/30/experiment-without-exporters">Experiment without Exporters</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/16/big-multi-instance">Big Multi Instance</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/09/timer-and-huge-variables">Experiment with Timers and Huge Variables</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/07/02/extract-k8-resources">Extract K8 resources from namespace</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/25/gateway-network-partition">Gateway Network Partition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/18/correlate-message-after-failover">Correlate Message after failover</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/11/high-cpu-gateway">High CPU load on Standalone Gateway</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zeebe-chaos/2020/06/04/first-chaos-day">First Chaos Day!</a></li></ul></div></nav></aside><main class="col col--7"><article><header><h1 class="title_f1Hy">Reducing the job activation delay</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-01-19T00:00:00.000Z">January 19, 2024</time> · <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/npepinpe.png" alt="Nicolas Pepin-Perreault"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Nicolas Pepin-Perreault</span></a></div><small class="authorTitle_nd0D" title="Senior Software Engineer @ Zeebe">Senior Software Engineer @ Zeebe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:</p>
<ul>
<li>How much is a single job activation latency reduced?</li>
<li>How much is the activation latency reduced between each task of the same process instance?</li>
<li>How much is the activation latency reduced on large clusters with a high broker and partition count?</li>
</ul>
<p>Additionally, we wanted to guarantee that every component involved in streaming, including clients, would remain resilient in the face of load surges.</p>
<p><strong>TL;DR;</strong> Job activation latency is greatly reduced, with task based workloads seeing up to 50% reduced overall execution latency. Completing a task now immediately triggers pushing out the next one, meaning the latency to activate the next task in a sequence is bounded by how much time it takes to process its completion in Zeebe. Activation latency is unaffected by how many partitions or brokers there in a cluster, as opposed to job polling, thus ensuring scalability of the system. Finally, reuse of gRPC&#x27;s flow control mechanism ensure clients cannot be overloaded even in the face of load surges, without impacting other workloads in the cluster.</p>
<p><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#job-streaming" target="_blank" rel="noopener noreferrer">Head over to the documentation to learn how to start using job push!</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-job-activation-latency-matters">Why job activation latency matters<a href="#why-job-activation-latency-matters" class="hash-link" aria-label="Direct link to Why job activation latency matters" title="Direct link to Why job activation latency matters">​</a></h2>
<p>Jobs are one of the fundamental building blocks of Zeebe, representing primarily all tasks (e.g. service, send, user), as well as some less obvious symbols (e.g. intermediate message throw event). In essence, they represent the actual unit of work in a process, the part users will implement, i.e. the actual application code. To reduce the likelihood of a job being worked on by multiple clients at the same time, it first goes through an activation process, where it is soft-locked for a specific amount of time. Soft-locked here means anyone can still interact with it - they can complete the job, fail it, etc. Only the activation is locked out, meaning no one else can activate the job until it&#x27;s timed out.</p>
<p>This means that most workloads will consist mostly of job interactions: creation, activation, completion, etc. As such, it&#x27;s critical to ensure clients receive jobs as fast as possible in order to make progress.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="polling-a-first-implementation">Polling: a first implementation<a href="#polling-a-first-implementation" class="hash-link" aria-label="Direct link to Polling: a first implementation" title="Direct link to Polling: a first implementation">​</a></h2>
<p>Back in 2018, Zeebe introduced the <code>ActivateJobs</code> RPC for its gRPC clients, analogous to fetching and locking <a href="https://docs.camunda.org/manual/7.20/user-guide/process-engine/external-tasks/" target="_blank" rel="noopener noreferrer">external tasks in Camunda 7.x</a>. This endpoint allowed clients to activate fetch and activate a specific number of available jobs. In other words, it allowed them to <em>poll</em> for jobs.</p>
<p>This was the first implementation to activate and work on jobs in Zeebe for multiple reason:</p>
<ul>
<li>It follows a simple request/response pattern</li>
<li>Flow control is delegated to the client/user</li>
<li>Most other approaches will build onto the building blocks used by polling</li>
<li>You will likely implement polling anyway as a fallback for other approaches (e.g. pushing)</li>
</ul>
<p>Grossly simplified, the implementation worked like this:</p>
<p><img decoding="async" loading="lazy" alt="Job polling" src="/zeebe-chaos/assets/images/job-poll-fbf0a5b11cac5467c5daba1424bc9230.png" width="784" height="554" class="img_ev3q"></p>
<ul>
<li>A client initiates an <code>ActivateJobs</code> call by sending an initial request</li>
<li>The gateway receives the request and validates it</li>
<li>The gateway starts polling each partition synchronously one by one</li>
<li>Whenever jobs are received from a partition, it forwards them to the client</li>
<li>When all partitions are exhausted, or the maximum number of jobs have been activated, the request is closed</li>
</ul>
<p>Already we can infer certain performance bottle necks based on the following:</p>
<ul>
<li>Every request - whether client to gateway, or gateway to broker - adds delay to the activation latency</li>
<li>In the worst case scenario, we have to poll <em>every</em> partition.</li>
<li>The gateway does not know in advance which partitions have jobs available.</li>
<li>Scaling out your clients may have adverse effects by sending out too many requests which all have to be processed independently</li>
<li><a href="https://github.com/camunda/camunda/issues/11813" target="_blank" rel="noopener noreferrer">If you have a lot of jobs, you can run into major performance issues when accessing the set of available jobs</a></li>
</ul>
<p>So if we have, say, 30 partitions, and each gateway-to-broker request takes 100ms, fetching the jobs on the last partition will take up to 3 seconds, even though the actual activation time on that partition was only 100ms.</p>
<p>Furthermore, if we have a sequence of tasks, fetching the next task in the sequence requires, in the worst case scenario, another complete round of polling through all the partitions, even though the task may already be available.</p>
<p>One would think a workaround to this issue would simply be to poll more often, but this can have an adverse impact: each polling request has to be processed by the brokers, and sending too many will simply flood your brokers and slow down all processing, further compounding the problem.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="long-polling-a-second-implementation">Long polling: a second implementation<a href="#long-polling-a-second-implementation" class="hash-link" aria-label="Direct link to Long polling: a second implementation" title="Direct link to Long polling: a second implementation">​</a></h3>
<p>To simplify things, the Zeebe team introduced <a href="https://github.com/camunda/camunda/issues/2825" target="_blank" rel="noopener noreferrer">long polling in 2019</a>. <a href="https://en.wikipedia.org/wiki/Push_technology#Long_polling" target="_blank" rel="noopener noreferrer">Long polling</a> is a fairly common technique to emulate a push or streaming approach while maintaing the request-response pattern of polling. Essentially, if the server has nothing to send to the client, instead of completing the request it will hold it until content is available, or a timeout is reached.</p>
<p>In Zeebe, this means that if we did not reach the maximum number of jobs to activate after polling all partitions, the request is parked but not closed. Eventually when jobs are available, the brokers will make this information known to the gateways, who will then unpark the oldest request and start a new polling round.</p>
<p><img decoding="async" loading="lazy" alt="Job polling" src="/zeebe-chaos/assets/images/job-long-poll-87a951a59369f8452d9a3e2f36421d8e.png" width="784" height="835" class="img_ev3q"></p>
<p>This solved certain problems:</p>
<ul>
<li>We reduced the amount of requests sent by clients, thus reducing load on the cluster.</li>
<li>In some cases, we reduced the latency when activating the next task in sequence.</li>
</ul>
<p>However, there are still some issues:</p>
<ul>
<li>When receiving the notification we <em>still</em> have to poll all partitions.</li>
<li>If you have multiple gateways, all gateways will start polling if they have parked requests. Some of them may not get any jobs, but they will still have sent requests to brokers which still all have to be processed.</li>
<li>In high load cases, you still need another client request/poll cycle to fetch the next task in a sequence.</li>
<li>Scaling out your clients still add more load on the system, even if the poll less often</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="job-push-third-times-the-charm">Job push: third time&#x27;s the charm<a href="#job-push-third-times-the-charm" class="hash-link" aria-label="Direct link to Job push: third time&#x27;s the charm" title="Direct link to Job push: third time&#x27;s the charm">​</a></h2>
<p>In order to solve these issues, the team decided to implement <a href="https://github.com/camunda/camunda/issues/11231" target="_blank" rel="noopener noreferrer">a push-based approach to job activation</a>.</p>
<p>Essentially, we added a new <code>StreamActivatedJobs</code> RPC to our gRPC protocol, a so-called <a href="https://grpc.io/docs/what-is-grpc/core-concepts/#server-streaming-rpc" target="_blank" rel="noopener noreferrer">server streaming RPC</a>. In our case, this is meant to be a long-lived stream, such that the call is completed only if the client terminates it, or if the server is shutting down.</p>
<p>The stream itself has the following lifecycle:</p>
<p><img decoding="async" loading="lazy" alt="Job push" src="/zeebe-chaos/assets/images/job-push-a314bcca5464ddee542b00633cc58d1b.png" width="784" height="612" class="img_ev3q"></p>
<ul>
<li>The client initiates the stream by sending a job activation request much like with the <code>ActivateJobs</code> RPC.<!-- -->
<ul>
<li>Since the stream is meant to be long lived, however, there is no upper bound on the number of jobs to activate.</li>
</ul>
</li>
<li>The gateway registers the new stream with all brokers in the cluster<!-- -->
<ul>
<li>Note that there is no direct connection between brokers and client; the gateway acts as a proxy for the client.</li>
</ul>
</li>
<li>When jobs are available for activation (e.g. on creation, on timeout, on backoff, etc.), the broker activates the job and pushes it to the gateway.</li>
<li>The gateway forwards the job to the client.</li>
</ul>
<p><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#how-it-works" target="_blank" rel="noopener noreferrer">You can read more about the implementation as part of our docs.</a></p>
<blockquote>
<p>Experienced readers will immediately spot that push-based approaches run the risk of overloading the client. Thanks to the built-in flow control facilities of gRPC, we can still ensure clients are resilient in the face of load surges. See <a href="https://docs.camunda.io/docs/components/concepts/job-workers/#backpressure" target="_blank" rel="noopener noreferrer">here for an explanation</a>.</p>
</blockquote>
<p>This solved most, if not all, of the problems listed above:</p>
<ul>
<li>Brokers push jobs out immediately as they become available, removing the need for a gateway-to-broker request.</li>
<li>Since the stream is long lived, there are almost no client requests required after the initial one.</li>
<li>No need to poll every partition anymore.</li>
<li>No thundering herd issues if you have many gateways all polling at the same time due to a notification.</li>
<li>Scaling out your clients adds little to no load to the system, as idle clients simply do nothing.</li>
<li>Even if you have a lot of jobs, in the average case, you never have to iterate over them and instead the broker pushes the job out on creation.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tests-results-and-comparisons">Tests, results, and comparisons<a href="#tests-results-and-comparisons" class="hash-link" aria-label="Direct link to Tests, results, and comparisons" title="Direct link to Tests, results, and comparisons">​</a></h3>
<p>In order to compare the advantages of pushing to polling, we did three different experiments.</p>
<blockquote>
<p>Note that all throughput measurements are in process instances executed per second, shortened to PI/s. Additionally, in the results shown below, dotted lines in graphs always refer to job polling measurements, and filled lines to job pushing.</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cluster-specifications">Cluster specifications<a href="#cluster-specifications" class="hash-link" aria-label="Direct link to Cluster specifications" title="Direct link to Cluster specifications">​</a></h4>
<p>Note that, unless specificed otherwise, we used the following clusters to run the tests: 3 brokers, 2 gateways, 3 partitions, replication factor 3.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="brokers">Brokers<a href="#brokers" class="hash-link" aria-label="Direct link to Brokers" title="Direct link to Brokers">​</a></h5>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>1350m</td></tr><tr><td>Memory request</td><td>4Gi</td></tr><tr><td>CPU thread count</td><td>3</td></tr><tr><td>IO thread count</td><td>3</td></tr><tr><td>Disk type</td><td><a href="https://cloud.google.com/compute/docs/disks#disk-types" target="_blank" rel="noopener noreferrer">pd-ssd</a></td></tr><tr><td>Disk size</td><td>32Gi</td></tr></tbody></table>
<blockquote>
<p>Disk type, size, and vCPU count in GCP is used to determine your maximum IOPS.</p>
</blockquote>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="gateways">Gateways<a href="#gateways" class="hash-link" aria-label="Direct link to Gateways" title="Direct link to Gateways">​</a></h5>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>450m</td></tr><tr><td>Kubernetes memory request</td><td>1Gi</td></tr><tr><td>Management thread count</td><td>2</td></tr></tbody></table>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="workers">Workers<a href="#workers" class="hash-link" aria-label="Direct link to Workers" title="Direct link to Workers">​</a></h5>
<p>To simulate work, whenever workers receive an activated job, they will wait 50ms before completing it.</p>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>500m</td></tr><tr><td>Kubernetes memory request</td><td>256Mi</td></tr><tr><td>Thread count</td><td>10</td></tr><tr><td>Max jobs active</td><td>60</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="one-task">One task<a href="#one-task" class="hash-link" aria-label="Direct link to One task" title="Direct link to One task">​</a></h4>
<p>As our baseline test, we ran a constant throughput of 150 PI/s of a single task process workload:</p>
<p><img decoding="async" loading="lazy" alt="A single task BPMN process: start -&amp;gt; task -&amp;gt; end" src="/zeebe-chaos/assets/images/single-task-bpmn-99ed3a15761cf3fbe8bfdc20807d4c7e.png" width="999" height="276" class="img_ev3q"></p>
<p>Since each job takes at least 50ms of work, the lower bound execution latency for this process is 50ms.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s single task process" src="/zeebe-chaos/assets/images/single-task-benchmark-4ef8a419140fd42094f359a54a74000b.png" width="1907" height="867" class="img_ev3q"></p>
<p>The results show a sharp decrease in both the p50 and p99 of the job lifetime (i.e. the time between creation and completion). Since this workload only consists of a single task, this is mirrored in the overall process execution latency. Overall, we see that switching to a push approach yields a p50 latency improvement of 50%, and a p99 improvement of 75%!</p>
<p>Additionally, we can see with job push that the Zeebe the p50 processing overhead is ~14ms, and the p99 ~390ms. For job polling, the p50 overhead is ~70ms, and the p99 overhead is ~1.7s.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ten-tasks">Ten tasks<a href="#ten-tasks" class="hash-link" aria-label="Direct link to Ten tasks" title="Direct link to Ten tasks">​</a></h4>
<p>For our next test, we ran a constant throughput of 150 PI/s of a ten tasks sequence process:</p>
<p><img decoding="async" loading="lazy" alt="A ten tasks sequence BPMN process: start -&amp;gt; task_1 -&amp;gt; task_2 -&amp;gt; ... -&amp;gt; task_10 -&amp;gt; end" src="/zeebe-chaos/assets/images/ten-tasks-bpmn-2617d2c0ddb0a87947bd2019efb66e74.png" width="2247" height="1137" class="img_ev3q"></p>
<p>Since each job takes at least 50ms of work, the lower bound execution latency for this process is 500ms.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s single task process" src="/zeebe-chaos/assets/images/ten-tasks-benchmark-bdae0ac5942ee080b193dbe7294ced1f.png" width="1901" height="864" class="img_ev3q"></p>
<p>The results show a sharp decrease in both the p50 and p99 of the job lifetime (i.e. the time between creation and completion). In this case, the process consists of several tasks, so the process execution latency is noticeably higher. But we can see that the p50 latency for job push is ~640ms. Overall, we see that switching to a push approach yields a p50 latency improvement of 30%, and a p99 improvement of 50%!</p>
<p>Additionally, we can see with job push that the Zeebe the p50 processing overhead is ~140ms, and the p99 ~1.8s. For job polling, the p50 overhead is ~1.4s, and the p99 overhead is ~4.3s.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="large-cluster">Large cluster<a href="#large-cluster" class="hash-link" aria-label="Direct link to Large cluster" title="Direct link to Large cluster">​</a></h4>
<p>In order to verify that the approach will scale along with the cluster size, we next compared polling and pushing with a cluster of 30 brokers and 30 partitions. Again, we tested with the single task process as above, and a constant throughput of 150 PI/s.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s against a large cluster" src="/zeebe-chaos/assets/images/thirty-partitions-benchmark-63cde3904d51c5b209efc0a1e9aad02e.png" width="1905" height="859" class="img_ev3q"></p>
<p>For job push, we see a greatly improved p99 - since each partition is doing less work than before with 3 partitions, we can achieve much more stable performance, with the p99 being quite close to the p50.</p>
<p>For job poll however, we see the downside of having to poll each partition in turn: the p50 is worse than before, and even though the p99 is greatly improved, we can see a wave pattern where it will spike up to 3s, so a decrease compared to the smaller cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="client-backpressure--load-surges">Client backpressure &amp; load surges<a href="#client-backpressure--load-surges" class="hash-link" aria-label="Direct link to Client backpressure &amp; load surges" title="Direct link to Client backpressure &amp; load surges">​</a></h4>
<p>One of the downsides of switching to a push approach, unfortunately, is that the client is now at risk of receiving more work than it can safely handle.</p>
<p>Thankfully, HTTP/2 and gRPC both have mechanisms to ensure flow control for server streaming RPCs.</p>
<p><a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading" target="_blank" rel="noopener noreferrer">You can find our tests results in a separate blog post</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="further-reading">Further reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further reading" title="Direct link to Further reading">​</a></h2>
<p>You can read more about job push here:</p>
<ul>
<li><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#job-streaming" target="_blank" rel="noopener noreferrer">Streaming job workers</a></li>
<li><a href="https://docs.camunda.io/docs/apis-tools/java-client/job-worker/#job-streaming" target="_blank" rel="noopener noreferrer">Job push for the Java client</a></li>
<li><a href="https://docs.camunda.io/docs/apis-tools/go-client/job-worker/#job-streaming" target="_blank" rel="noopener noreferrer">Job push for the Go client</a></li>
<li><a href="https://github.com/camunda-community-hub/spring-zeebe#enable-job-streaming" target="_blank" rel="noopener noreferrer">Job push for spring-zeebe</a></li>
</ul>
<p>Additionally, we&#x27;ve already written two other blog posts:</p>
<ul>
<li><a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading" target="_blank" rel="noopener noreferrer">Client backpressure resilience</a></li>
<li><a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency" target="_blank" rel="noopener noreferrer">Job stream fault tolerance</a></li>
</ul></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zeebe-chaos/tags/availability">availability</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-days/blog/2024-01-19-Job-Activation-Latency/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Using flow control to handle uncontrolled process loops</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zeebe-chaos/2023/12/20/Broker-scaling-performance"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Broker Scaling and Performance</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#why-job-activation-latency-matters" class="table-of-contents__link toc-highlight">Why job activation latency matters</a></li><li><a href="#polling-a-first-implementation" class="table-of-contents__link toc-highlight">Polling: a first implementation</a><ul><li><a href="#long-polling-a-second-implementation" class="table-of-contents__link toc-highlight">Long polling: a second implementation</a></li></ul></li><li><a href="#job-push-third-times-the-charm" class="table-of-contents__link toc-highlight">Job push: third time&#39;s the charm</a><ul><li><a href="#tests-results-and-comparisons" class="table-of-contents__link toc-highlight">Tests, results, and comparisons</a></li></ul></li><li><a href="#further-reading" class="table-of-contents__link toc-highlight">Further reading</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/zeebe" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://forum.camunda.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/Camunda" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/zeebe-io/zeebe-chaos/" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Zeebe Chaos. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>