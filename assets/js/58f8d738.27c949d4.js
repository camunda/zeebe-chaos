"use strict";(self.webpackChunkzell_chaos=self.webpackChunkzell_chaos||[]).push([[6024],{68882:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>n,toc:()=>h});var n=a(52742),s=a(74848),r=a(28453);const i={layout:"posts",title:"News from Camunda Exporter project",date:new Date("2024-12-12T00:00:00.000Z"),categories:["chaos_experiment","bpmn"],tags:["availability"],authors:"zell"},l="Chaos Day Summary",o={authorsImageUrls:[void 0]},h=[{value:"Chaos Experiment",id:"chaos-experiment",level:2},{value:"Benchmarks",id:"benchmarks",level:3},{value:"Details Experiment",id:"details-experiment",level:3},{value:"Expected",id:"expected",level:3},{value:"Base",id:"base",level:4},{value:"Main",id:"main",level:4},{value:"Actual",id:"actual",level:3},{value:"General Performance",id:"general-performance",level:4},{value:"Base general",id:"base-general",level:5},{value:"Main general",id:"main-general",level:5},{value:"Latency",id:"latency",level:4},{value:"Base latency",id:"base-latency",level:5},{value:"Main latency",id:"main-latency",level:5},{value:"Result",id:"result",level:3},{value:"Found Bugs",id:"found-bugs",level:4}];function c(e){const t={a:"a",h2:"h2",h3:"h3",h4:"h4",h5:"h5",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:"In this Chaos day we want to verify the current state of the exporter project, and run benchmarks with it. Comparing\nwith a previous version (v8.6.6) should give us a good hint on the current state and potential improvements."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"TL;DR;"})," The performance that the user sees data has been improved due to the architecture change, but there are still some bugs that we have to fix until the release."]}),"\n",(0,s.jsx)(t.h2,{id:"chaos-experiment",children:"Chaos Experiment"}),"\n",(0,s.jsx)(t.h3,{id:"benchmarks",children:"Benchmarks"}),"\n",(0,s.jsx)(t.p,{children:"We have seen in previous experiments and benchmarks that the realistic benchmarks are not yet totally reliable, as they seem to overload at some-point the system. This can happen if there is a hiccup and jobs take longer to process. Jobs in the queue are getting delayed, and time out, they are sent out to different workers, but we will reach at some point again the jobs, and we will publish also for this job a message. This in general increases the load of the system as we have to timeout jobs, we have to handle additional message publish, etc."}),"\n",(0,s.jsx)(t.p,{children:"Additionally, message publish can be rejected, when this happens we wait for another timeout adding again load on the system, more and more retries happen etc. this breaks the benchmark performance."}),"\n",(0,s.jsx)(t.p,{children:"To avoid this, we reduce the benchmark payload for now, which is in charge of creating multi instances and call activities etc. To be specific, the reduced the items from 50 to 5,\nbut scaled the starter to start more instances. With this payload we can scale more fine granular. Each instance can create 5 sub-instances, when creating three process instances  we create effectively 15 instances/token."}),"\n",(0,s.jsx)(t.p,{children:"As this the benchmark runs quite stable, it allows us to better compare the latency between based and main."}),"\n",(0,s.jsx)(t.h3,{id:"details-experiment",children:"Details Experiment"}),"\n",(0,s.jsx)(t.p,{children:"We will run two benchmarks one against 8.6.6, call based, and one against the current main branch (commit a1609130)."}),"\n",(0,s.jsx)(t.h3,{id:"expected",children:"Expected"}),"\n",(0,s.jsx)(t.p,{children:"When running the base and the main and comparing each other we expect that the general throughput, should be similar.\nFurthermore, we expect that the latency until the user sees data (or data is written into ES and searchable) should be lowered on main than base."}),"\n",(0,s.jsx)(t.p,{children:"Note: Right now we don't have a good metric to measure that data is available for the user, we plan to implement this in the starter benchmark application at some-point via querying the REST API. For now, we calculate different average latencies together, whereas we take as elasticsearch flush a constant of 2 seconds."}),"\n",(0,s.jsx)(t.p,{children:"We expect a reduction of latency as we reduce one additional hop/usage of ES as intermediate storage, before aggregation."}),"\n",(0,s.jsx)(t.h4,{id:"base",children:"Base"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"current-8.6",src:a(11535).A+"",width:"1096",height:"885"})}),"\n",(0,s.jsx)(t.h4,{id:"main",children:"Main"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"main-target",src:a(94007).A+"",width:"1114",height:"736"})}),"\n",(0,s.jsx)(t.h3,{id:"actual",children:"Actual"}),"\n",(0,s.jsx)(t.p,{children:"We have set up both benchmarks, running as described above with changed payloads."}),"\n",(0,s.jsx)(t.h4,{id:"general-performance",children:"General Performance"}),"\n",(0,s.jsx)(t.p,{children:"The general throughput performance looks similar. The resource consumption looks similar as well, but we didn't investigate this more deeply. Will be done separate."}),"\n",(0,s.jsx)(t.h5,{id:"base-general",children:"Base general"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"base-general",src:a(73760).A+"",width:"1901",height:"780"})}),"\n",(0,s.jsx)(t.h5,{id:"main-general",children:"Main general"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"main-general",src:a(20080).A+"",width:"1889",height:"784"})}),"\n",(0,s.jsx)(t.h4,{id:"latency",children:"Latency"}),"\n",(0,s.jsx)(t.p,{children:"This experiment targets to show difference in the data availability for the user."}),"\n",(0,s.jsx)(t.p,{children:"In order to better visualize the dashboard has been adjusted for this experiment."}),"\n",(0,s.jsx)(t.h5,{id:"base-latency",children:"Base latency"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"base-latency",src:a(66921).A+"",width:"1134",height:"793"})}),"\n",(0,s.jsx)(t.h5,{id:"main-latency",children:"Main latency"}),"\n",(0,s.jsx)(t.p,{children:"As we expected we were able to reduce the latency data is available for the user by the additional ES flush, reducing it by ~2 seconds."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"main-latency",src:a(84217).A+"",width:"1078",height:"581"})}),"\n",(0,s.jsx)(t.h3,{id:"result",children:"Result"}),"\n",(0,s.jsx)(t.p,{children:"We were able to show that the latency has been reduced under normal load."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Note:"})," Be aware this experiment only runs benchmarks with less-to-normal load, on higher load this might change, and need to be tested separately."]}),"\n",(0,s.jsx)(t.h4,{id:"found-bugs",children:"Found Bugs"}),"\n",(0,s.jsx)(t.p,{children:"Within the experiment we run into several other issues. Especially after running for a while, when pods got restarted and importer have been enabled, the Camunda Exporter broke."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"exporting-fail",src:a(54635).A+"",width:"951",height:"449"})}),"\n",(0,s.jsx)(t.p,{children:"This caused to increase the latency."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"exporting-fail-latency",src:a(63662).A+"",width:"1888",height:"193"})}),"\n",(0,s.jsx)(t.p,{children:"The exporter was not able to detect correctly anymore that the importing was done, but was still flushing periodically (which is as well wrong)"}),"\n",(0,s.jsx)(t.p,{children:"See related github issue(s)"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://github.com/camunda/camunda/issues/26046",children:"Importer(s) are not communicating import done correctly"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://github.com/camunda/camunda/issues/26047",children:"Exporter flushes periodically even when importer not completed"})}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Furthermore, based on logs we saw that the treePath hasn't be published correctly in the Exporter."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"https://github.com/camunda/camunda/issues/26048",children:"Camunda Exporter is not able to consume treePath"})}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},11535:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/current-miro-659b193b670b1b604ebb32ff30b067a4.png"},73760:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/base-general-452effab191f32fcf5a140949ec5a024.png"},66921:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/base-latencies-tree-17aa593ad5dc16c9ca89726c38155b82.png"},63662:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/exporting-fail-latency-15efaf79627febc56dbe8ee0247c87d3.png"},54635:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/exporting-fail-2ddb3996ac30f721fe4e9a1ec8fcce7a.png"},20080:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/main-general-a2f75f96be9f6682c54ab3cdfb931a8f.png"},84217:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/main-latencies-tree-7908eb4f973bd8e21f5fab8b2aec36bb.png"},94007:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/target-1781d302fcf5b933b427a8f5d5df7bd7.png"},28453:(e,t,a)=>{a.d(t,{R:()=>i,x:()=>l});var n=a(96540);const s={},r=n.createContext(s);function i(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),n.createElement(r.Provider,{value:t},e.children)}},52742:e=>{e.exports=JSON.parse('{"permalink":"/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project","editUrl":"https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-days/blog/2024-12-12-News-from-Camunda-Exporter-project/index.md","source":"@site/blog/2024-12-12-News-from-Camunda-Exporter-project/index.md","title":"News from Camunda Exporter project","description":"In this Chaos day we want to verify the current state of the exporter project, and run benchmarks with it. Comparing","date":"2024-12-12T00:00:00.000Z","tags":[{"inline":true,"label":"availability","permalink":"/zeebe-chaos/tags/availability"}],"readingTime":3.5,"hasTruncateMarker":true,"authors":[{"name":"Christopher Kujawa","title":"Chaos Engineer @ Zeebe","url":"https://github.com/zelldon","page":{"permalink":"/zeebe-chaos/authors/zell"},"imageURL":"https://github.com/zelldon.png","key":"zell"}],"frontMatter":{"layout":"posts","title":"News from Camunda Exporter project","date":"2024-12-12T00:00:00.000Z","categories":["chaos_experiment","bpmn"],"tags":["availability"],"authors":"zell"},"unlisted":false,"nextItem":{"title":"Impact of Camunda Exporter on processing performance","permalink":"/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance"}}')}}]);