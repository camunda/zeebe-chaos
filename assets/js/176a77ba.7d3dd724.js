"use strict";(self.webpackChunkzell_chaos=self.webpackChunkzell_chaos||[]).push([[4265],{40187:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>d,contentTitle:()=>l,default:()=>o,frontMatter:()=>i,metadata:()=>h,toc:()=>c});var n=r(74848),s=r(28453);const i={layout:"posts",title:"Optimizing cluster sizing using a real world benchmark",date:new Date("2024-10-14T00:00:00.000Z"),categories:["chaos_experiment","performance"],tags:["performance"],authors:"rodrigo"},l="Chaos Day Summary",h={permalink:"/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark",editUrl:"https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-days/blog/2024-10-14-Optimizing-cluster-sizing-using-a-real-world-benchmark/index.md",source:"@site/blog/2024-10-14-Optimizing-cluster-sizing-using-a-real-world-benchmark/index.md",title:"Optimizing cluster sizing using a real world benchmark",description:"Our first goal of this experiment is to use a benchmarks to",date:"2024-10-14T00:00:00.000Z",tags:[{inline:!0,label:"performance",permalink:"/zeebe-chaos/tags/performance"}],readingTime:6.125,hasTruncateMarker:!1,authors:[{name:"Rodrigo Lopes",title:"Associate Software Engineer @ Zeebe",url:"https://github.com/rodrigo-lourenco-lopes",imageURL:"https://github.com/rodrigo-lourenco-lopes.png",key:"rodrigo",page:null}],frontMatter:{layout:"posts",title:"Optimizing cluster sizing using a real world benchmark",date:"2024-10-14T00:00:00.000Z",categories:["chaos_experiment","performance"],tags:["performance"],authors:"rodrigo"},unlisted:!1,prevItem:{title:"Camunda Exporter MVP",permalink:"/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP"},nextItem:{title:"Improve Operate import latency",permalink:"/zeebe-chaos/2024/08/19/Operate-improve-import-latency"}},d={authorsImageUrls:[void 0]},c=[{value:"Chaos Experiment",id:"chaos-experiment",level:2},{value:"Expected",id:"expected",level:3},{value:"Actual",id:"actual",level:3},{value:"Minimal Requirements for our Cluster",id:"minimal-requirements-for-our-cluster",level:4},{value:"Reverse Engineering the Cluster Configuration",id:"reverse-engineering-the-cluster-configuration",level:4},{value:"Reduction in Resources for our Optimized Cluster",id:"reduction-in-resources-for-our-optimized-cluster",level:5},{value:"Scaling out the Cluster",id:"scaling-out-the-cluster",level:4},{value:"Bugs found",id:"bugs-found",level:3}];function a(e){const t={h2:"h2",h3:"h3",h4:"h4",h5:"h5",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.p,{children:"Our first goal of this experiment is to use a benchmarks to\nderive new optimized cluster configuration that can handle\nat least 100 tasks per second, while maintaining low backpressure and low latency."}),"\n",(0,n.jsx)(t.p,{children:"For our experiment, we use a newly defined realistic benchmark (with a more complex process model). More about this in a separate blog post."}),"\n",(0,n.jsx)(t.p,{children:"The second goal is to scale out optimized cluster configuration\nresources linearly and see if the performance scales accordingly."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"TL;DR;"})}),"\n",(0,n.jsx)(t.p,{children:"We used a realistic benchmark to derive a new\ncluster configuration based on previous requirements."}),"\n",(0,n.jsx)(t.p,{children:"When we scale this base configuration linearly we see that the performance\nincreases almost linearly as well, while maintaining low\nbackpressure and low latency."}),"\n",(0,n.jsx)(t.h2,{id:"chaos-experiment",children:"Chaos Experiment"}),"\n",(0,n.jsx)(t.h3,{id:"expected",children:"Expected"}),"\n",(0,n.jsx)(t.p,{children:"We expect that we can find a cluster configuration that can handle at 100\ntasks second to be significantly reduced in resources in relation to our\nsmaller clusters (G3-S HA Plan) since these can process significantly above\nour initial target."}),"\n",(0,n.jsx)(t.p,{children:"We also expect that we can scale this base configuration linearly, and that\nthe processing tasks rate to grow initially a bit faster than linearly due to\nthe lower relative overhead, and if we keep expanding further to flatten due\nto the partition count being a bottleneck."}),"\n",(0,n.jsx)(t.h3,{id:"actual",children:"Actual"}),"\n",(0,n.jsx)(t.h4,{id:"minimal-requirements-for-our-cluster",children:"Minimal Requirements for our Cluster"}),"\n",(0,n.jsx)(t.p,{children:"Based on known customer usage, and our own previous experiments, we\ndetermined that the new cluster would need to create and complete a\nbaseline of 100 tasks per second, or about 8.6 million tasks per day."}),"\n",(0,n.jsx)(t.p,{children:"Other metrics that we want to preserve and keep track are the backpressure\nto preserve user experience, guarantee that exporting speed can keep up\nwith the processing speed, write-to-import latency which tells us how long\nit takes for a record to be written to being imported by our other\napps such as the operator."}),"\n",(0,n.jsx)(t.h4,{id:"reverse-engineering-the-cluster-configuration",children:"Reverse Engineering the Cluster Configuration"}),"\n",(0,n.jsx)(t.p,{children:"For our new configurations the only resources that we are going to change\nare the ones relevant to the factors described above. These are the\nresources allocated to our zeebe-brokers, gateway and elasticSearch."}),"\n",(0,n.jsx)(t.p,{children:"Our starting point in resources was the configuration for our G3-S HA Plan\nas this already had the capability to significantly outperform the current\ngoal of 100 tasks per second."}),"\n",(0,n.jsx)(t.p,{children:"The next step was to deploy our realistic benchmark, with a payload of 5\ncustomer disputes per instance and start 7 instances per second, this\ngenerated approximately 120 tasks per second (some buffer was added to guarantee performance)."}),"\n",(0,n.jsx)(t.p,{children:"After this we reduced the resources iteratively until we saw any increase\nin backpressure, given that no there was no backlog of records, and no\nsignificant increase in the write to import latency."}),"\n",(0,n.jsx)(t.p,{children:"The results for our new cluster are specified bellow in the tables, where\nour starting cluster configuration is the G3-S HA Plan and the new\nconfiguration cluster is the G3 - BasePackage HA."}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"G3-S HA"}),(0,n.jsx)(t.th,{children:"CPU Limit"}),(0,n.jsx)(t.th,{children:"Memory Limit in GB"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"operate"}),(0,n.jsx)(t.td,{children:"2"}),(0,n.jsx)(t.td,{children:"2"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"operate.elasticsearch"}),(0,n.jsx)(t.td,{children:"6"}),(0,n.jsx)(t.td,{children:"6"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"optimize"}),(0,n.jsx)(t.td,{children:"2"}),(0,n.jsx)(t.td,{children:"2"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"tasklist"}),(0,n.jsx)(t.td,{children:"2"}),(0,n.jsx)(t.td,{children:"2"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"zeebe.broker"}),(0,n.jsx)(t.td,{children:"2.88"}),(0,n.jsx)(t.td,{children:"12"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"zeebe.gateway"}),(0,n.jsx)(t.td,{children:"0.9"}),(0,n.jsx)(t.td,{children:"0.8"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"TOTAL"})}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"15.78"})}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"24.8"})})]})]})]}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"G3 - BasePackage HA"}),(0,n.jsx)(t.th,{children:"CPU Limit"}),(0,n.jsx)(t.th,{children:"Memory Limit in GB"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"operate"}),(0,n.jsx)(t.td,{children:"1"}),(0,n.jsx)(t.td,{children:"1"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"operate.elasticsearch"}),(0,n.jsx)(t.td,{children:"3"}),(0,n.jsx)(t.td,{children:"4.5"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"optimize"}),(0,n.jsx)(t.td,{children:"1"}),(0,n.jsx)(t.td,{children:"1.6"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"tasklist"}),(0,n.jsx)(t.td,{children:"1"}),(0,n.jsx)(t.td,{children:"1"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"zeebe.broker"}),(0,n.jsx)(t.td,{children:"1.5"}),(0,n.jsx)(t.td,{children:"4.5"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"zeebe.gateway"}),(0,n.jsx)(t.td,{children:"0.6"}),(0,n.jsx)(t.td,{children:"1"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"TOTAL"})}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"8.1"})}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"13.6"})})]})]})]}),"\n",(0,n.jsx)(t.h5,{id:"reduction-in-resources-for-our-optimized-cluster",children:"Reduction in Resources for our Optimized Cluster"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{style:{textAlign:"left"}}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"CPU Reduction (%)"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Memory Reduction (%)"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"zeebe.broker"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"47.92"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"62.5"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"zeebe.gateway"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"33.33"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"-25.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"operate.elasticsearch"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"50.00"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"25.0"})]})]})]}),"\n",(0,n.jsx)(t.p,{children:"Total cluster reduction:"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{style:{textAlign:"left"}}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"G3-S HA"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"G3 - BasePackage HA"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Reduction (%)"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"CPU Limits"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"15.78"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"8.1"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"49"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Memory Limits"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"24.8"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"13.6"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"45"})]})]})]}),"\n",(0,n.jsx)(t.p,{children:"The process of reducing the hardware requirements was donne initially by\nscaling down the resources of the zeebe-broker, gateway and elasticSearch.\nThe other components were left untouched, as they had no impact in our key\nmetrics, and were scaled down later in separate experiences to maintain\nuser experience."}),"\n",(0,n.jsx)(t.h4,{id:"scaling-out-the-cluster",children:"Scaling out the Cluster"}),"\n",(0,n.jsx)(t.p,{children:"Now for the scaling procedure we intend to see if we can linearly increase\nthe allocated resources and having a corresponding performance increase,\nwhile keeping the backpressure low, low latency, and user experience."}),"\n",(0,n.jsx)(t.p,{children:"For this we started with the G3 - BasePackage HA configuration and\nincremented the load again until we saw any increase in backpressure,\ncapture our key metrics and repeated the process for the cluster\nconfiguration resources respectively multiplied by 2x, 3x, and 4x."}),"\n",(0,n.jsx)(t.p,{children:"This means that the resources allocated for our clusters were:"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{style:{textAlign:"left"}}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 1x"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 2x"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 3x"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 4x"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"CPU Limits"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"8.7"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"17.4"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"26.1"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"34.8"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Memory Limits"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"14.9"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"29.8"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"44.7"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"59.6"})]})]})]}),"\n",(0,n.jsx)(t.p,{children:"The results in the table bellow show the performance of our several cluster\nconfigurations:"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{style:{textAlign:"left"}}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 1x"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 2x"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 3x"}),(0,n.jsx)(t.th,{style:{textAlign:"right"},children:"Base 4x"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Process Instances/s"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"7"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"12"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"23"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"27"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Tasks/s"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"125"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"217"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"414"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"486"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Average Backpressure"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"2%"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"2%"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"3%"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"6%"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Write-to-Import Latency"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"90s"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"120s"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"150s"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"390s"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Write-to-Process Latency"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"140ms"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"89ms"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"200ms"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"160ms"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Records Processed Rate"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"2500"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"4700"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"7800"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"11400"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Records Exported Rate"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"2100"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"3900"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"6500"}),(0,n.jsx)(t.td,{style:{textAlign:"right"},children:"9200"})]})]})]}),"\n",(0,n.jsx)(t.p,{children:"This first observations is that the performance scales particularly well by\njust adding more resources to the cluster, particularly for a linear\nincrease of the resources the performance as measured by tasks completed\nincreases slightly less than linearly (comparing the 1x and 4x task/s we\nget 388% the initial rate)."}),"\n",(0,n.jsx)(t.p,{children:"This a very good result as it means that we can scale our system linearly\n(at least initially) to handle the expected increase in loads."}),"\n",(0,n.jsx)(t.p,{children:"Importantly, the backpressure is kept low, and the write-to-import latency\nonly increases significantly if we leave the cluster running at max rate\nfor long periods of time. For slightly lower rates the write-to-import\nlatency is kept in the single digits of seconds or lower tens. This might\nimply that a these sustained max rates, the amount records generated starts\nto be too much for either ElasticSearch or our web apps that import these\nrecords to handle. Some further investigation could be done here to\ninvestigate the bottleneck."}),"\n",(0,n.jsx)(t.p,{children:"Another metric also relevant but not shown in this table is the backlog of\nrecords not exported, which kept at almost null through all the experiments\nconducted."}),"\n",(0,n.jsx)(t.h3,{id:"bugs-found",children:"Bugs found"}),"\n",(0,n.jsx)(t.p,{children:"During the initial tests, we had several OOM errors in the gateways pods.\nAfter some investigation, we found that this was exclusive to the Camunda 8.\n6.0 version, which consumes more memory in the gateway than the previous\nversions. This explains why the gateway memory limits were the only\nresource that was increased in the new reduced cluster configuration."})]})}function o(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(a,{...e})}):a(e)}},28453:(e,t,r)=>{r.d(t,{R:()=>l,x:()=>h});var n=r(96540);const s={},i=n.createContext(s);function l(e){const t=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function h(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);