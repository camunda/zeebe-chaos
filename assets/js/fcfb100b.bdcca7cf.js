"use strict";(self.webpackChunkzell_chaos=self.webpackChunkzell_chaos||[]).push([[4591],{51060:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>n,toc:()=>c});var n=t(71220),s=t(74848),r=t(28453);const o={layout:"posts",title:"Performance of REST API",date:new Date("2025-06-30T00:00:00.000Z"),categories:["chaos_experiment","bpmn"],tags:["availability"],authors:"zell"},i="Chaos Day Summary",l={authorsImageUrls:[void 0]},c=[{value:"Chaos Experiment (Pt. 1)",id:"chaos-experiment-pt-1",level:2},{value:"Expected",id:"expected",level:3},{value:"Actual",id:"actual",level:3},{value:"Result",id:"result",level:3},{value:"Chaos Experiment (Pt. 2)",id:"chaos-experiment-pt-2",level:2},{value:"Expected",id:"expected-1",level:2},{value:"Actual",id:"actual-1",level:2},{value:"Chaos Experiment (Pt. 3)",id:"chaos-experiment-pt-3",level:2},{value:"Expected",id:"expected-2",level:3},{value:"Actual",id:"actual-2",level:3},{value:"Found Bugs",id:"found-bugs",level:2}];function h(e){const a={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.p,{children:"In today's Chaos day we wanted to experiment with the new REST API (v2) as a replacement for our previous used gRPC API."}),"\n",(0,s.jsx)(a.p,{children:"Per default, our load tests make use of the gRPC, but as we want to make REST API the default and release this fully with 8.8, we want to make sure to test this accordingly in regard to reliability."}),"\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.strong,{children:"TL;DR;"})," We observed severe performance regression when using the REST API, even when job streaming is in use by the job workers (over gRPC). Our client seems to have a higher memory consumption, which caused some instabilities in our tests as well. With the new API, we lack certain observability, which makes it harder to dive into certain details. We should investigate this further and find potential bottlenecks and improvements."]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"general",src:t(84298).A+"",width:"1879",height:"879"})}),"\n",(0,s.jsx)(a.h2,{id:"chaos-experiment-pt-1",children:"Chaos Experiment (Pt. 1)"}),"\n",(0,s.jsxs)(a.p,{children:["To experiment with the REST API, we have to adjust our client applications to make use of the REST API. This is done by the following PR ",(0,s.jsx)(a.a,{href:"https://github.com/camunda/camunda/pull/34527",children:"#34527"}),". We can take our normal benchmark/load tests where we run 150 PI/s, and enable the REST API usage. To make this possible, the charts have been adjusted by this PR ",(0,s.jsx)(a.a,{href:"https://github.com/camunda/zeebe-benchmark-helm/pull/269",children:"#269"}),"."]}),"\n",(0,s.jsx)(a.p,{children:"As a base to compare we can use our weekly benchmarks. We use gRPC here as the default in the client applications (starter + worker).\nIn our weekly benchmarks, we can see that we are able to create and complete 150 process instances per second."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"base-general",src:t(37706).A+"",width:"1911",height:"990"})}),"\n",(0,s.jsx)(a.p,{children:"The performance is stable, and we have low backpressure. As the process instances are quite simple (with one service task), the execution time is rather low with 0.2 seconds on average."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"base-latency",src:t(98712).A+"",width:"1897",height:"644"})}),"\n",(0,s.jsx)(a.h3,{id:"expected",children:"Expected"}),"\n",(0,s.jsx)(a.p,{children:"When using the REST API, we expect some more overhead (maybe ~10%), like serializing and sending data over the wire (as gRPC is optimized for it). In general, we expect a stable performing system."}),"\n",(0,s.jsx)(a.h3,{id:"actual",children:"Actual"}),"\n",(0,s.jsxs)(a.p,{children:["Observing the first experiment, we saw a degradation of performance ",(0,s.jsx)(a.strong,{children:"by more than 70%"}),". Additionally, we seem to have no metrics for the REST API requests. Backpressure seems to be zero, while we're not performing as expected."]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp1-general",src:t(12547).A+"",width:"1903",height:"967"})}),"\n",(0,s.jsx)(a.p,{children:"The process instance completion latency has been increased to above than one minute."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp1-latency",src:t(69917).A+"",width:"1905",height:"649"})}),"\n",(0,s.jsx)(a.p,{children:"We can observe with our metrics that job push is still in use, and the job workers get to work on the available jobs."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp1-push",src:t(79719).A+"",width:"1894",height:"339"})}),"\n",(0,s.jsx)(a.p,{children:"The issue we are seeing is related to crash looping workers (which we can also see in the panels above about Pod restarts)."}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-shell",children:"$ kgpo\nNAME                                                              READY   STATUS             RESTARTS         AGE\nbenchmark-worker-5765dbfb55-2gckc                                 1/1     Running            34 (5m40s ago)   4h1m\nbenchmark-worker-5765dbfb55-6mckn                                 1/1     Running            26 (69m ago)     3h46m\nbenchmark-worker-5765dbfb55-qtrmm                                 0/1     CrashLoopBackOff   33 (4m20s ago)   4h1m\nck-bojan-rest-benchmark-prometheus-elasticsearch-exporter-v7nqk   1/1     Running            0                3h46m\nck-bojan-rest-benchmark-zeebe-0                                   1/1     Running            0                4h1m\nck-bojan-rest-benchmark-zeebe-1                                   1/1     Running            0                107m\nck-bojan-rest-benchmark-zeebe-2                                   1/1     Running            0                4h1m\nelastic-0                                                         1/1     Running            0                3h45m\nelastic-1                                                         1/1     Running            0                4h1m\nelastic-2                                                         1/1     Running            0                4h1m\nleader-balancer-29188095-9gdhd                                    0/1     Completed          0                8m39s\nstarter-677bc5cb4-pr7xq                                           1/1     Running            0                3h46m\n\n"})}),"\n",(0,s.jsx)(a.p,{children:"Investigating the respective pods, we can see that they are failing because of OOM errors."}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-shell",children:"    Last State:     Terminated\n      Reason:       OOMKilled\n      Exit Code:    137\n      Started:      Mon, 30 Jun 2025 14:15:14 +0200\n      Finished:     Mon, 30 Jun 2025 14:18:00 +0200\n    Ready:          True\n    Restart Count:  34\n    Limits:\n      cpu:     500m\n      memory:  256Mi\n    Requests:\n      cpu:     500m\n      memory:  256Mi\n"})}),"\n",(0,s.jsx)(a.h3,{id:"result",children:"Result"}),"\n",(0,s.jsx)(a.p,{children:"Our first experiment failed to validate our expectation of:"}),"\n",(0,s.jsxs)(a.blockquote,{children:["\n",(0,s.jsx)(a.p,{children:"When using the REST API we expect some more overhead (maybe ~10%), like serializing and sending data over the wire (as gRPC is optimized for it). In general, we expect a stable performing system."}),"\n"]}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:["\u274c"," We were not able to prove that our load tests run with simply enabling the REST API with minimal impact"]}),"\n",(0,s.jsxs)(a.li,{children:["\u274c"," The performance of the system was not stable."]}),"\n",(0,s.jsxs)(a.li,{children:["\u274c"," The workers, can't work with the same amount of memory they used before for gRPC."]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"chaos-experiment-pt-2",children:"Chaos Experiment (Pt. 2)"}),"\n",(0,s.jsx)(a.p,{children:"To validate whether our experiment would work with the REST API and the workers having more memory, we increase the resource usage of the workers."}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-shell",children:"    State:          Running\n      Started:      Mon, 30 Jun 2025 14:25:40 +0200\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      cpu:     500m\n      memory:  1Gi\n    Requests:\n      cpu:     500m\n      memory:  1Gi\n"})}),"\n",(0,s.jsx)(a.h2,{id:"expected-1",children:"Expected"}),"\n",(0,s.jsx)(a.p,{children:"When the client applications have enough resources the expected performance of the REST API usage should be minimally lower than with the gRPC API. The system should perform stable."}),"\n",(0,s.jsx)(a.h2,{id:"actual-1",children:"Actual"}),"\n",(0,s.jsx)(a.p,{children:"As soon as we configured the workers, and gave them more memory, they stopped to crash loop. Still we are not able to reache the same performance (not even close) as with our normal base (weekly benchmark)."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp2-general",src:t(58072).A+"",width:"1901",height:"903"})}),"\n",(0,s.jsx)(a.p,{children:"The performance (after 1430) looks more stale (less fluctuating), but still not well."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp2-push",src:t(1526).A+"",width:"1892",height:"341"})}),"\n",(0,s.jsx)(a.p,{children:"We seem to push more jobs out, on a constant rate. Looking at the logstream metrics, we can see that we rejecting a lot of commands, especially COMPLETEs and FAILs."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp2-log",src:t(6826).A+"",width:"1893",height:"336"})}),"\n",(0,s.jsx)(a.p,{children:"We see interesting warning logs by the workers:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-shell",children:"12:40:07.532 [pool-4-thread-2] WARN  io.camunda.client.job.worker - Worker benchmark failed to handle job with key 4503599643648545 of type benchmark-task, sending fail command to broker\njava.lang.IllegalStateException: Queue full\n\tat java.base/java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:?]\n\tat java.base/java.util.concurrent.ArrayBlockingQueue.add(ArrayBlockingQueue.java:329) ~[?:?]\n\tat io.camunda.zeebe.Worker.lambda$handleJob$1(Worker.java:122) ~[classes/:?]\n\tat io.camunda.client.impl.worker.JobRunnableFactoryImpl.executeJob(JobRunnableFactoryImpl.java:45) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]\n\tat io.camunda.client.impl.worker.JobRunnableFactoryImpl.lambda$create$0(JobRunnableFactoryImpl.java:40) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]\n\tat io.camunda.client.impl.worker.BlockingExecutor.lambda$execute$0(BlockingExecutor.java:50) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]\n\tat java.base/java.lang.Thread.run(Thread.java:1583) [?:?]\n"})}),"\n",(0,s.jsx)(a.p,{children:"I think it is not fully clear what the user should do with this. AFAIK, based on the implementation, it is also not how we expected it to behave, as we wanted to block in this case."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp2-snapshot",src:t(60739).A+"",width:"940",height:"318"})}),"\n",(0,s.jsx)(a.p,{children:"We can see that even when we recover the workers, with more memory, we are not able to come back to a performing system. This is likely because we aggregated already quite some data, and are running in some weird timeout and completion/fail loops. This needs further investigation (follow-up)."}),"\n",(0,s.jsx)(a.h2,{id:"chaos-experiment-pt-3",children:"Chaos Experiment (Pt. 3)"}),"\n",(0,s.jsx)(a.p,{children:"With our third experiment, we want to validate how our load tests perform with some clean state, and workers set up correctly."}),"\n",(0,s.jsx)(a.h3,{id:"expected-2",children:"Expected"}),"\n",(0,s.jsx)(a.p,{children:"See above."}),"\n",(0,s.jsx)(a.h3,{id:"actual-2",children:"Actual"}),"\n",(0,s.jsx)(a.p,{children:"With no previous data and stable workers, we seem to be able to reach higher throughput again."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp3-general",src:t(34457).A+"",width:"1877",height:"884"})}),"\n",(0,s.jsx)(a.p,{children:"The latency looks fairly similar to our base (weekly) benchmarks. Here again, 99% of PIs need less than 0.25 seconds to complete."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp3-latency",src:t(12279).A+"",width:"1892",height:"611"})}),"\n",(0,s.jsx)(a.p,{children:"After a while, the load tests seem to behave similarly to the previous ones, reporting several timeouts and completion rejections."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp3-jobs",src:t(71276).A+"",width:"1898",height:"337"})}),"\n",(0,s.jsx)(a.p,{children:"This is degrading the performance completely."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp3-general-drop",src:t(90291).A+"",width:"1884",height:"912"})}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"exp3-latency-mess",src:t(95818).A+"",width:"1886",height:"636"})}),"\n",(0,s.jsx)(a.p,{children:"Our workers seem to report similar issues as before, regarding having a full queue:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-shell",children:"13:25:14.684 [pool-4-thread-3] WARN  io.camunda.client.job.worker - Worker benchmark failed to handle job with key 4503599628992806 of type benchmark-task, sending fail command to broker\njava.lang.IllegalStateException: Queue full\n\tat java.base/java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:?]\n\tat java.base/java.util.concurrent.ArrayBlockingQueue.add(ArrayBlockingQueue.java:329) ~[?:?]\n\tat io.camunda.zeebe.Worker.lambda$handleJob$1(Worker.java:122) ~[classes/:?]\n\tat io.camunda.client.impl.worker.JobRunnableFactoryImpl.executeJob(JobRunnableFactoryImpl.java:45) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]\n\tat io.camunda.client.impl.worker.JobRunnableFactoryImpl.lambda$create$0(JobRunnableFactoryImpl.java:40) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]\n\tat io.camunda.client.impl.worker.BlockingExecutor.lambda$execute$0(BlockingExecutor.java:50) ~[camunda-client-java-8.8.0-SNAPSHOT.jar:8.8.0-SNAPSHOT]\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?\n"})}),"\n",(0,s.jsxs)(a.p,{children:["\u274c"," Right now it seems that the usage of the REST API can impact the general performance of the system (even with the usage of the Job streaming in the workers). As of now it is not clear why, which we have to further investigate and clarify."]}),"\n",(0,s.jsx)(a.h2,{id:"found-bugs",children:"Found Bugs"}),"\n",(0,s.jsx)(a.p,{children:"Following issues and follow ups have been noted down"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"REST API usage affects highly general performance of the system"}),"\n",(0,s.jsx)(a.li,{children:"REST API observability is missing"}),"\n",(0,s.jsx)(a.li,{children:"Clients using the REST API have higher memory usage"}),"\n",(0,s.jsx)(a.li,{children:"Worker seem to fail with unexpected error/warning messages when receiving jobs."}),"\n"]})]})}function d(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},37706:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/base-general-e28fa9defe09774a06b06e1875411d34.png"},98712:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/base-latency-0a48e74f5c1bb7b726086f290ab82c15.png"},12547:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp1-general-666de10e428ddacf15eec4af011831a4.png"},69917:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp1-latency-6780630818b87b53dd473beb01ddc29e.png"},79719:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp1-push-c50f1b764452b3be53ee861f4c111731.png"},58072:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp2-general-0406467c1e3f8ae9f58baf590ea95e4f.png"},6826:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp2-log-8c650f58f451d54cad986da8f575e166.png"},1526:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp2-push-aae3cba4d20f09d18e83303fa116cdc7.png"},60739:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp2-snapshots-81650c422f7258308963327c14669cb8.png"},90291:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp3-general-drop-b6c30790b698047dd290286c8861f203.png"},34457:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp3-general-aeb1fc9dd70c0196e2d8dc69606a372c.png"},71276:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp3-jobs-rejections-09cfb799b115c8ae5ebbc9c70fbf870e.png"},95818:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp3-latency-mess-bfc491d125d481bc98e8a0e036c0ffed.png"},12279:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/exp3-latency-55ecd2393d8199b12edb2cd098c83249.png"},84298:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/general-overview-a0c6c48be94b9a8aa8cbbd3b44830a67.png"},28453:(e,a,t)=>{t.d(a,{R:()=>o,x:()=>i});var n=t(96540);const s={},r=n.createContext(s);function o(e){const a=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(r.Provider,{value:a},e.children)}},71220:e=>{e.exports=JSON.parse('{"permalink":"/zeebe-chaos/2025/06/30/Performance-of-REST-API","editUrl":"https://github.com/camunda/zeebe-chaos/blob/master/chaos-days/blog/2025-06-30-Performance-of-REST-API/index.md","source":"@site/blog/2025-06-30-Performance-of-REST-API/index.md","title":"Performance of REST API","description":"In today\'s Chaos day we wanted to experiment with the new REST API (v2) as a replacement for our previous used gRPC API.","date":"2025-06-30T00:00:00.000Z","tags":[{"inline":true,"label":"availability","permalink":"/zeebe-chaos/tags/availability"}],"readingTime":6.2,"hasTruncateMarker":true,"authors":[{"name":"Christopher Kujawa","title":"Chaos Engineer @ Zeebe","url":"https://github.com/ChrisKujawa","page":{"permalink":"/zeebe-chaos/authors/zell"},"imageURL":"https://github.com/ChrisKujawa.png","key":"zell"}],"frontMatter":{"layout":"posts","title":"Performance of REST API","date":"2025-06-30T00:00:00.000Z","categories":["chaos_experiment","bpmn"],"tags":["availability"],"authors":"zell"},"unlisted":false,"nextItem":{"title":"How does Zeebe behave with NFS","permalink":"/zeebe-chaos/2025/06/12/How-does-Zeebe-behave-with-NFS"}}')}}]);